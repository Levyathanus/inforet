{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee016c2a",
   "metadata": {},
   "source": [
    "# Example of IR system based on Vector Space Model on CISI\n",
    "\n",
    "The CISI dataset can be donwloaded at the following address: [CISI dataset](https://www.kaggle.com/datasets/dmaso01dsta/cisi-a-dataset-for-information-retrieval/code?select=CISI.REL)\n",
    "\n",
    "In this example, we access a local, parsed version of CISI stored in MongoDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b179d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50527065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd83540",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = MongoClient()['cisi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c145403",
   "metadata": {},
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b02c005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('63ff54cf5881e58ca7d9bb75'),\n",
       " 'id': 1,\n",
       " '.T': '18 Editions of the Dewey Decimal Classifications',\n",
       " '.A': 'Comaromi, J.P.',\n",
       " '.W': \"The present study is a history of the DEWEY Decimal Classification. The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed. In spite of the DDC's long and healthy life, however, its full story has never been told. There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad.\",\n",
       " '.X': [['1', '5', '1'],\n",
       "  ['92', '1', '1'],\n",
       "  ['262', '1', '1'],\n",
       "  ['556', '1', '1'],\n",
       "  ['1004', '1', '1'],\n",
       "  ['1024', '1', '1'],\n",
       "  ['1024', '1', '1']]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['documents'].find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed47c592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('63ff54fb5881e58ca7d9c129'),\n",
       " 'id': 1,\n",
       " '.W': 'What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['queries'].find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c3617f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('63ff56f65881e58ca7d9c199'), 'query': 1, 'doc': 28}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['rel'].find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547bb497",
   "metadata": {},
   "source": [
    "## Get documents, queries and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da0b6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69eb770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(r['id'], \". \".join([r['.T'], r['.W']])) for r in db['documents'].find()]\n",
    "queries = [(r['id'], r['.W']) for r in db['queries'].find()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebc396d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = defaultdict(list)\n",
    "\n",
    "for r in db['rel'].find():\n",
    "    ground_truth[r['query']].append(r['doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eb9ba5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can actually pertinent data, as opposed to references or entire articles themselves, be retrieved automatically in response to information requests? \n",
      "\n",
      "Some Questions Concerning \"Information Need\". The expression \"satisfying a requester's information need\" is often used, but its meaning is obscure. The literature on \"information need\" in relation to retrieval suggests three different (though not inconsistent) possible interpretations. However, each of these interpretations is itself fundamentally unclear. The various obscurities involved are indicated by critical questions, which those who write of information need are invited to answer. \n",
      "\n",
      "Retrieval of Answer-Providing Documents. (I) Better understanding of subject document retrieval might result if different functions of subject document retrieval system are studied separately.. This paper is concerned with retrieval of documents, in response to a question, from which answers to that question can be inferred (\"answer-providing documents\").. \"Answer can be inferred from document\" has many possible meanings, one of which must be selected (an \"inference specification\").. Inasmuch as scientists in a field disagree about the correctness of inferences, have somewhat different background knowledge, etc., any inference specification can only approximate scientific inference practices.. Two sources of systematic knowledge of document-statement inference practices in a scientific field are described.. (II) If a content word occurs in a question, then it occurs in any answer to that question (with some apparently tractable exceptions).. An indexing procedure based on that fact is described which would permit retrieval of all answer-providing documents for a question.. However, because the indexing is \"nonrelational\", it could cause false retrievals as well.. Various ways of dealing with such false retrievals are briefly indicated, and a study is sketched that would provide data for helping selection among them.. Two special point concerning indexing for retrieval of answer-providing documents are discussed separately.. \n",
      "\n",
      "AIM-TWX service at the University of Virginia: A Review and Evaluation. The paper reviews the highlights of a four-week trial period (November 19 - December 18, 1970) during which the Medical Library of the University of Virginia experimented with a new remote-access bibliographical control and retrieval system via its TWX machine.. The system, called AIM-TWX, was sponsored by the Lister Hill National Center for Biomedical Communications and utilized a time-shared IBM 360/67 computer in Santa Monica, California.. Citations from 109 clinically-oriented journals from 1966 to date, including those currently included in the Abridged Index Medicus, may be retrieved either on- or off-line.. Various aspects of this service are described, including problems of staffing, training, and record keeping, as well as the role of the MeSH vocabulary which is the principle \"language\" of the man-computer dialog.. The statistical results indicated that the system was used for approximately 200 minuted on nineteen days and that an average of sixteen searches were run on any given day, or about 4.6 searches per hour of use.. In spite of an inexperienced staff who had little knowledge of the MeSH vocabulary and whose training schedule was limited to one four-hour session, the experiment was highly successful in terms of searches and citations.. At the end of the period, 298 searches had been run for 114 requestors, and 5,343 citations had been produced.. Only fifty-five searches yielded no citations.. The experiment generated a great deal of excitement and interest among the staff of the Library and of the Medical Center.. Moreover, a large number of medical practitioners in large and small communities of Virginia participated in this experiment, indicating that there exists a great demand for this type of literature searching which AIM-TWX is able to provide with great rapidity.. \n",
      "\n",
      "The Role of the Medical Librarian in SDI Systems. Many ongoing selective dissemination systems designers assume that the librarian can be omitted from active participation in execution of the master plan.. ISI's four years of experience with ASCA service have shown that librarians must be an integral part of the system and engage in a active dialogue between users and the machine.. Specific examples of how librarians can best serve the information needs of scientists using SDI systems are examined.. It is the basic contention of this paper that the librarian should serve as an intermediary between users and the numerous new information media.. In this manner the librarian can filter and translate the requirements of individual scientists to conform with the inherent limitations of all machine systems while exploiting their capabilities to the fullest.. \n",
      "\n",
      "Library Participation in a Biomedical Communication and Information Network. The experience of two libraries participating in the SUNY Biomedical Communication Network is described.. The history of the Network if briefly given together with its original aims and their current status.. Use of the terminals and formulation of queries are explained.. Figures are given for total costs, number of searches performed, and cost per search.. There is a account of the internal structure of the administration of the Network.. \n",
      "\n",
      "The SMART Automatic Document Retrieval System - An Illustration. A fully automatic document retrieval system operating on the IBM 7094 is described.. The system is characterized by the fact that several hundred different methods are available to analyze documents and search requests.. This feature is used in the retrieval process by leaving the exact sequence of operations initially unspecified, and adapting the search strategy to the needs of individual users.. The system is used not only to simulate an actual operating environment, but also to test the effectiveness of the various available processing methods.. Results obtained so far seem to indicate that some combination of analysis procedures can in general be relied upon to retrieve the wanted information.. A typical search request is used as an example in the present report to illustrate systems operations and evaluation procedures.. \n",
      "\n",
      "Inefficiency of the Use of Boolean Functions for Information Retrieval Systems. In this note we attempt to point out why boolean functions are, in general, not applicable in information retrieval systems. First, we wish to stress that a system, which supposedly is to serve a certain purpose, has to try to optimize some overall performance rather than certain detailed parts of it. This situation is, of course, well known. Saying that a system should cater to an optimal performance implies that the reward varies with different circumstances. That is, there may always be some customers who will not agree that the system's output is satisfactory. However, these should be relatively few. In the case of an information retrieval system, let us consider one whose function is to furnish a reference list as a reaction to a question. So, if we have a set of documents S and a set of questions Q, the system has to assign to each question q, an answer A(q) which is a subset of S. Naturally, this answer cannot be chosen arbitrarily; it should reflect a relation between the question and the resulting reference list. Usually one says that the documents in the list are relevant to the question. More precisely stated, we assume that the enquirer expects a certain reference list, namely the one he would have procured had he himself probed the documents in the set. \n",
      "\n",
      "Computational Analysis of Present-Day American English. Readers can expect to find many parts of this volume tantalizing. The definiteness of the answers to certain questions irresistibly provokes more questions. The happy feature is that the book provides information required to limit the effect to that of tantalizing rather than frustrating. For there is given here a wholly adequate description of the nature of the Corpus of Present-Day Edited American English on which this study is based, the details of its constituents, and the modes of its transfer to tape. A replica of that tape is available at a small cost in money, which is minuscule compared to the cost in time needed to produce a like corpus. Accordingly, any reader who seriously wants answers to further questions can set about getting those answers. \n",
      "\n",
      "The Information Content of Titles in Engineering Literature. Since many alerting and information services rely very heavily on the use of titles to transfer information to the potential user, it is essential that he be aware of the proportion of the information contained in the complete document which will not be deducible from the title and which he will therefore miss.. Methods will be discussed for analyzing the relative information content of the titles of engineering paper and results presented for the amount and type of information lost through scanning title listing only.. Between one-third and one-half of indexable terms are not retrievable from article titles even if all possible synonyms and related terms are used.. If all synonyms are used instead of one keyword the amount of information retrieved is increased by about 70 percent.. The problems of dealing with synonyms and with syntactical variants in searching titles indexes are discussed.. The possibility of using keywords in journal titles as supplementary retrieval tags is suggested since they were deemed useful in nearly one-third of the sample of papers analyzed.. \n",
      "\n",
      "Experiments in Automatic Extracting and Indexing. This article reports on several experiments in automatic extracting and one experiment in automating indexing.. Nine chapters, each from a different technical book, were used as a text corpus for all the experiments.. In the first experiment, an attempt was made to construct a sentence dictionary of syntactic sentence types, for distinguishing extract-worthy sentences, but it proved unrewarding.. Nevertheless, the results indicated that sentence typing might be used in a screening process in conjunction with other extracting techniques.. The later attempts to combine synactic and statistical criteria in the choice of extract sentences and index phrases proved more rewarding.. The sentences selected by the extracting algorithm were representative and are presented for the reader to peruse.. The noun phrases selected by the indexing algorithm compared favorably with the back-of-the-book index phrases.. There is every indication that satisfactory back-of-the-book indexes could be produced automatically, with post-editing to delete superfluous items.. \n",
      "\n",
      "Text Searching Retrieval of Answer-Sentences and Other Answer-Passages. Some new text searching retrieval techniques are described which retrieve not documents but sentences from documents and sometimes (on occasions determined by the computer) multi-sentence sequences.. Since the goal of the techniques is retrieval of answer-providing documents, \"answer-passages\" are retrieved.. An \"answer-passage\" is a passage which is either answer-providing or \"answer-indicative,\" i.e., it permits inferring that the document containing it is answer-providing.. In most cases answer-sentences, i.e., single-sentence answer-passages, are retrieved.. This has great advantages for screening retrieval output.. Two new automatic procedures for measuring closeness of relation between clue words in a sentence are described.. One approximates syntactic closeness by counting the number of intervening \"syntactic joints\" (roughly speaking, prepositions, conjunctions and punctuation marks) between successive clue words.. The other measure uses word proximity in a new way.. The two measures perform about equally well.. The computer uses \"enclosure\" and \"connector words\" for determining when a multi-sentence passage should be retrieved.. However, no procedure was found in this study for retrieving multi-paragraph answer-passages, which were the only answer-passages occurring in 6% of the papers.. In a test of the techniques they failed to retrieve two answer-providing documents (7% of those to be retrieved) because of one multi-paragraph answer-passage and one complete failure of clue word selection.. For the other answer-providing documents they retrieved at all recall levels with greater precision than SMART, which has produced the best previously reported recall-precision results.. The retrieval questions (mostly from real users) and documents used in this study were from the field of information science.. The results of the study are surprisingly good for retrieval in such a \"soft science,\" and it is reasonable to hope that in less \"soft\" sciences and technologies the techniques described will work even better.. On this basis a dissemination and retrieval system of the near future is predicted.. \n",
      "\n",
      "Rapid Structure Searches via Permuted Chemical Line-Notations. The Wiswesser chemical line-notation is an unique and unambiguous method of representing chemical structures by a linear series of letters, numbers, ampersands, and hyphens. These symbols are meaningful to chemists familiar with the notation and can be processed by automatic data processing (ADP) equipment. The uniqueness of the line-notation permits the use of alphanumerically arranged lists of notations for dictionary-type searches. This ordered arrangement permits the rapid location of a specific compound or a specific class of ring compounds other than benzenoid. \n",
      "\n",
      "A Chemical Structure Storage and Search System Developed at Du Pont. As early as 1961, we in the engineering Department of Du Pont recognized the need for a better system for recording chemical structure information for storage and subsequent retrieval. We believed that current methods and the then current development of notation systems would not completely serve our chemists' long range chemical identification needs. Accordingly, we studied and then developed a chemical structure storage and search system. Huber gave a good review of the various approaches and applications. To use his terminology, our system is topological coding. Our initial investigation led to singling out the following needs for such a system. \n",
      "\n",
      "Installation and Operation of a Registry for Chemical Compounds. Since 1958 the Chemical Abstracts Service has been working toward establishing a computer-based system for handling chemical information. Briefly, the concept of the CAS system consists of sets of special subject files in the following categories: (1) physical properties, (2) chemical reactivities, (3) biochemical activities, and (4) applications. With the importance of compounds in correlation studies, and the need to interrelate compounds and the huge collections of chemical and other data, a highly developed subsystem, called the Registry System, for handling compounds must be the first step in the actual operation of an over-all computer-based service. The Registry System will include files of compounds interconnected with files of associated data that permit identifying the compounds and retrieving them from the files. \n",
      "\n",
      "Experience with the Mechanized Chemical and Biological Information Retrieval System. New computer methods have been developed in associations with the drug development programs of the Walter Reed Army Institute of Research. Experiences with these systems are recounted. Special input devices and computer programming have been developed for the input and retrieval of conventional chemical structural diagrams. The costs, operation, and the advantages of this system are discussed. Associated files of biological properties and inventory control information have been created, which are searchable. The methods used in creating consolidated listings of selected chemical compounds and associated biological data are discussed. \n",
      "\n",
      "Design and Operation of a Computer Search Center for Chemical Information. The objective of the Computer Search Center (CSC) of the Information Sciences section of IIT Research Institute (IITRI) is to provide a link between a wide variety of users and the rapidly expanding information resources in machine- readable form. Because none of the available computer search programs met the criteria of the center, and because of the need to handle a variety of data bases, new general purpose computer programs were written, and a tape format was developed so that a wide variety of data bases can be searched by the same computer program. The center was designed to provide current awareness and retrospective search services from both document-type and data-type computerized data files. The desire to develop transferable programs for use at many installations prompted the adoption of the machine-independent compiler language PL/1 and the use of IBM 360 series computers. The objective of education and training led to the development of a \"Search Manual\" for profile preparation, the development of a workbook in \"Modern Techniques in Chemical Information,\" the teaching of a new academic course, and the presentation of seminars. \n",
      "\n",
      "Interactive Searching of Chemical Files and Structural Diagram Generation from Wiswesser Line Notation. An interactive search and retrieval system for Weswesser Line Notation (WLN) has been implemented.. The system employs bit screens, which are useful for filtering a file.. The user can graphically specify a search request structure and immediately receive graphic information as the result of the search.. Four Fortran IV programs were developed to prepare bit screens for WLN files, input the search request to generate the WLN, iteratively search the WLN bit screen file, and generate a two-dimensional representation of the chemical structure directly from the WLN.. \n",
      "\n",
      "Strategic Considerations in the Design of a Screening System for Substructure Searches of Chemical Structure Files. . Cowell, J. Lynch, M.F. McLure, A.H. Town, W.G. Yapp, A.M. A major problem in the design of screening systems for substructure searches of chemical structure files is the development of a methodology for selection of an optimal set of structural characteristics to act as screens. The set chosen for a particular application will depend on the characteristics of the collection, as well as on its size and growth rate. A strategy which takes account of the disparate frequencies of the various species of fragments in a data-base by use of differential, and, in part, hierarchical levels of description is detailed. The distributions of a variety of structural characteristics, including bond-centered, atom-centered, and ring fragments in a 30,000-compound sample of the Chemical Abstracts Service Registry System are summarized. Implementation of the approach, using primarily bond-centered fragments, by means of simple and highly efficient computer programs, is detailed. \n",
      "\n",
      "Use of the IUPAC Notation in Computer Processing of Information on Chemical Structures. A computer-operated storage and retrieval system for chemical structures based on the use of the IUPAC notation has been in operation at Shell Research Limited, Sittingbourne, Kent, England, since 1965, involving a file of nearly 50,000 compounds. Use of the IUPAC cipher has proved advantageous as regards speed and cost of both input and searching. For most searches, scanning of the information explicit in the cipher has proved adequate. Our computer programs also enable conversion of ciphers into atom- connection tables and generation of fragmentation codes. The integrated use of these facilities and their merits relative to other approaches are discussed. \n",
      "\n",
      "The Chemical Abstracts Service Chemical Registry System. I. General Design. The Chemical Abstracts Service (CAS) Chemical Registry System is a computer- based system that uniquely identifies chemical substances on the basis of composition and structure. Since initial operation in 1964 as a stand-alone input, storage, and retrieval system for structural representations of organic chemical compounds, the scope of the CAS Registry System has steadily increased to include all types of chemical substances and the entire system has been integrated into CAS indexing operations. The third refinement of this system, Registry III, which has been in operation for over a year, involves major changes in Registry recods but no change in the basic algorithmic techniques for registering chemical substances. The previous format for listing atoms and bonds has been modified so that each ring system is now separately identified, and this ring-system identifier is used in the record for each substance that contains that ring. These modifications support CAS nomenclature derivation and also a computer-based structure output system. The general design of Registry III, which involves a structure record of cyclic and acyclic segments, is presented. \n",
      "\n",
      "A Selective Current-Awareness System Using Engineering Index's Plastics Data Base. II. Performance. The operational performance over a 17-month period of the previously described selective dissemination system is presented. Of the 21,000 notifications sent to about 20 users, 91% were evaluated; of these, 14% were of \"Document-Ordered Interest,\" 48% were \"Of Interest,\" 27% were \"Marginal,\" and 11% were \"Of No Interest.\" Recall data obtained from about half the users over a period of eight months show the precision- factor/recall-factor products are generally greater than 0.5. The effect of iterative profile adjustments on precision-recall performance is discussed. A comparison made with four other SDI systems shows a relatively high level of performance for this system. \n",
      "\n",
      "Evaluation of an SDI Service Based on the Index Chemicus Registry System. The Index Chemicus Registry System (ICRS) is the machine-readable equivalent of Current Abstracts in Chemistry & Index Chemicus (CAC & IC). In an earlier paper, we described the development of an experimental selective-dissemination-of-information (SDI) service based on these tapes. A detailed description of the techniques of profile construction for searching a Wiswesser Line Notation (WLN) structure file is given in this earlier paper. The present paper describes the evaluation of the SDI service in terms both of quantitative measures of retrieval performance, coverage and currency, and also of user reactions to the service, as expressed in their replies to a questionnaire. Failure analysis techniques were used to identify the reasons for retrieval failures and possible methods for improving retrieval performance. A fuller description of the evaluation has been published in report form. \n",
      "\n",
      "Profiling, the Key to Successful Information retrieval. A major tool employed to enter an information source is the search profile.. The development of an adequate profile depends upon the aids supplied by the data bases.. These aids vary in their content and depth and their proper use is essential for relevant information retrieval.. The data bases examined are CA Condensates, Index Medicus, and BA data bases.. Several searches are presented with a study of their comparative profiles.. \n",
      "\n",
      "Substructure Searching of Computer-Readable Chemical Abstracts Service Ninth Collective Index Nomenclature Files. The increasing availability of computer-readable files of chemical nomenclature and of programs for text searching has led to the development of methods for performing substructure searches in which CA nomenclature terms are used as search terms. Substructure searches on CA Index nomenclature can often result in very high recall relative to topological searches, as is shown by experimental results achieved on a variety of searches. Many data bases which contain CA Index nomenclature also contain nonsubstance data. Thus, searching of substance and nonsubstance data can often be done within a single search of a file with both high recall and relevancy. Profile construction aids prepared by CAS make it possible for persons without sophisticated nomenclature backgrounds to construct nomenclature profiles for many questions. \n",
      "\n",
      "Searching CA Condensates On-Line vs. the CA Keyword Indexes. A study was conducted to compare the comprehensiveness of searches performed using Systems Development Corporation's (SDC) Chemcon data base and keyword indexes of Chemical Abstracts.. It was concluded that, in most cases, a computer search yielded at least as many relevant references as did a manual search.. However, in the case of very general search questions, results from manual searches were much more satisfactory.. \n",
      "\n",
      "Data Retrieval Systems: Specifics and Problems. The essential differences between data retrieval system and document retrieval systems are considered.. The notion of \"fact\" is discussed, analyzing the influence of the definition adopted on the structure of a data retrieval system.. A proposition is advanced that a factographic JRS is a rudimentary but indispensable form on the way to a logical information system.. The latter type of system by a capability for automatic analysis of input data and synthesis of new information.. The problem of the information retrieval language for data retrieval system is discussed, as is its machine organization, intricately tied up with the specifics and functions of a system of that kind.. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "qid, q = queries[1]\n",
    "print(q, '\\n')\n",
    "doc_index = dict(documents)\n",
    "for doc_id in ground_truth[qid]:\n",
    "    print(doc_index[doc_id], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39337466",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a06df58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f7ea073",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, doc = documents[0]\n",
    "tokens = word_tokenize(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6530bb4",
   "metadata": {},
   "source": [
    "## Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdc4efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ba6a53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1af091570d8434fbc1c6b523e3a886c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1460 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TFidx = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for doc_id, doc_text in tqdm(documents):\n",
    "    for token in word_tokenize(doc_text):\n",
    "        TFidx[token][doc_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1c3dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF = pd.DataFrame(TFidx).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "135153e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>18</th>\n",
       "      <th>Editions</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>Dewey</th>\n",
       "      <th>Decimal</th>\n",
       "      <th>Classifications</th>\n",
       "      <th>.</th>\n",
       "      <th>The</th>\n",
       "      <th>present</th>\n",
       "      <th>...</th>\n",
       "      <th>subsidization</th>\n",
       "      <th>morn</th>\n",
       "      <th>religiously</th>\n",
       "      <th>prompts</th>\n",
       "      <th>soundness</th>\n",
       "      <th>supposition</th>\n",
       "      <th>Thought</th>\n",
       "      <th>abstraction</th>\n",
       "      <th>certificates</th>\n",
       "      <th>100-150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13455 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      18  Editions    of   the  Dewey  Decimal  Classifications    .  The  \\\n",
       "1    1.0       1.0   7.0   8.0    2.0      2.0              1.0  5.0  2.0   \n",
       "197  1.0       0.0  20.0  18.0    0.0      0.0              0.0  1.0  4.0   \n",
       "354  1.0       0.0  11.0   9.0    2.0      2.0              0.0  8.0  3.0   \n",
       "581  1.0       0.0  16.0   9.0    0.0      0.0              0.0  5.0  6.0   \n",
       "609  1.0       0.0   3.0   4.0    0.0      0.0              0.0  1.0  0.0   \n",
       "\n",
       "     present  ...  subsidization  morn  religiously  prompts  soundness  \\\n",
       "1        1.0  ...            0.0   0.0          0.0      0.0        0.0   \n",
       "197      0.0  ...            0.0   0.0          0.0      0.0        0.0   \n",
       "354      0.0  ...            0.0   0.0          0.0      0.0        0.0   \n",
       "581      0.0  ...            0.0   0.0          0.0      0.0        0.0   \n",
       "609      0.0  ...            0.0   0.0          0.0      0.0        0.0   \n",
       "\n",
       "     supposition  Thought  abstraction  certificates  100-150  \n",
       "1            0.0      0.0          0.0           0.0      0.0  \n",
       "197          0.0      0.0          0.0           0.0      0.0  \n",
       "354          0.0      0.0          0.0           0.0      0.0  \n",
       "581          0.0      0.0          0.0           0.0      0.0  \n",
       "609          0.0      0.0          0.0           0.0      0.0  \n",
       "\n",
       "[5 rows x 13455 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4f2f1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 13455)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f68f234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can actually pertinent data, as opposed to references or entire articles themselves, be retrieved automatically in response to information requests?'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, query_text = queries[1]\n",
    "query_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "793c2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tokens = word_tokenize(query_text)\n",
    "vocabulary = list(TF.columns.values)\n",
    "q = np.zeros(TF.shape[1])\n",
    "for token in query_tokens:\n",
    "    try:\n",
    "        i = vocabulary.index(token)\n",
    "        q[i] += 1\n",
    "    except IndexError:\n",
    "        pass\n",
    "q = q / q.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2afe40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NormTF = (TF.T / TF.max(axis=1)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f19e798",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "447768ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59fb3ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = cosine_similarity(q.reshape(1, -1), NormTF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bdd8b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1460)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0630a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = pd.DataFrame(match, columns=NormTF.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f5cc9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = M.loc[0].sort_values(ascending=False).head(2000).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8c3f2fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can actually pertinent data, as opposed to references or entire articles themselves, be retrieved automatically in response to information requests? \n",
      "\n",
      "Rules for a Dictionary Catalog. No code of cataloguing could be adopted in all points by everyone, because the libraries for study and the libraries for reading have different objects, and those which combine the two do so in different proportions. Again, the preparation of a catalogue must vary as it is to be manuscript or printed, and, if the latter, as it is to be merely an index to the library, giving in the shortest possible compass clues by which the public can find books, or is to attempt to furnish more information on various points, or finally is to be made with a certain regard to what may be called style. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(query_text, '\\n')\n",
    "for answer in answers:\n",
    "    print(doc_index[answer], '\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74a8e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = set(list(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f2f472f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = set(list(ground_truth[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f00fe152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.031506849315068496\n",
      "Recall 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Precision', len(R.intersection(E)) / len(R))\n",
    "print('Recall', len(R.intersection(E)) / len(E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6f73cb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = np.zeros((2, 2))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f932fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_id, _ in documents:\n",
    "    if doc_id in R and doc_id in E:\n",
    "        cm[0,0] += 1\n",
    "    elif doc_id in R and not doc_id in E:\n",
    "        cm[0,1] += 1\n",
    "    elif not doc_id in R and doc_id in E:\n",
    "        cm[1,0] += 1\n",
    "    else:\n",
    "        cm[1,1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4c953deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  46., 1414.],\n",
       "       [   0.,    0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e2d5e81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031506849315068496"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[0,0] / cm[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "82f38562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[0,0] / cm[:,0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ce6f07",
   "metadata": {},
   "source": [
    "## Understand the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d1db0d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "18 Editions of the Dewey Decimal Classifications. The present study is a history of the DEWEY Decimal Classification. The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed. In spite of the DDC's long and healthy life, however, its full story has never been told. There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad.\n"
     ]
    }
   ],
   "source": [
    "doc_id, doc = documents[0]\n",
    "print(doc_id)\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6eb40dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the        1.000\n",
       "of         0.875\n",
       ",          0.625\n",
       ".          0.625\n",
       "in         0.375\n",
       "and        0.375\n",
       "history    0.250\n",
       "has        0.250\n",
       "that       0.250\n",
       "DDC        0.250\n",
       "edition    0.250\n",
       "first      0.250\n",
       "this       0.250\n",
       "to         0.250\n",
       "is         0.250\n",
       "The        0.250\n",
       "been       0.250\n",
       "Decimal    0.250\n",
       "Dewey      0.250\n",
       "a          0.250\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NormTF.loc[1].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5105caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "37ae09db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc89be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crike",
   "language": "python",
   "name": "crike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
