{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool # waning: it will raise exception if executed in notebook\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text from sentences\n",
    "Example of sentences are taken from `20 newsgroup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_20newsgroups(data_home=\"/Users/flint/Data/sklearn/\", subset='train', \n",
    "                           remove=('headers', 'footers', 'quotes'),\n",
    "                           categories=['rec.sport.baseball'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I have lived in the Boston area for 15 years now.  They have been talking\n",
      "about a new Boston Garden (hockey/basketball) since I've lived here.  One\n",
      "day the \"last hurdle\" has been overcome, and the next day there's a new\n",
      "hurdle.  Fans have been grumbling about Foxboro Stadium (or whatever it's\n",
      "called this year) for nearly as long, but there are only preliminary\n",
      "proposals for a new stadium.  Local politics prevents anything from being\n",
      "done in a timely fashion.  There will not be a new ballpark in my\n",
      "lifetime.\n",
      "['rec.sport.baseball']\n"
     ]
    }
   ],
   "source": [
    "print(train.data[2])\n",
    "print(train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for doc in train.data:\n",
    "    for s in nltk.tokenize.sent_tokenize(doc):\n",
    "        sentences.append(s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "so you want to decrease players' salaries?\n"
     ]
    }
   ],
   "source": [
    "print(sentences[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding\n",
    "Many current NLP systems and techniques treat words as atomic\n",
    "units - there is no notion of similarity between words, as these are\n",
    "represented as indices in a vocabulary <br/>\n",
    "<i>(Mikolov et al., 2013).</i>\n",
    "\n",
    "<br/>\n",
    "Suppose that the number of different words in the vocabulary (the vocabulary size) is $V$. To obtain the one-hot vector representation for any word with index $i$, we create a length-$V$ vector with all $0$s and set the element at position $i$ to $1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = sentences\n",
    "V = set()\n",
    "for sentence in corpus:\n",
    "    for word in word_tokenize(sentence):\n",
    "        V.add(word)\n",
    "V = list(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 8723\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "print('Vocab size:', len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7354"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.index('suppose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(V, word) -> np.array:\n",
    "    \"\"\"Return one-hot encoding\n",
    "    \n",
    "    Args:\n",
    "        V(list): Vocabulary, i.e., word list.\n",
    "        word: word in the vocabulary.\n",
    "    Returns:\n",
    "        one_hot_encoding(np.array)\n",
    "    \"\"\"\n",
    "    vec = np.zeros(len(V))\n",
    "    vec[V.index(word)] = 1.0\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot Encoding: next: [0. 1. 0. ... 0. 0. 0.]\n",
      "One-hot Encoding: still: [0. 0. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "word1, word2 = V[1], V[2]\n",
    "vec1, vec2 = one_hot_encoding(V, word1), one_hot_encoding(V, word2)\n",
    "\n",
    "print(f\"One-hot Encoding: {word1}:\", vec1)\n",
    "print(f\"One-hot Encoding: {word2}:\", vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoded vectors are orthonormal. <br/>\n",
    "\n",
    "For vectors $x, y \\in \\mathbb{R}^V$ with $x\\ne y$, their _similarity_ is always $0$. \n",
    "\n",
    "On the contrary, for vectors $x, y \\in \\mathbb{R}^V$ with $x = y$, their _similarity_ is always $1$.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{x^T \\ y}{\\|x\\| \\ \\|y\\|} \\in \\{0, 1\\}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1: np.array, vec2: np.array) -> float:\n",
    "    \"\"\"Return cosine similarity between two vectors\n",
    "    \n",
    "    Args:\n",
    "        vec1(np.array): vector 1.\n",
    "        vec2(np.array): vector 2.\n",
    "    Returns:\n",
    "        cosine similarity\n",
    "    \"\"\"\n",
    "    return np.dot(vec1, vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiped</th>\n",
       "      <th>next</th>\n",
       "      <th>still</th>\n",
       "      <th>power</th>\n",
       "      <th>0.295</th>\n",
       "      <th>again</th>\n",
       "      <th>fox</th>\n",
       "      <th>mound</th>\n",
       "      <th>bodies</th>\n",
       "      <th>yankovic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wiped</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>still</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.295</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>again</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mound</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodies</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yankovic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          wiped  next  still  power  0.295  again  fox  mound  bodies  \\\n",
       "wiped       1.0   0.0    0.0    0.0    0.0    0.0  0.0    0.0     0.0   \n",
       "next        0.0   1.0    0.0    0.0    0.0    0.0  0.0    0.0     0.0   \n",
       "still       0.0   0.0    1.0    0.0    0.0    0.0  0.0    0.0     0.0   \n",
       "power       0.0   0.0    0.0    1.0    0.0    0.0  0.0    0.0     0.0   \n",
       "0.295       0.0   0.0    0.0    0.0    1.0    0.0  0.0    0.0     0.0   \n",
       "again       0.0   0.0    0.0    0.0    0.0    1.0  0.0    0.0     0.0   \n",
       "fox         0.0   0.0    0.0    0.0    0.0    0.0  1.0    0.0     0.0   \n",
       "mound       0.0   0.0    0.0    0.0    0.0    0.0  0.0    1.0     0.0   \n",
       "bodies      0.0   0.0    0.0    0.0    0.0    0.0  0.0    0.0     1.0   \n",
       "yankovic    0.0   0.0    0.0    0.0    0.0    0.0  0.0    0.0     0.0   \n",
       "\n",
       "          yankovic  \n",
       "wiped          0.0  \n",
       "next           0.0  \n",
       "still          0.0  \n",
       "power          0.0  \n",
       "0.295          0.0  \n",
       "again          0.0  \n",
       "fox            0.0  \n",
       "mound          0.0  \n",
       "bodies         0.0  \n",
       "yankovic       1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example \n",
    "example_words = [V[i] for i in range(10)]\n",
    "vectors = [one_hot_encoding(V, w) for w in example_words]\n",
    "sigma = dict([(w, {}) for w in example_words])\n",
    "for i, w1 in enumerate(example_words):\n",
    "    for j, w2 in enumerate(example_words):\n",
    "        sigma[w1][w2] = cosine_similarity(vectors[i], vectors[j])\n",
    "pd.DataFrame(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_play = one_hot_encoding(V, 'play')\n",
    "v_game = one_hot_encoding(V, 'game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(v_play, v_game)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec: semantic word representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec maps each word to a **low-dimensional continuous vector**, in a way that words that have similar meaning have similar representations.\n",
    "\t\n",
    "Word2Vec is based on a simple but efficient *feed-forward* neural architecture which is trained with language modeling objective. \n",
    "\n",
    "Word2Vec consists of two different architectures: __Skip-gram__ and __Continuous Bag-of-Words__ (CBOW)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [[x for x in word_tokenize(t) if x not in sw and x not in string.punctuation] for t in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finally, i throw all this into a a formula i call defensive contribution, or\n",
      "dcon :->.\n",
      "\n",
      "['finally', 'throw', 'formula', 'call', 'defensive', 'contribution', 'dcon']\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "print(corpus[20], end='\\n\\n')\n",
    "print(tokens[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(token_batches, min_count=15) -> dict:\n",
    "    '''Build vocabulary and filter rare words.\n",
    "    \n",
    "    Args:\n",
    "        token_batches(list): Token batches.\n",
    "        min_count(int, optional, default=15): Minimum frequency threshold.\n",
    "    Returns:\n",
    "        vocab(dict): Dictionary containing token and frequencies.\n",
    "    '''\n",
    "    \n",
    "    counts = Counter([token for tokens in token_batches for token in tokens])\n",
    "    vocab = list(counts.keys())\n",
    "    vocab = {k:v for k, v in counts.items() if v > min_count} # Filtering\n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocab(tokens, min_count=10)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824 \n",
      "\n",
      "  ...,\n",
      " '7': 76,\n",
      " '70': 12,\n",
      " '8': 36,\n",
      " '80': 14,\n",
      " '89': 11,\n",
      " '9': 47,\n",
      " '92': 12,\n",
      "  ...\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "print(vocab_size, '\\n')\n",
    "print(f\"  ..., {str({k: vocab[k] for k in sorted(vocab)[100:107]})[1:-1]},  ...\".replace(',', ',\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(vocab: list) -> tuple:\n",
    "    '''\n",
    "    Generate mapping dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        vocab(dict): Dictionary containing token and frequencies.\n",
    "    Returns:\n",
    "        token_to_id(dict): Mapping token -> id. \n",
    "        id_to_token(dict): Mapping id -> token. \n",
    "    '''\n",
    "    token_to_id = dict()\n",
    "    id_to_token = dict()\n",
    "\n",
    "    for i, token in enumerate(vocab):\n",
    "        token_to_id[token] = i\n",
    "        id_to_token[i] = token\n",
    "\n",
    "    return token_to_id, id_to_token\n",
    "\n",
    "token_to_id, id_to_token = mapping(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345 : pitch\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "print(token_to_id['pitch'],':', id_to_token[token_to_id['pitch']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(token_id, vocab_size) -> np.array:\n",
    "    '''Return one-hot encoding\n",
    "    \n",
    "    Args:\n",
    "        token_id(int): Token id.\n",
    "        vocab_size(int): Number of token in the dictionary.\n",
    "    Returns:\n",
    "        one_hot_encoding(np.array)\n",
    "    '''\n",
    "    vec = np.zeros(vocab_size)\n",
    "    vec[token_id] = 1.0\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_samples(tokens: list, token_to_id: dict, id_to_token: dict, window:int=3) -> list:\n",
    "    '''Generate training examples for word2vec algorithm.\n",
    "    \n",
    "    Args:\n",
    "        tokens(list): Batch of tokens.\n",
    "        token_to_id(dict): Mapping token -> id.\n",
    "        id_to_token(dict): Mapping id -> token.\n",
    "        window(int, optional, default=5): Number of left and right context words for each target word.\n",
    "    \n",
    "    Returns:\n",
    "        examples(list).\n",
    "    '''\n",
    "    \n",
    "    examples = list()\n",
    "    n_tokens = len(tokens)\n",
    "\n",
    "    for i in range(n_tokens):\n",
    "        if tokens[i] not in token_to_id: continue\n",
    "            \n",
    "        target = token_to_id[tokens[i]]\n",
    "        new_examples = list()\n",
    "\n",
    "        for j in range(1, window+2):\n",
    "            # right context\n",
    "            if i + j < len(tokens):\n",
    "                if not tokens[i + j] in token_to_id: continue\n",
    "                context = token_to_id[tokens[i + j]]\n",
    "                new_examples.append((target, context))\n",
    "                \n",
    "            # left context\n",
    "            if i - j >= 0:\n",
    "                if not tokens[i - j] in token_to_id: continue\n",
    "                context = token_to_id[tokens[i - j]]\n",
    "                new_examples.append((target, context))\n",
    "            \n",
    "        examples.append(new_examples)\n",
    "\n",
    "    return np.asarray(examples, dtype=object)\n",
    "\n",
    "def generate_multiple_training_samples(token_batches: list, token_to_id: dict, id_to_token: dict, window:int=3, \n",
    "                                   workers:int = 10):\n",
    "    '''Generate training example for word2vec algorithm.\n",
    "    \n",
    "    Args:\n",
    "        tokens(list): Batch of tokens.\n",
    "        token_to_id(dict): Mapping token -> id.\n",
    "        id_to_token(dict): Mapping id -> token.\n",
    "        vocab_size(int): Number of token in the dictionary.\n",
    "        window(int, optional, default=5): Number of left and right context words for each target word.'''\n",
    "    \n",
    "    \n",
    "    with Pool(processes=workers) as p:\n",
    "         res = p.starmap(generate_training_samples, [(tokens, token_to_id, id_to_token, window) for tokens in token_batches])\n",
    "    \n",
    "    return res\n",
    "\n",
    "window = 3\n",
    "#samples = generate_multiple_training_samples(tokens, token_to_id, id_to_token, window=3, workers=10) # not working in notebook\n",
    "samples = [generate_training_samples(t, token_to_id, id_to_token, window=window) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['finally', 'throw', 'formula', 'call', 'defensive', 'contribution', 'dcon']\n",
      "[('finally', 'throw'), ('finally', 'call'), ('finally', 'defensive')]\n",
      "[('throw', 'call'), ('throw', 'defensive')]\n",
      "[('call', 'defensive')]\n",
      "[('defensive', 'throw'), ('defensive', 'finally')]\n"
     ]
    }
   ],
   "source": [
    "print(tokens[20])\n",
    "for e in generate_training_samples(tokens[20], token_to_id, id_to_token):\n",
    "    print([(id_to_token[a], id_to_token[b]) for a, b in e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color(text, color='#990000'):\n",
    "    return \"<span style='color: {};'>{}</span>\".format(color, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finally throw formula call defensive contribution dcon\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.   <span style='color: #000099;'></span> <span style='color: #990000;'>finally</span> <span style='color: #000099;'>throw formula call</span> defensive contribution dcon"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1.   <span style='color: #000099;'>finally</span> <span style='color: #990000;'>throw</span> <span style='color: #000099;'>formula call defensive</span> contribution dcon"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2.   <span style='color: #000099;'>finally throw</span> <span style='color: #990000;'>formula</span> <span style='color: #000099;'>call defensive contribution</span> dcon"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3.   <span style='color: #000099;'>finally throw formula</span> <span style='color: #990000;'>call</span> <span style='color: #000099;'>defensive contribution dcon</span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4.  finally <span style='color: #000099;'>throw formula call</span> <span style='color: #990000;'>defensive</span> <span style='color: #000099;'>contribution dcon</span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5.  finally throw <span style='color: #000099;'>formula call defensive</span> <span style='color: #990000;'>contribution</span> <span style='color: #000099;'>dcon</span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Example (id, id) - 4:\n",
      "[(71, 72), (71, 73), (71, 45)] \n",
      "\n",
      "\n",
      "Training Example (word, word) - 4:\n",
      "[['finally' 'throw']\n",
      " ['finally' 'call']\n",
      " ['finally' 'defensive']] \n",
      "\n",
      "\n",
      "Training Example (id, id) - 4:\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "example = 20\n",
    "\n",
    "print(\" \".join(tokens[example]), end='\\n')\n",
    "\n",
    "for i in range(len(tokens[example])):\n",
    "    if i>5: break\n",
    "    before = \" \".join([t for j, t in enumerate(tokens[example]) if j < i-window])\n",
    "    context_l = color(\" \".join(tokens[example][max(i-window,0):i]), '#000099')\n",
    "    target = color(tokens[example][i], '#990000')\n",
    "    context_r = color(\" \".join(tokens[example][i+1:i+window+1]), '#000099')\n",
    "    after = \" \".join(tokens[example][i+window+1:])\n",
    "    html = '{}. '.format(i) + \" \" + before + \" \" + context_l + \" \" + target + \" \" + context_r + \" \" + after\n",
    "    display(HTML(html))\n",
    "\n",
    "training_samples = generate_training_samples(tokens[example], token_to_id, id_to_token, window)[0]\n",
    "\n",
    "print('Training Example (id, id) - 4:')\n",
    "print(str(training_samples), '\\n\\n')\n",
    "\n",
    "print('Training Example (word, word) - 4:')\n",
    "print(str(np.array([[id_to_token[i[0]], id_to_token[i[1]]] for i in training_samples])), '\\n\\n')\n",
    "\n",
    "print('Training Example (id, id) - 4:')\n",
    "print(str(np.array([[one_hot_encoding(i[0], vocab_size), \n",
    "                     one_hot_encoding(i[1], vocab_size)] \n",
    "                    for i in training_samples])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec: CBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_input to hidden_ \n",
    "\n",
    "Input layer: $\\mathbf{x} \\in \\mathbb{R}^{V}$ <br/>\n",
    " \\begin{eqnarray*}\n",
    "\t        \\bar{\\mathbf{x}} = \\frac{1}{C}\\sum^C_{c=1} \\mathbf{x^{(c)}}\n",
    "\t    \\end{eqnarray*}\n",
    "Weights: $W \\in \\mathbb{R}^{V\\times N}$, randomly initialized<br/><br/>\n",
    "Hidden layer: $\\mathbf{h} \\in \\mathbb{R}^{N}$\n",
    "\\begin{eqnarray}\n",
    "\\mathbf{h} = \\frac{1}{C} \\mathbf{W}^T \\sum^C_{c=1}  x^{(c)} = \\mathbf{W}^T \\bar{\\mathbf{x}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Activation function: $\\mathbb{I}\\text{dentity}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_hidden to output_\n",
    "\n",
    "Weights: $\\mathbf{W'} \\in \\mathbb{R}^{N\\times V}$, randomly initialized\n",
    "\n",
    "Output layer: $\\mathbf{u} \\in \\mathbb{R}^V$\n",
    "\\begin{eqnarray}\n",
    "\\mathbf{u} = \\mathbf{W}'^T \\mathbf{h} = \\frac{1}{C} \\sum^C_{c=1} \\mathbf{W'}^T \\mathbf{W}^T x^{(c)} = \\mathbf{W'}^T \\mathbf{W}^T \\bar{\\mathbf{x}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Activation function: $\\mathbb{S}\\text{oftmax}$\n",
    "\\begin{eqnarray}\n",
    "\\mathbf{y} = \\mathbb{S}\\text{oftmax}(\\mathbf{u}) = \\mathbb{S}\\text{oftmax}(\\mathbf{W'}^T\\mathbf{W}^T \\bar{\\mathbf{x}})\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Loss Function_\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathcal{L} &=& -\\log \\mathbb{P}(w_O| w_{c,1}, w_{c,2}, ..., w_{c,C})\\\\\n",
    "&=& \\max \\log y_{j^*} \\nonumber\\\\\n",
    "\t\t            &=& \\max \\log \\left(\\frac{\\exp(u_{j^*})}{\\sum^V_{j'=1} \\exp(u_{j'})} \\right) \\nonumber\\\\\n",
    "\t\t            &=& \\max u_{j^*} - \\log \\sum^V_{j' = 1} \\exp(u_{j'}) \\nonumber\\\\\n",
    "\t\t            &=& \\min \\log \\sum^V_{j' = 1} \\exp(u_{j'}) - u_{j^*}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Gradient descent_\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\t    \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W'}} = (\\mathbf{W}^T \\bar{\\mathbf{x}}) \\otimes E \n",
    "\t    \\end{eqnarray}\n",
    "\t    \\begin{eqnarray} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}} = \\bar{\\mathbf{x}} \\otimes (\\mathbf{W'} E) \n",
    "\t    \\end{eqnarray}\n",
    "        \n",
    "_Backpropagation_\n",
    "\\begin{eqnarray}\n",
    "\\mathbf{v}_{W}^{(new)} &=&  \\mathbf{v}_{W}^{(old)} - \\eta \\cdot \\frac{\\partial \\mathcal{L}}{\\partial W}\n",
    "\\end{eqnarray}\n",
    "                \n",
    "\\begin{eqnarray}\n",
    "    \\mathbf{v}_{W'}^{(new)} &=&  \\mathbf{v}_{W'}^{(old)} - \\eta \\cdot \\frac{\\partial \\mathcal{L}}{\\partial W'}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x.astype(float)\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec:\n",
    "    \n",
    "    def __init__(self, sequences:list, vector_size=100):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sequences(list): Token batches.\n",
    "        \"\"\"\n",
    "        self.sequences = sequences\n",
    "        self.vector_size = vector_size\n",
    "    \n",
    "    def __init_network__(self):\n",
    "        \"\"\"Initialize the network\"\"\"\n",
    "        \n",
    "        self.model = {\n",
    "            \"W\": np.random.uniform(-1, 1, (self.vocab_size, self.vector_size)),  # input to hidden\n",
    "            \"W'\": np.random.uniform(-1, 1, (self.vector_size, self.vocab_size)) # hidden to output\n",
    "        }\n",
    "        return self.model\n",
    "    \n",
    "    def build_vocab(self, min_count=15) -> dict:\n",
    "        \"\"\"Build vocabulary and filter rare words.\n",
    "\n",
    "        Args:\n",
    "            min_count(int, optional, default=15): Minimum frequency threshold.\n",
    "        Returns:\n",
    "            vocab(dict): Dictionary containing token and frequencies.\n",
    "        \"\"\"\n",
    "\n",
    "        counts = Counter([token for sequence in self.sequences for token in sequence])\n",
    "        vocab = list(counts.keys())\n",
    "        vocab = {k:v for k, v in counts.items() if v > min_count} # Filtering\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.vocab_size = len(vocab)\n",
    "        \n",
    "        self.token_to_id, self.id_to_token = self.__mapping__()\n",
    "        \n",
    "        return vocab\n",
    "    \n",
    "    def one_hot_encoding(self, token_id) -> np.array:\n",
    "        '''Return one-hot encoding\n",
    "\n",
    "        Args:\n",
    "            token_id(int): Token id.\n",
    "        Returns:\n",
    "            one_hot_encoding(np.array)\n",
    "        '''\n",
    "        vec = np.zeros(self.vocab_size)\n",
    "        vec[token_id] = 1.0\n",
    "        return vec\n",
    "    \n",
    "    def __mapping__(self) -> tuple:\n",
    "        '''\n",
    "        Generate mapping dictionaries.\n",
    "\n",
    "        Returns:\n",
    "            token_to_id(dict): Mapping token -> id. \n",
    "            id_to_token(dict): Mapping id -> token. \n",
    "        '''\n",
    "        token_to_id = dict()\n",
    "        id_to_token = dict()\n",
    "\n",
    "        for i, token in enumerate(self.vocab):\n",
    "            token_to_id[token] = i\n",
    "            id_to_token[i] = token\n",
    "        \n",
    "        return token_to_id, id_to_token\n",
    "\n",
    "    def __generate_training_samples__(self, tokens: list, window:int=3) -> list:\n",
    "        '''Generate training examples for word2vec algorithm.\n",
    "\n",
    "        Args:\n",
    "            tokens(list): Batch of tokens.\n",
    "            window(int, optional, default=3): Number of left and right context words for each target word.\n",
    "\n",
    "        Returns:\n",
    "            examples(list).\n",
    "        '''\n",
    "\n",
    "        examples = list()\n",
    "        n_tokens = len(tokens)\n",
    "\n",
    "        for i in range(n_tokens):\n",
    "            if tokens[i] not in self.token_to_id: continue\n",
    "\n",
    "            target = self.token_to_id[tokens[i]]\n",
    "            X, y = list(), np.array(self.one_hot_encoding(target))\n",
    "\n",
    "            for j in range(1, window+2):\n",
    "                # right context\n",
    "                if i + j < len(tokens):\n",
    "                    if not tokens[i + j] in self.token_to_id: continue\n",
    "                    context = self.token_to_id[tokens[i + j]]\n",
    "                    X.append(self.one_hot_encoding(context))\n",
    "\n",
    "                # left context\n",
    "                if i - j >= 0:\n",
    "                    if not tokens[i - j] in self.token_to_id: continue\n",
    "                    context = self.token_to_id[tokens[i - j]]\n",
    "                    X.append(self.one_hot_encoding(context))\n",
    "\n",
    "            examples.append((np.mean(X, axis=0), y))\n",
    "\n",
    "        return np.asarray(examples, dtype=object)\n",
    "\n",
    "    def __build_training_samples__(self, window:int=3, workers:int = 10):\n",
    "        '''Generate training example for word2vec algorithm.\n",
    "\n",
    "        Args:\n",
    "            vocab_size(int): Number of token in the dictionary.\n",
    "            window(int, optional, default=5): Number of left and right context words for each target word.'''\n",
    "\n",
    "\n",
    "        #with Pool(processes=workers) as p:\n",
    "        #     res = p.starmap(self.__generate_training_samples__, [(tokens, window) for tokens in self.sequences])\n",
    "\n",
    "        #return res\n",
    "        for tokens in self.sequences:\n",
    "            for sample in self.__generate_training_samples__(tokens, window=window):\n",
    "                target, context = sample[1], sample[0]\n",
    "                yield target, context\n",
    "    \n",
    "    def __forward_prop__(self, x):\n",
    "    \n",
    "        h = np.dot(self.model['W'].T, x)\n",
    "        u = np.dot(self.model[\"W'\"].T, h)\n",
    "        y_pred = softmax(u)\n",
    "\n",
    "        return y_pred, h, u\n",
    "    \n",
    "    def __backward_prop__(self, y_pred, h, target, context, learning_rate):\n",
    "        total_error = self.__calculate_error__(y_pred, target)\n",
    "        \n",
    "        derivatives = dict()\n",
    "        derivatives[\"∂L/∂W\"] = np.outer(target, np.dot(self.model[\"W'\"], total_error.T))\n",
    "        derivatives[\"∂L/∂W'\"] = np.outer(h, total_error)\n",
    "\n",
    "        # Update weights\n",
    "        self.model[\"W\"] = self.model[\"W\"] - (learning_rate * derivatives[\"∂L/∂W\"])\n",
    "        self.model[\"W'\"] = self.model[\"W'\"] - (learning_rate * derivatives[\"∂L/∂W'\"])\n",
    "\n",
    "    def __calculate_error__(self, y_pred, y):\n",
    "        return y_pred - y\n",
    "        #return np.sum([y_pred - self.one_hot_encoding(index) for index in np.where(context == 1)[0]], axis=0)\n",
    "    \n",
    "    def __calculate_loss__(self, u, target):\n",
    "        u = u.astype(float)\n",
    "        return -u[target==1][0] + np.log(np.sum(np.exp(u)))\n",
    "        #return -u[context==1].sum() + len(np.where(context==1)[0]) *np.log(np.sum(np.exp(u)))\n",
    "    \n",
    "    def train(self, window:int=3, workers:int=10, epochs:int=25, learning_rate:float=0.01):\n",
    "        \n",
    "        self.__init_network__()\n",
    "\n",
    "        #For analysis purposes\n",
    "        epoch_loss = []\n",
    "        weights_1 = []\n",
    "        weights_2 = []\n",
    "\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            loss = 0\n",
    "\n",
    "            for target, context in self.__build_training_samples__(window, workers=10):\n",
    "                y_pred, h, u = self.__forward_prop__(target)\n",
    "                self.__backward_prop__(y_pred, h, target, context, learning_rate)\n",
    "\n",
    "                loss_temp = self.__calculate_loss__(u,target)\n",
    "                loss += loss_temp\n",
    "\n",
    "            epoch_loss.append( loss )\n",
    "            weights_1.append(self.model['W'])\n",
    "            weights_2.append(self.model[\"W'\"])\n",
    "\n",
    "        self.epoch_loss = epoch_loss\n",
    "        return epoch_loss, np.array(weights_1), np.array(weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10a8b0d537849449a9b62051fc0c050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = Word2Vec([x for x in tokens if 'game' in x][:50], vector_size=6)\n",
    "\n",
    "w.build_vocab(min_count=0)\n",
    "\n",
    "# fit parameters\n",
    "_ = w.train(window=3, epochs=25, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game ['three', '5-2', 'daryl', '5-7/12', 'one', 'function', 'coach', 'true', 'cleveland', 'saw'] \n",
      "\n",
      "bat ['chet', 'baylor', 'determines', 'dibble', 'spelled', 'lead', 'media', 'papa', 'even', '9/21'] \n",
      "\n",
      "play ['catcher', '9/28', 'effort', 'people', 'moving', 'ttacs1.ttu.edu', 'vs.', 'pinch', 'read', 'dinger'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "def get_distance_matrix(wordvecs, metric):\n",
    "    dist_matrix = distance.squareform(distance.pdist(wordvecs, metric))\n",
    "    return dist_matrix\n",
    "\n",
    "def get_k_similar_words(word, dist_matrix, token_to_id, id_to_token, k=10):\n",
    "    idx = token_to_id[word]\n",
    "    dists = dist_matrix[idx]\n",
    "    ind = np.argpartition(dists, k)[:k+1]\n",
    "    ind = ind[np.argsort(dists[ind])][1:]\n",
    "    out = [(i, id_to_token[i], dists[i]) for i in ind]\n",
    "    return out\n",
    "\n",
    "sim_matrix = get_distance_matrix(w.model[\"W\"], 'cosine')\n",
    "for word in ['game', 'bat', 'play']:\n",
    "    print(word, [t[1] for t in get_k_similar_words(word, sim_matrix, w.token_to_id, w.id_to_token)], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(495, 6)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.model['W'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = cosine_similarity(w.model['W'], w.model['W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maybe', 'decent', 'comes', '92', 'swing', '70']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id_to_token[i] for i, x in sorted(enumerate(sigma[0]), key=lambda x: -x[1])][:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_game = w.model['W'][token_to_id['game']]\n",
    "v_play = w.model['W'][token_to_id['baseball']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04308703916930066"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(v_game, v_play)/(np.linalg.norm(v_game)*np.linalg.norm(v_play))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe9c882b340>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoBUlEQVR4nO3deXhV5bn+8e+TAcI8hikhhEkRkUECyCjQKuAEVlSos1Yqah16rNWentpjj6ce2ypa5xmrdR5wRkQFZBASZkEhzAkIYZ4DSZ7fH1n0l6qQBELWzt7357r2lbXe9e61n9Vtufd612TujoiIxKa4sAsQEZHwKARERGKYQkBEJIYpBEREYphCQEQkhiWEXUBpGjdu7Onp6WGXISJSZWRlZW129+Sy9I34EEhPTyczMzPsMkREqgwzW1PWvmUaDjKz1Wa2yMzmm1lm0PYXM/vGzBaa2dtmVj9oTzezfUHf+Wb2eIn1dA/Wk21mD5mZlXPbRESkApXnmMAgd+/q7hnB/CSgk7t3BpYBd5bouyLo29XdryvR/hhwLdA+eA09htpFROQYHfWBYXf/xN0LgtlZQOqR+ptZc6Cuu8/y4suUXwBGHO3ni4jIsStrCDjwiZllmdmYH1l+NfBRifnWZjbPzKaYWf+gLQXIKdEnJ2j7ATMbY2aZZpaZl5dXxhJFRKS8ynpguJ+755pZE2CSmX3j7lMBzOw/gQLgpaDvBiDN3beYWXfgHTM7uTxFufuTwJMAGRkZurmRiMhxUqY9AXfPDf5uAt4GegKY2ZXAOcAlwRAP7p7v7luC6SxgBXACkMu/DxmlBm0iIhKSUkPAzGqZWZ1D08CZwGIzGwrcDpzn7ntL9E82s/hgug3FB4BXuvsGYKeZnRacFXQ5MKHCt0hERMqsLMNBTYG3g7M5E4B/uvvHZpYNVKd4eAhgVnAm0ADgbjM7CBQB17n71mBd1wPPAzUoPoZQ8jhChSkoLOKpaavo1aYhp6Y1OB4fISISFSzSnyeQkZHh5b1YbHd+AWfeP4XaSQm8/6v+VEvQ3TFEJHaYWVaJ0/mPKCr/daxdPYF7zj+FZRt38+gX2WGXIyISsaIyBAAGdWjC8K4teOTzbJZt3BV2OSIiESlqQwDgD+d0pE5SIre/sZDCosge9hIRCUNUh0Cj2tW569yOzF+3nfEzVoddjohIxInqEAA4r0sLBp2YzF8mfsu6rXtLf4OISAyJ+hAwM+45/xTiDH739iIi/WwoEZHKFPUhANCifg3uGNaBacs38+ZcXaQsInJITIQAwCW9WtEjvQF/en8Jebvywy5HRCQixEwIxMUZ917QmX0HC/nju1+HXY6ISESImRAAaJtcm5t/0p4PFm1g4tffhV2OiEjoYioEAMYMaMNJzevyX+8sZse+g2GXIyISqpgLgcT4OO67oDObd+dz70dLwy5HRCRUMRcCAKek1uPa/m14efY6ZqzYHHY5IiKhickQALjlpyeQ3qgmd761iH0HCsMuR0QkFDEbAjWqxfPnn3VmzZa9jPt0WdjliIiEImZDAKB320aM7tmSp6atZGHO9rDLERGpdDEdAgB3DDuJ5DrVuf2NhRwsLAq7HBGRSlWmEDCz1Wa2yMzmm1lm0NbQzCaZ2fLgb4Og3czsITPLNrOFZnZqifVcEfRfbmZXHJ9NKp96NRL50/BOfPPdLp6cujLsckREKlV59gQGuXvXEo8suwOY7O7tgcnBPMAwih8u3x4YAzwGxaEB3AX0AnoCdx0KjrCdeXIzzu7cnAcnL2f15j1hlyMiUmmOZThoODA+mB4PjCjR/oIXmwXUN7PmwBBgkrtvdfdtwCRg6DF8foW669yOxJvxt0k6SCwisaOsIeDAJ2aWZWZjgram7r4hmP4OaBpMpwDrSrw3J2g7XPsPmNkYM8s0s8y8vLwylnhsmtRJ4pp+rXlvwXq+Xr+jUj5TRCRsZQ2Bfu5+KsVDPTeY2YCSC734Jv0VdqN+d3/S3TPcPSM5ObmiVluqawe0oV6NRP468dtK+0wRkTCVKQTcPTf4uwl4m+Ix/Y3BMA/B301B91ygZYm3pwZth2uPGPVqJDJ2YFs+/zaP2au2hl2OiMhxV2oImFktM6tzaBo4E1gMvAscOsPnCmBCMP0ucHlwltBpwI5g2GgicKaZNQgOCJ8ZtEWUK3qn07Rude77+Bs9hUxEol5Z9gSaAl+a2QJgNvCBu38M3AucYWbLgZ8G8wAfAiuBbOAp4HoAd98K/AmYE7zuDtoiSo1q8dz0k/ZkrtnG599uKv0NIiJVmEX6r92MjAzPzMys1M88WFjEGfdPISkxng9v6k9cnFXq54uIHAszyypxOv8RxfwVwz8mMT6OW884gW++28V7C9eHXY6IyHGjEDiMczu34KTmdbl/0jLdTkJEopZC4DDi4ozbh5zImi17eXXOutLfICJSBSkEjmDgicn0SG/AQ5OX65kDIhKVFAJHYGbcPrQDm3bl8/yM1WGXIyJS4RQCpeiR3pDBHZrw2BfZ7NirB9OLSHRRCJTBbWeeyM79BTwxdUXYpYiIVCiFQBl0bFGX87q04Lnpq9m0a3/Y5YiIVBiFQBn9+owTOFhYxMOfZYddiohIhVEIlFF641pc3KMl//xqLWu37A27HBGRCqEQKIebftKehHjjgU/14BkRiQ4KgXJoWjeJK/qk8878XL75bmfY5YiIHDOFQDmNPb0ttasn8NeJ2hsQkapPIVBO9WtW47rT2/Lp0o1krYm4O2GLiJSLQuAoXNU3nca1q3Pfx9/qwTMiUqUpBI5CzWoJ3PSTdny1aitTl28OuxwRkaOmEDhKo3qk0bJhDf784VLdXE5EqiyFwFGqlhDH3ed14tuNu7jtjQUUFWlYSESqnjKHgJnFm9k8M3s/mJ9mZvOD13ozeydoH2hmO0os+0OJdQw1s2/NLNvM7qjwralkgzo04Y6hHfhg4QbGTV4edjkiIuWWUI6+NwNLgboA7t7/0AIzexOYUKLvNHc/p+SbzSweeAQ4A8gB5pjZu+6+5ChrjwhjBrQhe9NuHpq8nLbJtRjeNSXskkREyqxMewJmlgqcDTz9I8vqAoOBd0pZTU8g291XuvsB4BVgeLmqjUBmxj3nn0LP1g35zRsLmbt2W9gliYiUWVmHg8YBtwM/9rDdEcBkdy95CW1vM1tgZh+Z2clBWwpQ8jmNOUHbD5jZGDPLNLPMvLy8MpYYnmoJcTx+aXea1U1izAtZ5G7fF3ZJIiJlUmoImNk5wCZ3zzpMl9HAyyXm5wKt3L0L8HdK30P4AXd/0t0z3D0jOTm5vG8PRcNa1Xj2ygzyCwq55vk57M4vCLskEZFSlWVPoC9wnpmtpngIZ7CZvQhgZo0pHub54FBnd9/p7ruD6Q+BxKBfLtCyxHpTg7ao0a5JHR695FSWb9rNLa/Mo1BnDIlIhCs1BNz9TndPdfd0YBTwmbtfGiweCbzv7v960oqZNTMzC6Z7Bp+xBZgDtDez1mZWLVjXuxW6NRGgf/tk/nhuRz5duol7P1oadjkiIkdUnrODfswo4N7vtY0ExppZAbAPGOXF91YoMLMbgYlAPPCsu399jJ8fkS7rnU72pt08NW0V7ZrU5uIeaWGXJCLyoyzS732TkZHhmZmZYZdRbgWFRVw9PpMZ2Zv5xzW96N22UdgliUiMMLMsd88oS19dMXycJMTH8fDPu5HeuBZjX8pi9eY9YZckIvIDCoHjqG5SIs9ckYEBV4+fw469B8MuSUTk3ygEjrNWjWrxxGUZrNu6lxv+OZeDhT92qYWISDgUApWgZ+uG/O/5p/Bl9mb++72v9QwCEYkYx3p2kJTRhRktWZG3h8enrKBejURu/ekJJMQrg0UkXAqBSnT7kBPZuiefRz5fwYwVWxh3cVdaNaoVdlkiEsP0U7QSxcUZ943swt9Hd2PFpt0Me3Aar8xeq+EhEQmNQiAE53ZpwcRbB9C1ZX3ueGsR176Qxebd+WGXJSIxSCEQkub1avDiNb34/dknMXV5HkPHTWXy0o1hlyUiMUYhEKK4OOMX/dvw3o39aFy7OteMz+TOtxax94DuQCoilUMhEAFObFaHCTf25ZcD2vDKnLWc9eA05unhNCJSCRQCEaJ6Qjx3nnUSL197GgcLnZGPz+SBScso0MVlInIcKQQizGltGvHRLf0Z3qUFD05ezgWPz2SV7jskIseJQiAC1U1K5P6Lu/LIz09l9eY9nPXgNJ6fvooiPaRGRCqYQiCCnd25ORNvGUDP1g3543tLuPjJmazM2x12WSISRRQCEa5ZvSSev6oHf72wC99+t4thD07jiSkrdKxARCqEQqAKMDNGdk/l01+fzuknJPPnj77hgsdm8O13u8IuTUSqOIVAFdKkbhJPXNadh3/ejXXb9nHO36fx0OTluj21iBy1MoeAmcWb2Twzez+Yf97MVpnZ/ODVNWg3M3vIzLLNbKGZnVpiHVeY2fLgdUWFb00MMDPO6dyCSbcOYFin5tw/aRnnPTydxbk7wi5NRKqg8uwJ3Aws/V7bb9y9a/CaH7QNA9oHrzHAYwBm1hC4C+gF9ATuMrMGx1B7TGtUuzoPje7Gk5d1Z8vufIY/Mp37Pv6G/QcLwy5NRKqQMoWAmaUCZwNPl6H7cOAFLzYLqG9mzYEhwCR33+ru24BJwNCjrFsCZ57cjEm3ns7PuqXw6BcrOPuhaWSt0dXGIlI2Zd0TGAfcDnx/8PmeYMjnATOrHrSlAOtK9MkJ2g7X/gNmNsbMMs0sMy8vr4wlxq56NRP5y4VdGH91T/YfLGLk4zO4+70l7DugvQIRObJSQ8DMzgE2uXvW9xbdCXQAegANgd9WVFHu/qS7Z7h7RnJyckWtNuqdfkIyE28dwCW90nh2+iqGPjiVWSu3hF2WiESwsuwJ9AXOM7PVwCvAYDN70d03BEM++cBzFI/zA+QCLUu8PzVoO1y7VKDa1RP4nxGn8M9re+EOo56cxR8mLGZPvu5MKiI/VGoIuPud7p7q7unAKOAzd780GOfHzAwYASwO3vIucHlwltBpwA533wBMBM40swbBAeEzgzY5Dvq0bczHt/Tnqr7p/GPWGoaMm8r07M1hlyUiEeZYrhN4ycwWAYuAxsD/BO0fAiuBbOAp4HoAd98K/AmYE7zuDtrkOKlZLYG7zj2Z137Zm8T4OC55+ivufGsRu/YfDLs0EYkQFunPt83IyPDMzMywy6jy9h8s5P5Jy3h62kqa1U3izxd05vQTdLxFJBqZWZa7Z5Slr64YjhFJifH87qyTeGNsH2pUi+eKZ2fzm9cXsGOf9gpEYplCIMacmtaAD27qz9iBbXlrXi5nPjBFzzYWiWEKgRiUlBjPb4d24O3r+1C/RjWuGZ/Jra/OZ/veA2GXJiKVTCEQwzqn1ue9X/Xjpp+0570F6znjganaKxCJMQqBGFctIY5fn3EC79zQl0a1ivcKbnt9ATt1BpFITFAICACdUuox4ca+3DCoLW/NzWHoA1OZtly37BCJdgoB+ZfqCfH8ZkgH3hzbh6Rq8Vz2zGx+/84iXW0sEsUUAvID3dIa8OFN/flFv9a89NVahj04ja90DyKRqKQQkB+VlBjP78/pyKtjegMw6qlZ/On9JXpegUiUUQjIEfVs3ZCPbu7Ppb1a8cyXqzjroWnMW6vnFYhEC4WAlKpW9QT+NKITL17Ti/0HCrngsRnc9/E35Bdor0CkqlMISJn1a9+Yj28dwMjuqTz6xQqGPzydr9fr2cYiVZlCQMqlblIi943swrNXZrBlzwFGPDKdRz7PprAosm9EKCI/TiEgR2Vwh6Z8cssAzuzYjL9M/JaLnpjJmi17wi5LRMpJISBHrUGtajz8826Mu7gryzbuYtiD03h59loi/fbkIvL/KQTkmJgZI7qlMPGWAXRtWZ8731rEL8ZnkrcrP+zSRKQMFAJSIVrUr8GL1/TiD+d05MvszQwZN5WPF38XdlkiUooyh4CZxZvZPDN7P5h/ycy+NbPFZvasmSUG7QPNbIeZzQ9efyixjqHBe7LN7I6K3xwJU1yccXW/1rz/q360qJ/EdS9m8R+v6WZ0IpGsPHsCNwNLS8y/BHQATgFqAL8osWyau3cNXndDcYgAjwDDgI7AaDPreCzFS2Rq37QOb43ty68Gt+PteTkMGzeNmSt02wmRSFSmEDCzVOBs4OlDbe7+oQeA2UBqKavpCWS7+0p3PwC8Agw/urIl0lVLiOM/zjyRN8b2ITHe+PnTs7jnA912QiTSlHVPYBxwO1D0/QXBMNBlwMclmnub2QIz+8jMTg7aUoB1JfrkBG0/YGZjzCzTzDLz8nQ746rs1LQGfHhzfy7plcZT01Zx3sNfsjhXF5iJRIpSQ8DMzgE2uXvWYbo8Ckx192nB/Fyglbt3Af4OvFPeotz9SXfPcPeM5OTk8r5dIkzNagn8z4hTeO6qHmzfe5DzHy2+wKyg8Ae/KUSkkpVlT6AvcJ6ZraZ4CGewmb0IYGZ3AcnArw91dved7r47mP4QSDSzxkAu0LLEelODNokRg05swie3DmDIycUXmF34xExWbdYFZiJhKjUE3P1Od09193RgFPCZu19qZr8AhgCj3f1fP+nMrJmZWTDdM/iMLcAcoL2ZtTazasG63q3wLZKIVr9mNR7++ak8NLobK/P2MOzBqbwwc7UuMBMJybFcJ/A40BSY+b1TQUcCi81sAfAQMCo4flwA3AhMpPgso9fc/etj+Hypws7r0oKJtwygZ+tG/GHC11z+7Gw27NgXdlkiMcci/RdYRkaGZ2Zmhl2GHCfuzktfreWeD5aSGG/cPbwTw7u2INiZFJGjYGZZ7p5Rlr66YlhCZWZcelorPrq5P+2a1OaWV+dzwz/nsnXPgbBLE4kJCgGJCOmNa/H6dX24feiJTFqykSHjpvLZNxvDLksk6ikEJGLExxnXD2zHhBv60ahWNa5+PpM73lzI7vyCsEsTiVoKAYk4HVvUZcKNfbnu9La8mrmOIQ9MZeoyXTQocjwoBCQiVU+I545hHXjjut5UT4zj8mdnc9vrC9i+V8cKRCqSQkAiWvdWDfnwpv7cOKgdb8/L5af3T+WjRRvCLkskaigEJOIlJcZz25ATeffGvjStW52xL83lun9ksWnn/rBLE6nyFAJSZZzcoh4TbujLb4d24LNvN/HT+6fweuY6XW0scgwUAlKlJMTHMXZgWz66uT8nNqvDb95YyOXPzmbd1r1hlyZSJSkEpEpqm1ybV8f05k/DT2bumm0MGTeV56evoqhIewUi5aEQkCorLs64rHc6E28dQI/0hvzxvSVc+MRMsjftCrs0kSpDISBVXmqDmjx/VQ/uv6gLK/J2c9aDX3L/J9+y74CeYiZSGoWARAUz42enpjLp1tMZdkozHvosm5/eP4WPFm3QgWORI1AISFRJrlOdB0d149Uxp1EnKYGxL83lsmdma4hI5DAUAhKVerVpxPu/6sd/n3cyC3O2M3TcNO75YAm79h8MuzSRiKIQkKiVEB/HFX3S+fy2gYzsnsrTX65i8N+m8NbcHA0RiQQUAhL1GtWuzr0XdOad6/uSUr8Gv35tASMfn8ni3B1hlyYSOoWAxIwuLevz1tg+3DeyM2u27OHch7/kP99exDY9wEZiWJlDwMzizWyemb0fzLc2s6/MLNvMXg0eHo+ZVQ/ms4Pl6SXWcWfQ/q2ZDanwrREpRVyccVFGSyb/x0Cu7JPOK3PWMehvX/CPWWsoKCwKuzyRSleePYGbKX5A/CH/Bzzg7u2AbcA1Qfs1wLag/YGgH2bWERgFnAwMBR41s/hjK1/k6NSrkchd557Mhzf1p0OzOvzXO4s5c9xUPl6sU0oltpQpBMwsFTgbeDqYN2Aw8EbQZTwwIpgeHswTLP9J0H848Iq757v7KiAb6FkB2yBy1E5sVoeXrz2Npy7PIN6M616cy/mPzmDmii1hlyZSKcq6JzAOuB04tL/cCNju7oee+5cDpATTKcA6gGD5jqD/v9p/5D3/xszGmFmmmWXm5emJUnJ8mRlndGzKx7cM4L6Rndm4cz+jn5rFlc/NZsn6nWGXJ3JclRoCZnYOsMndsyqhHgDc/Ul3z3D3jOTk5Mr6WIlx8cHxgs9vG8jvzurAvLXbOfvv07j11fm6S6lErYQy9OkLnGdmZwFJQF3gQaC+mSUEv/ZTgdygfy7QEsgxswSgHrClRPshJd8jEjGSEuMZM6AtF2ek8diUFTw3fRUfLNzAJaelceOgdjSqXT3sEkUqTKl7Au5+p7ununs6xQd2P3P3S4DPgZFBtyuACcH0u8E8wfLPvPhI27vAqODsodZAe2B2hW2JSAWrVzORO4Z14IvfDORnp6YwfsZqTv/LFzw0eTl78gtKX4FIFXAs1wn8Fvi1mWVTPOb/TND+DNAoaP81cAeAu38NvAYsAT4GbnB33eZRIl7zejW494LOfHLrAPq2a8T9k5Zx+l++YPyM1ew/qP+EpWqzSD8dLiMjwzMzM8MuQ+RfstZs4/8+/obZq7bSrG4S1w9qy0UZLUlK1BnPEhnMLMvdM8rUVyEgUn7uzowVWxj36TLmrN6mMJCIohAQqSSHwuCBScvIXFMcBjcMastFPVpSPUFhIOFQCIhUMoWBRBKFgEhIvh8Gzeslcf1AhYFULoWASMgOFwYX6piBVAKFgEiEcHemZxcfQM5cs40mdaozZkAbRvdMo1b1slyrKVJ+CgGRCHNoz+CRz7OZsWIL9WsmclWf1lzZJ516NRPDLk+ijEJAJILNXbuNRz/P5tOlm6hVLZ5Le7fiF/3akFxHt6OQiqEQEKkClm7YyaNfrOCDhetJjI/j4h4tGTOgDakNaoZdmlRxCgGRKmTV5j08MWUFb87NwR1GdEth7MC2tE2uHXZpUkUpBESqoPXb9/HUtJW8PHst+QVFnNWpOWMHtqVTSr2wS5MqRiEgUoVt3p3Pc9NX8cKMNezKL6B/+8aMPb0tvds2ovghfSJHphAQiQI79x/kxVlrePbL1WzenU/n1Hr8ckBbhnZqRnycwkAOTyEgEkX2Hyzk7Xm5PDl1Jas276FVo5pc278NI7un6sIz+VEKAZEoVFjkTFryHY9NWcmCddtpXLsaV/ZJ57LTdK2B/DuFgEgUc3dmrdzK41NWMGVZHrWqxTO6ZxpX92tNi/o1wi5PIoBCQCRGLN2wkyemrOC9hRswYHjXFH55ehtOaFon7NIkRAoBkRiTs20vT09bxatz1rHvYCGnn5DMmAFt6KMzimJShYaAmSUBU4HqQALwhrvfZWbTgEM/N5oAs919hJkNpPih86uCZW+5+93BuoYCDwLxwNPufm9pBSoERMpu254DvPTVGp6fsYbNu/Pp2Lwu1w5ozTmdW5AYfyyPFJeqpKJDwIBa7r7bzBKBL4Gb3X1WiT5vAhPc/YUgBG5z93O+t554YBlwBpADzAFGu/uSI32+QkCk/PYfLGTC/FyemraK7E27aVY3iav6pjO6Vxp1k3QQOdqVJwRK/WngxXYHs4nB61/JYWZ1gcHAO6WsqieQ7e4r3f0A8AowvCxFikj5JCXGc3GPND65ZQDPXdmDNsm1+PNH39D7fyfzp/eXkLNtb9glSoQo0w3Ng1/xWUA74BF3/6rE4hHAZHffWaKtt5ktANZTvFfwNZACrCvRJwfodZjPGwOMAUhLSyvblojID8TFGYM6NGFQhyYszt3B09NW8vyM1Tw/YzVnndKca/u3pnNq/bDLlBCVaZDQ3QvdvSuQCvQ0s04lFo8GXi4xPxdo5e5dgL9T+h7Cj33ek+6e4e4ZycnJ5X27iPyITin1GDeqG9NuH8Q1/Vrz+TebOO/h6Vz8xEwmLdlIYVFknyQix0e5jhS5+3bgc2AogJk1pniY54MSfXYeGj5y9w+BxKBfLtCyxOpSgzYRqUQt6tfgd2edxMw7B/P7s09i3da9XPtCJoP/9gXPT1/FnvyCsEuUSlRqCJhZspnVD6ZrUHxg95tg8UjgfXffX6J/s+BgMmbWM/iMLRQfCG5vZq3NrBowCni3ArdFRMqhTlIiv+jfhqm3D+Lhn3ejYa1q/PG9JZz258n874dLyd2+L+wSpRKU5ZhAc2B8cFwgDnjN3d8Plo0Cvn+a50hgrJkVAPuAUV58ClKBmd0ITKT4FNFng2MFIhKihPg4zuncgnM6t2Du2m08++UqngleQ09uxtX9WtO9VYOwy5TjRBeLicgP5G7fxwszVvPP2WvZtb+Ari3rc3W/1gzr1EzXG1QBumJYRCrEnvwC3pybw3PTV7Nq8x6a10viij7pjO6RppvWRTCFgIhUqKIi57NvNvHs9FXMWLGFGonx/OzUFK7sk0573aco4igEROS4WbJ+J89NX8WEBes5UFBEv3aNubJPOoM6NNHDbiKEQkBEjrutew7w8uy1/GPmGr7buZ+0hjW5vHcrLsxoSb0aGioKk0JARCrNwcIiPvl6I8/PWMWc1duoWS2eC05N5Yo+6bRrUjvs8mKSQkBEQrE4dwfPTV/NewvWc6CwiP7tG3NV33QGntCEOA0VVRqFgIiEavPufF7+ai3/mLWGTbvySW9Uk8t6pzOye6qGiiqBQkBEIsLBwiI+Wvwdz09fxdy126mRGM+Ibilc3rsVJzWvG3Z5UUshICIRZ3HuDl6YuZoJ89eTX1BEz/SGXNa7FUNObka1BF2AVpEUAiISsbbtOcDrWet4cdZa1m7dS3Kd6ozumcYlvdJoWjcp7PKigkJARCJeUZEzZVke42euZsqyPOLNGHJyMy7v3YqerRvq2cjHoDwhUKaHyoiIVLSSD7xZs2UPL85aw2uZOXywaAMnNq3DZb1bcX63FGpV1z9Tx5P2BEQkYuw7UMi7C3J5YeYavl6/k9rVEzi/WwqXnJZGh2Y6kFxWGg4SkSrN3Zm7djsvfbWG9xdu4EBBEd1bNeDS09IY1qk5SYnxYZcY0RQCIhI1tu05wJtzc3jpq7Ws2ryHBjUTuTCjJaN7ptG6ca2wy4tICgERiTpFRc7MlVt4cdYaPgmeidyvXWMuPS2Nn5zUVM85KEEhICJRbePO/bw2Zx0vz17L+h37aVq3Ohf3SGNUj5a0qF8j7PJCV6EhYGZJwFSgOsVnE73h7neZ2fPA6cCOoOuV7j4/eL7wg8BZwN6gfW6wriuA3wf9/8fdx5dWoEJARA6noLCIL77N48Wv1jBlWR4GDO7QhFE90hh4YjIJMbp3UNGniOYDg919t5klAl+a2UfBst+4+xvf6z8MaB+8egGPAb3MrCFwF5ABOJBlZu+6+7ayFCoi8n0J8XH8tGNTftqxKeu27uXl2Wt5PSuHT5dm0qxuEhf1aMnFPVqSor2Dwyo1Jr3Y7mA2MXgdafdhOPBC8L5ZQH0zaw4MASa5+9bgH/5JwNBjK19EpFjLhjW5fWgHZtwxmMcv7U6H5nX4+2fL6fd/n3Hlc7OZ+PV3HCwsCrvMiFOmqzDMLB7IAtoBj7j7V2Y2FrjHzP4ATAbucPd8IAVYV+LtOUHb4dp/7PPGAGMA0tLSyrVBIhLbEuPjGNqpGUM7NSNn215ey8zhtTnr+OU/skiuU52LMlIZ1SONlg1rhl1qRCjTgJm7F7p7VyAV6GlmnYA7gQ5AD6Ah8NuKKsrdn3T3DHfPSE5OrqjVikiMSW1Qk1+fcQJf/nYQT1+eQZfUejz2xQr63/c5lz3zFR8uKr4GIZaV63psd99uZp8DQ939r0Fzvpk9B9wWzOcCLUu8LTVoywUGfq/9i6OoWUSkXEoeO9iwYx+vZ+bw6px1XP/SXBrVqsb53VK4uEdL2jetE3apla4sZwclAweDAKgBfAL8H5Dl7huCs4EeAPa7+x1mdjZwI8VnB/UCHnL3nsGB4Szg1GDVc4Hu7r71SJ+vs4NE5HgoLHKmLs/jtTnr+HTpRg4WOt3S6nNRRkvO6dycOklV9+E3FX2KaGdgPBBP8fDRa+5+t5l9BiQDBswHrgvOIDLgYYoP+u4FrnL3zGBdVwO/C1Z9j7s/V1qBCgEROd627M7n7Xm5vDpnHcs37aZGYjxnd27ORRkt6ZHeoMrd0VQXi4mIHAV3Z/667byWuY73Fmxgd34BrRvX4sKMVEaemkqTKvK8A4WAiMgx2nuggA8Xfcdrc9Yxe/VW4uOMQScmc2FGSwZ3aBLRt6lQCIiIVKCVebt5PSuHN7Ny2LQrn0a1qjG8awoju6fSsUXk3eJaISAichwUFBYxZVkeb2Tl/Otg8knN6zKyeyrDu7agce3qYZcIKARERI67bXsO8N7C9byRlcPCnB0kxBkDT2zCyO4pDO7QlGoJ4Q0XKQRERCrRso27eDMrh7fm5ZK3K58GNRM5r0sLRnZvSaeUupV+dpFCQEQkBAWFRUzL3swbWTlMWrKRAwVFnNC0djBclELTSjq7SCEgIhKyHXsP/mu4aP667cQZ9G3XmBFdUxjSqRm1q5frhg3lohAQEYkgK/J2M2FeLm/Pz2Xd1n0kJcYx5ORmjOiWQv92jSv8uQcKARGRCOTuZK3Zxtvzcnl/4QZ27DtI49rVOLdLC87vlsIpKfUq5PiBQkBEJMLlFxTyxbd5vDMvl8lLN3GgsIi2ybU4v1sKw7umHNOtrhUCIiJVyI69B/lw8QbenpfL7FXF99Ts2bohL17T66hONa3ox0uKiMhxVK9mIqN7pjG6Zxo52/YyYf561m3dWynXGigEREQiSGqDmtwwqF2lfV7k3gFJRESOO4WAiEgMUwiIiMQwhYCISAxTCIiIxDCFgIhIDFMIiIjEMIWAiEgMi/jbRphZHrDmKN/eGNhcgeVUJbG87RDb269tj12Htr+VuyeX5Q0RHwLHwswyy3r/jGgTy9sOsb392vbY3HY4uu3XcJCISAxTCIiIxLBoD4Enwy4gRLG87RDb269tj13l3v6oPiYgIiJHFu17AiIicgQKARGRGBaVIWBmQ83sWzPLNrM7wq6nspnZajNbZGbzzSyqn81pZs+a2SYzW1yiraGZTTKz5cHfBmHWeDwdZvv/aGa5wfc/38zOCrPG48XMWprZ52a2xMy+NrObg/ao//6PsO3l/u6j7piAmcUDy4AzgBxgDjDa3ZeEWlglMrPVQIa7R/1FM2Y2ANgNvODunYK2+4Ct7n5v8COggbv/Nsw6j5fDbP8fgd3u/tcwazvezKw50Nzd55pZHSALGAFcSZR//0fY9oso53cfjXsCPYFsd1/p7geAV4DhIdckx4m7TwW2fq95ODA+mB5P8f85otJhtj8muPsGd58bTO8ClgIpxMD3f4RtL7doDIEUYF2J+RyO8n+cKsyBT8wsy8zGhF1MCJq6+4Zg+jugaZjFhORGM1sYDBdF3XDI95lZOtAN+IoY+/6/t+1Qzu8+GkNAoJ+7nwoMA24IhgxikhePd0bXmGfpHgPaAl2BDcDfQq3mODOz2sCbwC3uvrPksmj//n9k28v93UdjCOQCLUvMpwZtMcPdc4O/m4C3KR4iiyUbgzHTQ2Onm0Kup1K5+0Z3L3T3IuApovj7N7NEiv8RfMnd3wqaY+L7/7FtP5rvPhpDYA7Q3sxam1k1YBTwbsg1VRozqxUcKMLMagFnAouP/K6o8y5wRTB9BTAhxFoq3aF/AAPnE6Xfv5kZ8Ayw1N3vL7Eo6r//w2370Xz3UXd2EEBwWtQ4IB541t3vCbeiymNmbSj+9Q+QAPwzmrffzF4GBlJ8C92NwF3AO8BrQBrFtyG/yN2j8uDpYbZ/IMXDAQ6sBn5ZYow8aphZP2AasAgoCpp/R/HYeFR//0fY9tGU87uPyhAQEZGyicbhIBERKSOFgIhIDFMIiIjEMIWAiEgMUwiIiMQwhYCISAxTCIiIxLD/B+jj/rmr65FkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(w.epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ebb3d41a5546c18f02a6c6687e2a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = Word2Vec([x for x in tokens if 'game' in x][:50], vector_size=6)\n",
    "\n",
    "w.build_vocab(min_count=0)\n",
    "\n",
    "# fit parameters\n",
    "_ = w.train(window=3, epochs=150, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game ['days', 'coons', 'suicide', 'popular', 'true', 'baylor', 'beat', 'tigers', 'unlikely', 'straight', 'squeeze', 'dramatic', 'tonight', 'aaron', 'drawn-in', 'dinger', 'torre', 'determines', 'waving', 'read'] \n",
      "\n",
      "bat ['occured', 'problems', '5-2', '3-5', 'david', 'lankford', 'branson', '2', '3-2', 'fans', 'furthermore', 'catcher', 'candy', 'three', 'due', '4-3', 'good', 'even', 'hank', 'monday'] \n",
      "\n",
      "play ['star', 'six-hitter', 'stood', 'league', 'ekdfc', 'gerald', 'suicide', 'morning', 'two', 'expected', 'waving', 'hundley', '20', 'unlikely', '3', 'dramatic', '4th', '18-6', 'seaver', 'phils'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "def get_distance_matrix(wordvecs, metric):\n",
    "    dist_matrix = distance.squareform(distance.pdist(wordvecs, metric))\n",
    "    return dist_matrix\n",
    "\n",
    "def get_k_similar_words(word, dist_matrix, token_to_id, id_to_token, k=20):\n",
    "    idx = token_to_id[word]\n",
    "    dists = dist_matrix[idx]\n",
    "    ind = np.argpartition(dists, k)[:k+1]\n",
    "    ind = ind[np.argsort(dists[ind])][1:]\n",
    "    out = [(i, id_to_token[i], dists[i]) for i in ind]\n",
    "    return out\n",
    "\n",
    "sim_matrix = get_distance_matrix(w.model[\"W\"], 'cosine')\n",
    "for word in ['game', 'bat', 'play']:\n",
    "    print(word, [t[1] for t in get_k_similar_words(word, sim_matrix, w.token_to_id, w.id_to_token)], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe9bcce22e0>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(w.epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36429a0a86940188707f150d30e6156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = Word2Vec([i for i in tokens if 'game' in i][:50], vector_size=10)\n",
    "\n",
    "w.build_vocab(min_count=0)\n",
    "\n",
    "# fit parameters\n",
    "_ = w.train(window=3, epochs=50, learning_rate=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe9bcd10af0>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAi8UlEQVR4nO3deXxV9Z3/8dcnNwtZyB4ISQhhCUvYAiKbgFtFXCpWp9YWO1Sd8uuM07HTxWp/nTptp62t86vLjNWxbnS6uFahTl0QQVBkCbLvYSeEhJAQwpaQ5Pv74x6Y1KIESDjJPe/n45HHPed7zr33c9rr+xy+55zvMeccIiISDFF+FyAiIheOQl9EJEAU+iIiAaLQFxEJEIW+iEiARPtdwKfJzMx0BQUFfpchItKpLF++vMo5l3W6ZR069AsKCigpKfG7DBGRTsXMdn7SMnXviIgEiEJfRCRAFPoiIgGi0BcRCRCFvohIgCj0RUQCRKEvIhIgrQp9M9thZmvMbKWZlXht6WY2x8y2eK9pXruZ2aNmVmpmq81sZIvPme6tv8XMprfPJkHZwWP8/M2NlNcea6+vEBHplM7mSP9y51yxc26UN38vMNc5VwjM9eYBrgEKvb8ZwOMQ3kkA9wNjgNHA/Sd3FG3tSH0jj8/fyoLN+9vj40VEOq3z6d6ZCsz0pmcCN7Zo/40LWwykmlkP4GpgjnOu2jlXA8wBppzH93+iwm5JZCd3YcHmqvb4eBGRTqu1oe+At81suZnN8Nq6O+fKvel9QHdvOhfY3eK9e7y2T2r/C2Y2w8xKzKxk//5zO1I3MyYWZvJ+aRVNzXoymIjISa0N/QnOuZGEu27uMrNJLRe68DMX2yRdnXNPOudGOedGZWWddrygVpnYP4vaYydYU1bbFmWJiESEVoW+c67Me60EXiXcJ1/hddvgvVZ6q5cBPVu8Pc9r+6T2djGhXyZmsFD9+iIip5wx9M0s0cy6npwGJgNrgdnAyStwpgOzvOnZwN96V/GMBWq9bqC3gMlmluadwJ3stbWL9MRYhuSksHCL+vVFRE5qzdDK3YFXzezk+r93zr1pZsuAF83sTmAncIu3/p+Ba4FS4ChwO4BzrtrMfgws89b7kXOuus225DQmFmby5IJt1B0/QdcuMe35VSIincIZQ985tw0Yfpr2A8CVp2l3wF2f8FnPAM+cfZnnZlL/LH41fysfbj3A5MHZF+prRUQ6rIi+I3dkfhoJsSF18YiIeCI69GOjoxjXJ4OFW3QyV0QEIjz0Idyvv+PAUXYdOOp3KSIivov80O8fvtZ/gY72RUQiP/T7ZCaSmxqvLh4REQIQ+mbGpP6ZLCo9QGNTs9/liIj4KuJDH2BiYRZ19Y2s2nPQ71JERHwViNAf3zeDKEOjbopI4AUi9FMTYhmWl6p+fREJvECEPoTvzl25+yC1R0/4XYqIiG+CE/qFmTQ7WLRVXTwiElyBCf3hPVPpGhfNAg3JICIBFpjQjwlFMa5vBgs27yc8JpyISPAEJvQh3K9fdvAYOzQkg4gEVLBCvzA8JMP8TZVnWFNEJDIFKvTzMxIY1COZVz7a43cpIiK+CFToA3xpdE/Wlh1ite7OFZEAClzoTx2RS3xMiD8s3eV3KSIiF1zgQj+5SwyfHd6DWSv3cri+0e9yREQuqMCFPsAXR+dztKGJWSvL/C5FROSCCmToF/dMZVCPZHXxiEjgBDL0zUwndEUkkAIZ+qATuiISTIEN/ZYndOuOa+RNEQmGwIY+wJfG9OJoQxOzV+31uxQRkQsi0KE/PC+FQT2S+f2SXRqETUQCIdChf/KE7rq9h1hTVut3OSIi7S7QoQ86oSsiwRL40NcJXREJksCHPuiErogEh0Kf8Andoh7J/GbRTp3QFZGIptAnfEL39ksK2FRRx0I9Q1dEIphC33NDcQ7dusbx64Xb/C5FRKTdKPQ9cdEhpo8vYOGWKjbuO+R3OSIi7UKh38K0MfnEx4R4auF2v0sREWkXCv0WUhNiuWVUHrNWllF56Ljf5YiItLlWh76ZhcxshZm97s33NrMlZlZqZi+YWazXHufNl3rLC1p8xn1e+yYzu7rNt6YN3DGhN43NjucW7fC7FBGRNnc2R/p3AxtazP8ceMg51w+oAe702u8Earz2h7z1MLMi4FZgMDAF+JWZhc6v/LbXKyORq4uy+d2SXRxt0OMURSSytCr0zSwPuA54yps34ArgZW+VmcCN3vRUbx5v+ZXe+lOB551z9c657UApMLoNtqHNfXVSb2qPneClkj1+lyIi0qZae6T/MHAP0OzNZwAHnXMnD4X3ALnedC6wG8BbXuutf6r9NO85xcxmmFmJmZXs37+/9VvShi7qlc7I/FSefn87Tc26WUtEIscZQ9/MrgcqnXPLL0A9OOeedM6Ncs6NysrKuhBfeVpfndiHXdVHmbN+n281iIi0tdYc6V8C3GBmO4DnCXfrPAKkmlm0t04eUOZNlwE9AbzlKcCBlu2neU+HM3lwNvnpCfxal2+KSAQ5Y+g75+5zzuU55woIn4h91zk3DZgH/I232nRgljc925vHW/6uCw9oMxu41bu6pzdQCCxtsy1pY6Eo445LCli+s4blO2v8LkdEpE2cz3X63wW+aWalhPvsn/banwYyvPZvAvcCOOfWAS8C64E3gbucc03n8f3t7vOjepLcJZqnNDSDiESI6DOv8r+cc/OB+d70Nk5z9Y1z7jjw+U94/0+An5xtkX5JjIvmy+N68av5W9m47xADs5P9LklE5LzojtwzmDGxL0lx0fz7W5v8LkVE5Lwp9M8gJSGGr13al3c2VLJ8Z7Xf5YiInBeFfivcfkkBmUlx/OLNTXrIioh0agr9VkiIjebrV/RjyfZqFughKyLSiSn0W+mLo/PJS4vnwbc20qy7dEWkk1Lot1JsdBTfvKo/a8sO8cZa3aUrIp2TQv8sTC3OpX/3JP7f25tobGo+8xtERDoYhf5ZCEUZ3548gG1VR3h5uUbgFJHOR6F/lq4q6s6I/FQembuF4yc69A3FIiJ/RaF/lsyM71w9gPLa4/x28U6/yxEROSsK/XMwvm8mEwszeWxeKbXHTvhdjohIqyn0z9F3pwyk9tgJfvHmRr9LERFpNYX+ORqSm8JXxvfmd0t2aXgGEek0FPrn4VuT+5OT0oX7/riGhkZdwikiHZ9C/zwkxkXzo6lD2FxxmF9rzH0R6QQU+ufpM0XduWZINo/O3cKOqiN+lyMi8qkU+m3gX28YTGwoiu+/tlajcIpIh6bQbwPdk7twz5QBvF9axWsrO+yz3kVEFPptZdqYXozIT+XHr2+g5kiD3+WIiJyWQr+NREUZP7tpKIeOneCnf97gdzkiIqel0G9DA7OT+eqkPry0fA8flOphKyLS8Sj029jdVxbSJzOR77y0SkM0iEiHo9BvY11iQjz0hWIq6+r5way1fpcjIvIXFPrtYHjPVP7pykJmrdzL7FV7/S5HROQUhX47+YfL+jIiP5Xvv7qG8tpjfpcjIgIo9NtNdCiKh24pprHZ8e2XVulh6iLSISj021FBZiL/cn0RH5Qe4LlFO/wuR0REod/ebr24J1cO7MYDb25kc0Wd3+WISMAp9NuZmfHAzcPoGhfNN55fqSGYRcRXCv0LIKtrHA/cPIz15Yd48C09aUtE/KPQv0CuKurOl8f24tcLt/Pm2n1+lyMiAaXQv4C+f/0ghuel8J2XVrFdY++LiA8U+hdQXHSIx6aNJBQy/v63yznW0OR3SSISMAr9CywvLYGHv1DMpoo6PXRFRC44hb4PLhvQja9fUcgrH+3h+WW7/S5HRAJEoe+Tu68sZGJhJvfPXsfaslq/yxGRgDhj6JtZFzNbamarzGydmf3Qa+9tZkvMrNTMXjCzWK89zpsv9ZYXtPis+7z2TWZ2dbttVScQijIeuXUEmYmxfO23y6k9qmGYRaT9teZIvx64wjk3HCgGppjZWODnwEPOuX5ADXCnt/6dQI3X/pC3HmZWBNwKDAamAL8ys1Abbkunk54Yy2PTRlJx6Dh3v7CCxibduCUi7euMoe/CDnuzMd6fA64AXvbaZwI3etNTvXm85VeamXntzzvn6p1z24FSYHRbbERnNiI/jR/eMIT5m/bzb/+jxyyKSPtqVZ++mYXMbCVQCcwBtgIHnXON3ip7gFxvOhfYDeAtrwUyWraf5j0tv2uGmZWYWcn+/fvPeoM6oy+NyefvJvTmuUU7eO6D7X6XIyIRrFWh75xrcs4VA3mEj84HtldBzrknnXOjnHOjsrKy2utrOpz7rh3EVUXd+dHr63l3Y4Xf5YhIhDqrq3eccweBecA4INXMor1FeUCZN10G9ATwlqcAB1q2n+Y9gRc+sVvM4JwU/vH3K1i3V1f0iEjba83VO1lmlupNxwNXARsIh//feKtNB2Z507O9ebzl77rwHUizgVu9q3t6A4XA0jbajoiQEBvN09NHkRofwx3PLWNf7XG/SxKRCNOaI/0ewDwzWw0sA+Y4514Hvgt808xKCffZP+2t/zSQ4bV/E7gXwDm3DngRWA+8CdzlnNM4BB/TLbkLT3/lYo7UN3HnzGUcqW8885tERFrJOvIwAKNGjXIlJSV+l+GLeZsqufO5ZVw+oBv/9eWLiA7pPjoRaR0zW+6cG3W6ZUqSDuryAd340dQhzN1YyXdeXq1n7IpIm4g+8yril9vG9qL22AkefGsTCbEh/u3GIYRveRAROTcK/Q7ursv7cbi+kcfnbyUxLpr7rhmo4BeRc6bQ7wTuuXoAR+obeXLBNpLiovmnKwv9LklEOimFfidgZvzrZwdzuL6RX87ZTGJcNHdO6O13WSLSCSn0O4moKOMXNw/jWEMTP359PYmxIW4dne93WSLSyejqnU4kOhTFw7cWc2n/LO57dQ0v6gEsInKWFPqdTFx0iCduu4gJ/TK555XVGqBNRM6KQr8Tio8N8dT0UVxV1J1//dN6HptX6ndJItJJKPQ7qbjoEL+aNpKpxTk8+NYmHnxrox6yLiJnpBO5nVhMKIpf3lJMfEyIx+Zt5Uh9Ez+4voioKF3HLyKnp9Dv5EJRxs9uGkp8bIhnP9jBsYYmfnrTUEIKfhE5DYV+BDAzfnB9EUlx0fzHu6XUHG3gkVtHEB8b6EcQi8hpqE8/QpgZ35o8gB9cX8ScDRXc+uSHVNZpPH4R+UsK/Qhzx4Te/NdtF7G54jCfe2wRmyvq/C5JRDoQhX4Emjw4mxf+z1gampq5+fFFfFBa5XdJItJBKPQj1LC8VF79h/H0SOnC9GeW8mKJ7t4VEYV+RMtLS+Dlvx/P2D4Z3PPyah54YyNNehiLSKAp9CNccpcYnr39Yr40Jp8n3tvKV55dSvWRBr/LEhGfKPQDICYUxU8/N5Sf3zyUJdur+ex/vM+aPbV+lyUiPlDoB8gXLs7n5a+NwznHzU8s0iidIgGk0A+YYXmp/OnrE7i4II17XlnN915dQ31jk99licgFotAPoIykOGbePpqvXdqX3y/ZxS1PfMjOA0f8LktELgCFfkBFh6K495qBPHHbRWyvOsJ1j77Pqyv2+F2WiLQzhX7ATRmSzRvfmERRj2T++YVVfOP5FdQdP+F3WSLSThT6Qm5qPH+YMZZ//kx/Zq/ay3WPvs+KXTV+lyUi7UChL0B4iOa7P1PIi/9nHE3Njs8/8SGPzSvVzVwiEUahL39hVEE6f757IlOGZPPgW5u4+fFFlFZq0DaRSKHQl7+SEh/Df3xxBI9+cQQ7Dxzh2kff54n3tuqoXyQCKPTltMyMG4bn8PY/X8rlA7J44I2NOuoXiQAKfflUWV3jeOK2i/7qqL+xqdnv0kTkHCj05YxOd9T/2f/8QFf4iHRCCn1ptZNH/Y9PG0nNkQZuenwR//fVNdQe1XX9Ip2FQl/OiplxzdAevPOtS7l9fG/+sHQXV/5yPq+tKMM5negV6egU+nJOkuKi+cFni5j9jxPITY3nGy+sZNpTSyitPOx3aSLyKRT6cl6G5Kbwx3+4hB/fOIQ1ZbVMeXgBP/zTOnX5iHRQZwx9M+tpZvPMbL2ZrTOzu732dDObY2ZbvNc0r93M7FEzKzWz1WY2ssVnTffW32Jm09tvs+RCCkUZXx7bi3nfvozPj+rJc4t2cNm/z+O/F+/UVT4iHUxrjvQbgW8554qAscBdZlYE3AvMdc4VAnO9eYBrgELvbwbwOIR3EsD9wBhgNHD/yR2FRIbMpDh+dtNQXv/6BPp378q/vLaW6x59nw9Kq/wuTUQ8Zwx951y5c+4jb7oO2ADkAlOBmd5qM4EbvempwG9c2GIg1cx6AFcDc5xz1c65GmAOMKUtN0Y6hsE5KTw/YyyPTxvJkYZGpj21hL+buYwtFbqxS8RvZ9Wnb2YFwAhgCdDdOVfuLdoHdPemc4GWz+Hb47V9UvvHv2OGmZWYWcn+/fvPpjzpQE5d5fPNS/nO1QNYsq2aqx9ewD0vr6K89pjf5YkEVqtD38ySgFeAbzjnDrVc5sLX6rXJ9XrOuSedc6Occ6OysrLa4iPFR11iQtx1eT/eu+dybr+kN6+t2MtlD87nZ29s0MleER+0KvTNLIZw4P/OOfdHr7nC67bBe6302suAni3enue1fVK7BEB6Yiz/cn0R7377Uq4b1oMnF2xj4i/e5fH5Wzna0Oh3eSKB0Zqrdwx4GtjgnPtli0WzgZNX4EwHZrVo/1vvKp6xQK3XDfQWMNnM0rwTuJO9NgmQvLQEfnlLMX/+p4lc1CuNn7+5kUm/mMdTC7dxrEEPaBdpb3amuyjNbAKwEFgDnLz+7nuE+/VfBPKBncAtzrlqbyfxn4RP0h4FbnfOlXifdYf3XoCfOOee/bTvHjVqlCspKTmX7ZJOYvnOGh5+ZzMLt1SR1TWOv7+0L18ak0+XmJDfpYl0Wma23Dk36rTLOvKt8wr94Fi6vZqH5mzmw20H6NY1jrsu78cXLu6p8Bc5Bwp96TQ+3HqAh+ZsZumOajKT4vi7ib25bWwvkuKi/S5NpNNQ6Eun4pxj8bZqfjW/lIVbqkiJj2H6+AJuH19AWmKs3+WJdHgKfem0Vu0+yGPzSnl7fQUJsSGmjcnnzgl9yE7p4ndpIh2WQl86vc0VdTw+fyuzV+3FgBuKc/jqxD4M6pHsd2kiHY5CXyLG7uqjPPPBdl5YtpujDU1MLMzkqxP7MLEwk/CFYyKi0JeIU3v0BL9bupNnP9jB/rp6BmZ35Y4JvblheI6u+JHAU+hLxKpvbGL2yr38euE2NlccJj0xli+Nzue2sb3U7y+BpdCXiOec48OtB3h20Q7e2VBByIwpQ7K5/ZICRuanqetHAuXTQl8XP0tEMDPG98tkfL9Mdh04yn8v3sHzy3bz+upyhuQmc9uYXtxQnENCrH7yEmw60peIdaS+kVdXlPHbxTvZuK+OrnHR3DQyl2lje9G/e1e/yxNpN+rekUBzzrF8Zw2/W7KL/1ldTkNTM6N7pzNtTD5XD87WiV+JOAp9EU/1kQZeKtnN75fuYueBo6TEx/C5Ebl84eKeuuZfIoZCX+RjmpsdH247wPPLdvPW2n00NDUzPC+FWy7uyQ3Dc+jaJcbvEkXOmUJf5FPUHGngtZVlPL90N5sq6ugSE8U1Q3pw88g8xvXNIBSlK3+kc1Hoi7SCc45Ve2p5YdluXl+9l7rjjeSkdOFzI3O5eWQefbKS/C5RpFUU+iJn6fiJJuasr+CVj/awYPN+mh2MyE/lphG5XDcsh3SN9ikdmEJf5DxUHDrOayvKeOWjPWyuOEx0lDGpfxZTi3OYXJRNfKyu/pGORaEv0gacc2wor2PWyjJmr9pLee1xEmNDXD04m88W5zChXyYxoTM+dlqk3Sn0RdpYc7Nj6Y5qZq0s439Wl3PoeCOpCTFMGZzN9cNyGNsnnWjtAMQnCn2RdlTf2MTCzVW8vnovc9ZXcKShicykWKYMCe8ALi5I1xVAckEp9EUukOMnmpi3sZLXV5czd2MFx080k5kUy+TB2Vw7pIf+BSAXhEJfxAdH6huZt6mSN9bu490NlRw70URaQgyTi7KZMjSb8X0ziIvWSWBpewp9EZ8da2jivc37eXNtOe9sqORwfSNd46K5bGA3rh7cncsGdCMpTiOAStvQ0MoiPouPDTFlSDZThmRT39jEB6VVvL2ugjnrK/jTqr3EhqK4pF8Gkwdnc+WgbnTrqgfASPvQkb6Ij5qawyOAvr1uH2+t38fu6mMAFPdM5TODuvGZou4M6N5VD4GRs6LuHZFOwDnHxn11vLO+gnc2VrJq90EA8tLi+cyg7lw5qBuje6frPICckUJfpBOqPHScuRsreWd9Be+XVlHf2ExibIgJhZlcMbAblw/oRrdkdQPJX1Poi3RyxxqaWLS1irkbK5m3sZLy2uMADM1N4fKB3bhsQBbD81J1P4AACn2RiHJyOIh5myqZu6GClbsP0uwgLSGGiYVZXDYgi0n9s8hMivO7VPGJQl8kgtUcaWBhaRXzN1Xy3qb9HDjSgFn4XwGTCrO4dEAWxT1TNS5QgCj0RQKiudmxdm8t8zft573N+1mxq4ZmB13johnfL4NJ/bOYVJhFz/QEv0uVdqTQFwmo2mMnWFRaxYIt+1mwuYqyg+FLQntnJjKhXyYTCzMZ1zdDj4eMMAp9EcE5x9b9R1iweT/vl1axeNsBjjY0EYoyinumMqFfJhMKM9UVFAEU+iLyVxoam/loVw3vb6li4Zb9rC6rxTlIjA0xunc6l/TL5JJ+mQzM1s1hnY1CX0TO6ODRBhZvO8AHpQf4oLSKbVVHAMhMimVsnwzG981kfN8MemUkaCfQwZ3X2Dtm9gxwPVDpnBvitaUDLwAFwA7gFudcjYV/CY8A1wJHga845z7y3jMd+L73sf/mnJt5PhslIm0rNSGWKUN6MGVIDwDKa4+d2gEs2lrF66vLAchJ6cLYvuGdwLi+GeSmxvtZtpylMx7pm9kk4DDwmxah/wug2jn3gJndC6Q5575rZtcCXycc+mOAR5xzY7ydRAkwCnDAcuAi51zNp323jvRFOgbnHNurjrBo6wE+3HqAD7cdoPpIAwD56QmM7ZPO2D4ZjO2TQY52Ar47ryN959wCMyv4WPNU4DJveiYwH/iu1/4bF96TLDazVDPr4a07xzlX7RU0B5gC/OFsN0ZELjwzo09WEn2ykrhtbC+amx2bKupYvO0Ai7cd4O31FbxYsgcI7wTG9E5nTJ8MxvROJy8tXt1BHci5Dq3c3TlX7k3vA7p707nA7hbr7fHaPqldRDqhqChjUI9kBvVI5vZLetPcHB4sbvG28L8C5myo4KXl4Z1ATkoXxvTJYHTvdEb3TqdPZqJ2Aj467/H0nXPOzNrsbLCZzQBmAOTn57fVx4pIO4qKMopykinKSeaOCeGdwObKOpZur2bJtmoWbqni1RVlQPjE8Khe6VzcO53RBekM6tFVj5C8gM419CvMrIdzrtzrvqn02suAni3Wy/Payvjf7qCT7fNP98HOuSeBJyHcp3+O9YmIj6KijIHZyQzMTuZvxxXgnGNb1RGWbq9m2fZqlu6o5s11+4DwJaIje6VxcUE6o3qlUZyfSkKsnu/UXs71f9nZwHTgAe91Vov2fzSz5wmfyK31dgxvAT81szRvvcnAfedetoh0JmZG36wk+mYl8cXR4X/Bl9ceC+8EdlSzbHsND72zGecgFGUMzknmohY7Ag0h3XZac/XOHwgfpWcCFcD9wGvAi0A+sJPwJZvV3iWb/0n4JO1R4HbnXIn3OXcA3/M+9ifOuWfPVJyu3hEJjtpjJ/hoVw3Ld9SwbEc1q/Yc5PiJZiD8IJmR+Wlc1Cv8NzBbXUKfRjdniUin09DYzLq9tXy06yAf7ayhZGc1FYfqAYiPCTG8Zwoj8tMYmZ/GiPxUDSXdgkJfRDo95xx7a4+zfGcNy3dUs2L3QdbvPURjczjD8tMTGJGfyoieqRTnpzGoR9fAPlryvK7TFxHpCMyM3NR4clPjuWF4DgDHTzSxpqyWFbtqWLHrIIu3HWDWyr0AxIaiGJSTHN4JeH8aQkJH+iISQZxzlNceZ9Xug6zcfZAVuw+yZk8tx040AZASH8OwvBSG56UyLC+F4p6pEXmSWEf6IhIIZkZOajw5qfFcMzQ8hlBjUzObKw6zas9BVu85yMrdtTz+3laavG6h7OQuDM1LYVhuCkPzUhiam0JGBJ8fUOiLSESLDkWdunHs5OWixxqaWF9ey6rdtazac5A1ZbXMWV9x6j25qfEMy0thSK73l5McMTsChb6IBE58bIiLeqVzUa/0U22Hjp9gXdkh1pQdZPWeWlbvqeWNtftOLc9J6cLg3BSG5KQwJDeZwTkpdE+O63TnCBT6IiJAcpcYxvXNYFzfjFNttUdPsK68lnVlh1i7t5Y1ZbW8s6GCk6dCMxJjKcoJ7wDCr8kUZCQSiuq4OwKFvojIJ0hJiPEeHpN5qu1wfSMbyw+xbu8h1u2tZd3eQzz9/jZONIX3BPExIQZkd6UoJzwgXVGPrgzMTiYxrmPEra7eERE5Tw2NzWyprGPd3kNsKA//rd97iEPHG0+t0ysjgYHZ4R3AIG9HkJ+eQFQ7/KtAV++IiLSj2OgoBuekMDgn5VTbyZvJ1ns7gk376tiw7xBz1lfgXThEfEyI/t2TGJDdlf7dwzuC/tlJZCW137kChb6ISDtoeTPZVUXdT7Ufa2hiS2UdG8vDO4FN++p4d2PlqYfQAKQnxnLTiFy+f31Rm9el0BcRuYDiY0MMy0tlWF7qX7RXHa5n8746Nu6rY9O+Onq002MnFfoiIh1AZlIcmf3iGN8v88wrnweNTSoiEiAKfRGRAFHoi4gEiEJfRCRAFPoiIgGi0BcRCRCFvohIgCj0RUQCpEMPuGZm+4Gd5/ERmUBVG5XTmWi7g0XbHSyt2e5ezrms0y3o0KF/vsys5JNGmotk2u5g0XYHy/lut7p3REQCRKEvIhIgkR76T/pdgE+03cGi7Q6W89ruiO7TFxGRvxTpR/oiItKCQl9EJEAiMvTNbIqZbTKzUjO71+962ouZPWNmlWa2tkVbupnNMbMt3muanzW2BzPraWbzzGy9ma0zs7u99ojedjPrYmZLzWyVt90/9Np7m9kS7/f+gpnF+l1rezCzkJmtMLPXvfmgbPcOM1tjZivNrMRrO+ffesSFvpmFgMeAa4Ai4Itm1vYPmuwYngOmfKztXmCuc64QmOvNR5pG4FvOuSJgLHCX9/9xpG97PXCFc244UAxMMbOxwM+Bh5xz/YAa4E7/SmxXdwMbWswHZbsBLnfOFbe4Pv+cf+sRF/rAaKDUObfNOdcAPA9M9bmmduGcWwBUf6x5KjDTm54J3Hgha7oQnHPlzrmPvOk6wkGQS4Rvuws77M3GeH8OuAJ42WuPuO0GMLM84DrgKW/eCMB2f4pz/q1HYujnArtbzO/x2oKiu3Ou3JveB3T3s5j2ZmYFwAhgCQHYdq+LYyVQCcwBtgIHnXON3iqR+nt/GLgHaPbmMwjGdkN4x/62mS03sxle2zn/1vVg9AjmnHNmFrHX5JpZEvAK8A3n3KHwwV9YpG67c64JKDazVOBVYKC/FbU/M7seqHTOLTezy3wuxw8TnHNlZtYNmGNmG1suPNvfeiQe6ZcBPVvM53ltQVFhZj0AvNdKn+tpF2YWQzjwf+ec+6PXHIhtB3DOHQTmAeOAVDM7eQAXib/3S4AbzGwH4e7aK4BHiPztBsA5V+a9VhLe0Y/mPH7rkRj6y4BC78x+LHArMNvnmi6k2cB0b3o6MMvHWtqF15/7NLDBOffLFosietvNLMs7wsfM4oGrCJ/PmAf8jbdaxG23c+4+51yec66A8H/P7zrnphHh2w1gZolm1vXkNDAZWMt5/NYj8o5cM7uWcB9gCHjGOfcTfytqH2b2B+AywkOtVgD3A68BLwL5hIelvsU59/GTvZ2amU0AFgJr+N8+3u8R7teP2G03s2GET9qFCB+wveic+5GZ9SF8BJwOrABuc87V+1dp+/G6d77tnLs+CNvtbeOr3mw08Hvn3E/MLINz/K1HZOiLiMjpRWL3joiIfAKFvohIgCj0RUQCRKEvIhIgCn0RkQBR6IuIBIhCX0QkQP4/MH87jcERht8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(w.epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game ['defensive', 'whew', '12-13', 'calls', 'brewer', 'tying', '9/30', 'jays', 'determines', 'hill', 'tuesday', 'legitimately', \"n't\", 'games', 'would', 'vs.', 'maintain', 'marginal', 'league', 'belcher'] \n",
      "\n",
      "bat ['great', '19-8', 'nights', 'lineup', '9/29', 'joined', 'making', 'outshone', 'two', 'extremely', 'thompson', 'defensive', 'shortstops', 'jumped', 'defined', 'promote', 'coons', 'role', 'squeeze', 'meant'] \n",
      "\n",
      "play ['ken', 'entered', 'think', 'next', 'things', 'hoyt', 'including', 'let', 'occured', 'twin', 'best', 'hundley', '9/25', '2-9', 'defeated', 'three-run', 'time', '10/2', 'jays', 'track'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "def get_distance_matrix(wordvecs, metric):\n",
    "    dist_matrix = distance.squareform(distance.pdist(wordvecs, metric))\n",
    "    return dist_matrix\n",
    "\n",
    "def get_k_similar_words(word, dist_matrix, token_to_id, id_to_token, k=20):\n",
    "    idx = token_to_id[word]\n",
    "    dists = dist_matrix[idx]\n",
    "    ind = np.argpartition(dists, k)[:k+1]\n",
    "    ind = ind[np.argsort(dists[ind])][1:]\n",
    "    out = [(i, id_to_token[i], dists[i]) for i in ind]\n",
    "    return out\n",
    "\n",
    "sim_matrix = get_distance_matrix(w.model[\"W\"], 'cosine')\n",
    "for word in ['game', 'bat', 'play']:\n",
    "    print(word, [t[1] for t in get_k_similar_words(word, sim_matrix, w.token_to_id, w.id_to_token)], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_20newsgroups(data_home=\"/Users/flint/Data/sklearn/\", subset='train', \n",
    "                           remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for doc in train.data:\n",
    "    for s in nltk.tokenize.sent_tokenize(doc):\n",
    "        sentences.append(s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [[x for x in word_tokenize(t) if x not in sw and x not in \n",
    "           string.punctuation] for t in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=tokens, vector_size=100, \n",
    "                 window=6, epochs=20, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('handgun', 0.7424942851066589),\n",
       " ('guns', 0.7384911179542542),\n",
       " ('hcikkk', 0.6669428944587708),\n",
       " ('unsurprisingly', 0.6582044363021851),\n",
       " ('control', 0.6468204259872437),\n",
       " ('crime', 0.6425794363021851),\n",
       " ('firearms', 0.6380162239074707),\n",
       " ('assault', 0.6378325819969177),\n",
       " ('owning', 0.637177586555481),\n",
       " ('handguns', 0.6165255308151245)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('gun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6944172"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('play', 'game')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model and specialized models\n",
    "Word embedding may be used also to get the specific shift of words among different corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics = copy.deepcopy(model)\n",
    "religion = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_docs = []\n",
    "religion_docs = []\n",
    "for i, text in enumerate(train.data):\n",
    "    class_label = train.target_names[train.target[i]]\n",
    "    if class_label in ['talk.politics.misc', 'talk.religion.misc']:\n",
    "        for sentence in nltk.tokenize.sent_tokenize(text):\n",
    "            tokens = [x for x in word_tokenize(sentence) if x not in sw and x not in string.punctuation]\n",
    "            if class_label == 'talk.politics.misc':\n",
    "                politics_docs.append(tokens)\n",
    "            else:\n",
    "                religion_docs.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the model for specific corpora to obtain specific fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics.train(politics_docs, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "religion.train(religion_docs, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics.wv.most_similar('gun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "religion.wv.most_similar('gun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "religion.wv.similarity('church', 'person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics.wv.similarity('church', 'person')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load_word2vec_format(datapath(\"/Users/flint/Data/word2vec/GoogleNews-vectors-negative300.bin\"), \n",
    "                                       binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321839332581),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134343147278),\n",
       " ('sultan', 0.5098593831062317),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['king', 'woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'car'\t'minivan'\t0.69\n",
      "'car'\t'bicycle'\t0.54\n",
      "'car'\t'airplane'\t0.42\n",
      "'car'\t'cereal'\t0.14\n",
      "'car'\t'communism'\t0.06\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle 0.7821096181869507\n",
      "cars 0.7423831224441528\n",
      "SUV 0.7160962224006653\n",
      "minivan 0.6907036900520325\n",
      "truck 0.6735789775848389\n",
      "Car 0.6677608489990234\n",
      "Ford_Focus 0.667320191860199\n",
      "Honda_Civic 0.6626849174499512\n",
      "Jeep 0.651133120059967\n",
      "pickup_truck 0.6441438794136047\n"
     ]
    }
   ],
   "source": [
    "for x, y in wv.most_similar('car'):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for word in ['car', 'minivan', 'bicycle', 'airplane']:\n",
    "    vectors.append(wv.get_vector(word))\n",
    "V = np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = V.mean(axis=0)\n",
    "#v = v - wv.get_vector('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('car', 0.852258026599884),\n",
       " ('minivan', 0.8156529664993286),\n",
       " ('vehicle', 0.7754934430122375),\n",
       " ('SUV', 0.7660486698150635),\n",
       " ('bicycle', 0.7264742255210876),\n",
       " ('pickup_truck', 0.723552942276001),\n",
       " ('scooter', 0.7198848724365234),\n",
       " ('truck', 0.7041884064674377),\n",
       " ('Jeep', 0.7000145316123962),\n",
       " ('motorcycle', 0.6802986264228821)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogy and compositionality\n",
    "\n",
    "FRANCE : PARIS = ITALY : ?\n",
    "\n",
    "PARIS - FRANCE + ITALY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Milan', 0.7222141623497009),\n",
       " ('Rome', 0.702830970287323),\n",
       " ('Palermo_Sicily', 0.5967570543289185),\n",
       " ('Italian', 0.5911272764205933),\n",
       " ('Tuscany', 0.5632812976837158),\n",
       " ('Bologna', 0.5608358383178711),\n",
       " ('Sicily', 0.5596384406089783),\n",
       " ('Bologna_Italy', 0.5470058917999268),\n",
       " ('Berna_Milan', 0.5464027523994446),\n",
       " ('Genoa', 0.5308900475502014)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['Paris', 'Italy'], negative=['France'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.doesnt_match(\"school professor apple student\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = wv['school']\n",
    "vr = wv['professor']\n",
    "vx = wv['student']\n",
    "m = (vp + vr + vx) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('student', 0.8481254577636719),\n",
       " ('professor', 0.7627506852149963),\n",
       " ('teacher', 0.6942789554595947),\n",
       " ('school', 0.6849855780601501),\n",
       " ('students', 0.6768636703491211),\n",
       " ('lecturer', 0.6700003147125244),\n",
       " ('faculty', 0.645453155040741),\n",
       " ('university', 0.6376535892486572),\n",
       " ('professors', 0.6346085667610168),\n",
       " ('associate_professor', 0.6325882077217102)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    ('lecturer', 'school'),\n",
    "    ('lecturer', 'professor'),\n",
    "    ('lecturer', 'student'),\n",
    "    ('lecturer', 'teacher'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar('buy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.similarity('buy', 'money')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crike",
   "language": "python",
   "name": "crike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
