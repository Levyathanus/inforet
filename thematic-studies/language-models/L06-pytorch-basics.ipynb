{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks using PyTorch\n",
    "See also the [PyTorch tutorial](https://pytorch.org/tutorials/beginner/nlp/deep_learning_tutorial.html#sphx-glr-beginner-nlp-deep-learning-tutorial-py)\n",
    "\n",
    "We want to model\n",
    "\n",
    "$$f(\\mathbf{x}) = \\mathbf{A}x + \\mathbf{b}$$\n",
    "\n",
    "where the vector $\\mathbf{x}$ is the input and the matrix and vector $\\mathbf{A}$ and $\\mathbf{b}$ are the parameters $\\Theta$ that we want to learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study\n",
    "We aim at training a network for guessing the correct word having as input an arbitrary string of characters (useful for spelling correction for example).\n",
    "\n",
    "### Input and output\n",
    "The output is a set of words (or *phrase words* such as 'you are'), represented as a one-hot vector $\\mathbf{w}$ of size $V$, having $V$ the size of the vocabulary.\n",
    "The input is a set of strings. Each string is represented as a matrix of characters $\\mathbf{C} \\in \\mathbb{R}^{28 \\times 28}$, where the 28 dimensions correspond to one ascii lowercase character plus a dimension for whitespace and another dimension for any other character.\n",
    "\n",
    "Each entry $[c_{ij}]$ represents a bigram which states that the character $j$ is the character that follows $i$ in the string. Given an input string $s$, we calcuate:\n",
    "\n",
    "$$[c_{ij}] = \\frac{count(c_i, c_j)}{\\max\\limits_{c_x, c_y \\in s} count(c_x, c_y)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = string.ascii_lowercase + string.whitespace + '#'\n",
    "CHAR_INDEX = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "    out = \"\"\n",
    "    for c in s.lower():\n",
    "        if c in CHAR_INDEX.keys():\n",
    "            out += c\n",
    "        else:\n",
    "            out += '#'\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_matrix(s, n=2):\n",
    "    z = preprocess(s)\n",
    "    C = np.zeros((len(CHAR_INDEX), len(CHAR_INDEX)))\n",
    "    for a, b in nltk.ngrams(z, n=n):\n",
    "        C[CHAR_INDEX[a], CHAR_INDEX[b]] += 1\n",
    "    C /= C.max()\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_string(s, ax, n=2):\n",
    "    S = string_to_matrix(s, n=n)\n",
    "    ax.imshow(S, cmap='Greys')\n",
    "    ax.set_title(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = [['play', 'plays', 'playing'], ['you are', \"you're\", 'yours']]\n",
    "fig, ax = plt.subplots(figsize=(10, 6), ncols=len(example[0]), nrows=len(example))\n",
    "for i, words in enumerate(example):\n",
    "    for j, w in enumerate(words):\n",
    "        visualize_string(w, ax[i,j], n=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions\n",
    "For a given string, the input is a vector $\\mathbf{x} \\in \\mathbb{R}^{28 \\times 28 = 784}$ dimensions obtained by concatenating the rows of the string characters matrix. The output will be another vector $\\mathbf{\\hat{y}} \\in \\mathbb{R}^V$. But, since we want the output to be a probability distribution, we apply a non-linear transformation to $f(\\mathbf{x})$ called *Softmax*:\n",
    "\n",
    "$$\n",
    "softmax(\\mathbf{\\hat{y}}) = \\frac{\\exp(\\mathbf{\\hat{y}}_i)}{\\sum\\limits_{j=1}^{V} \\exp(\\mathbf{\\hat{y}}_j)}\n",
    "$$\n",
    "\n",
    "so that the complete non-linear transformation is\n",
    "\n",
    "$$\n",
    "\\mathbf{\\hat{y}} = softmax(\\mathbf{A}x + \\mathbf{b})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Given a **loss function** $L(\\Theta)$ and a learning parameter $\\eta$, training in this example is performed by gradient update as\n",
    "\n",
    "$$\n",
    "\\Theta^t = \\Theta^{t-1} - \\eta \\nabla_{\\Theta} L(\\Theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10d7248d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "import gettext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['ITA', 'FRA', 'USA', 'DEU', 'GBR', 'ESP', 'IND', 'CHN']\n",
    "languages = ['de', 'it', 'fr']\n",
    "translator = {}\n",
    "for lang in languages:\n",
    "    translator[lang] = gettext.translation(\n",
    "        'iso3166', pycountry.LOCALES_DIR, languages=[lang])\n",
    "    translator[lang].install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_names(country, translator):\n",
    "    names = []\n",
    "    c = pycountry.countries.get(alpha_3=country)\n",
    "    names.append(c.name)\n",
    "    names.append(c.official_name)\n",
    "    for _, t in translator.items():\n",
    "        names.append(t.gettext(c.name))\n",
    "        names.append(t.gettext(c.official_name))\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Italy',\n",
       " 'Italian Republic',\n",
       " 'Italien',\n",
       " 'Italienische Republik',\n",
       " 'Italia',\n",
       " 'Repubblica italiana',\n",
       " 'Italie',\n",
       " 'République italienne']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_country_names('ITA', translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "training_data, testing_data = [], []\n",
    "for country in countries:\n",
    "    names = get_country_names(country, translator)\n",
    "    np.random.shuffle(names)\n",
    "    training_data.append((names[:6], country))\n",
    "    testing_data.append((names[6:], country))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LABELS = len(countries)\n",
    "V = len(CHAR_INDEX) * len(CHAR_INDEX)\n",
    "LABEL_INDEX = dict((l, i) for i, l in enumerate(countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple2Gram(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_labels, size):\n",
    "        super(Simple2Gram, self).__init__()\n",
    "        self.linear = nn.Linear(size, num_labels)\n",
    "    \n",
    "    def forward(self, vec):\n",
    "        return F.log_softmax(self.linear(vec), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector(s, n=2):\n",
    "    vec = torch.tensor(string_to_matrix(s, n=n)).float()\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "def target(label):\n",
    "    return torch.LongTensor([LABEL_INDEX[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple2Gram(N_LABELS, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0232,  0.0252, -0.0071,  ...,  0.0276,  0.0177, -0.0157],\n",
      "        [-0.0300,  0.0115,  0.0170,  ..., -0.0122,  0.0145,  0.0083],\n",
      "        [-0.0116,  0.0185, -0.0097,  ..., -0.0171, -0.0184,  0.0082],\n",
      "        ...,\n",
      "        [ 0.0020, -0.0153, -0.0293,  ..., -0.0090, -0.0055, -0.0013],\n",
      "        [ 0.0020,  0.0133,  0.0229,  ..., -0.0209, -0.0280, -0.0164],\n",
      "        [ 0.0227,  0.0297, -0.0125,  ..., -0.0215,  0.0244, -0.0138]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0033,  0.0102, -0.0202, -0.0028, -0.0102, -0.0072, -0.0110,  0.0194],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the model without training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sample = training_data[0]\n",
    "    vec = vector(sample[0][0], n=2)\n",
    "    log_probs = model(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0635, -2.0689, -2.0875, -2.0680, -2.1185, -2.0148, -2.1776, -2.0451]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "    for samples, label in training_data:\n",
    "        for instance in samples:\n",
    "            model.zero_grad()\n",
    "            vec = vector(instance)\n",
    "            tar = target(label)\n",
    "            log_probs = model(vec)\n",
    "            L = loss(log_probs, tar)\n",
    "            L.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.6093e-03, -8.4416e+00, -6.2243e+00, -7.1669e+00, -7.6948e+00,\n",
      "         -7.8157e+00, -7.6101e+00, -8.1921e+00]])\n",
      "Input string: Italie\n",
      "Guess: ITA \n",
      "\n",
      "tensor([[-3.6591e-03, -8.8909e+00, -6.3918e+00, -7.7374e+00, -8.1160e+00,\n",
      "         -7.8405e+00, -7.4865e+00, -8.8019e+00]])\n",
      "Input string: Italien\n",
      "Guess: ITA \n",
      "\n",
      "tensor([[-1.4202, -0.3974, -7.4095, -3.1033, -6.6508, -6.6253, -6.2852, -3.3168]])\n",
      "Input string: Französische Republik\n",
      "Guess: FRA \n",
      "\n",
      "tensor([[-0.9964, -1.5369, -3.7776, -3.0368, -4.1242, -2.6001, -2.8445, -1.6282]])\n",
      "Input string: French Republic\n",
      "Guess: ITA \n",
      "\n",
      "tensor([[-5.5274, -6.7789, -0.0292, -5.3894, -4.4423, -5.4580, -6.5894, -6.4062]])\n",
      "Input string: Stati Uniti d'America\n",
      "Guess: USA \n",
      "\n",
      "tensor([[-6.2207, -7.3520, -0.0249, -6.1863, -4.6118, -5.5297, -6.0948, -5.5859]])\n",
      "Input string: Vereinigte Staaten von Amerika\n",
      "Guess: USA \n",
      "\n",
      "tensor([[-5.7635, -5.1152, -4.6296, -0.0421, -4.4459, -5.1140, -5.7714, -6.5394]])\n",
      "Input string: Germania\n",
      "Guess: DEU \n",
      "\n",
      "tensor([[-3.3590, -4.3396, -4.7659, -0.5489, -3.1659, -4.7696, -1.2422, -3.6242]])\n",
      "Input string: Bundesrepublik Deutschland\n",
      "Guess: DEU \n",
      "\n",
      "tensor([[-4.1868, -6.2053, -2.7833, -6.1162, -0.1581, -2.8181, -6.3970, -5.6325]])\n",
      "Input string: Regno Unito\n",
      "Guess: GBR \n",
      "\n",
      "tensor([[-4.8002, -4.1434, -1.4015, -4.0729, -1.1975, -1.2443, -4.0806, -2.2478]])\n",
      "Input string: Vereinigtes Königreich\n",
      "Guess: GBR \n",
      "\n",
      "tensor([[-5.7431, -5.7511, -5.7581, -6.1137, -5.4975, -0.0181, -6.4275, -7.7152]])\n",
      "Input string: Spanien\n",
      "Guess: ESP \n",
      "\n",
      "tensor([[-4.7000, -4.4665, -3.8299, -4.4138, -3.2528, -0.3901, -2.3992, -1.9723]])\n",
      "Input string: Kingdom of Spain\n",
      "Guess: ESP \n",
      "\n",
      "tensor([[-4.5116, -7.9751, -9.2015, -6.6332, -8.3612, -8.4098, -0.0162, -5.8537]])\n",
      "Input string: Republic of India\n",
      "Guess: IND \n",
      "\n",
      "tensor([[-3.9324, -5.6649, -6.7833, -3.4991, -5.1519, -6.9780, -0.2247, -1.9655]])\n",
      "Input string: République d'Inde\n",
      "Guess: IND \n",
      "\n",
      "tensor([[-5.8175e+00, -9.0536e+00, -1.0076e+01, -6.6639e+00, -9.4307e+00,\n",
      "         -9.1007e+00, -7.4834e+00, -5.1777e-03]])\n",
      "Input string: People's Republic of China\n",
      "Guess: CHN \n",
      "\n",
      "tensor([[-5.5511e+00, -8.8435e+00, -1.0321e+01, -8.6906e+00, -1.0045e+01,\n",
      "         -8.7812e+00, -6.4589e+00, -6.0101e-03]])\n",
      "Input string: Volksrepublik China\n",
      "Guess: CHN \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for test, label in testing_data:\n",
    "        for word in test:\n",
    "            vec = vector(word, n=2)\n",
    "            log_probs = model(vec)\n",
    "            print(log_probs)\n",
    "            print('Input string:', word)\n",
    "            prediction = np.argmax(log_probs.numpy())\n",
    "            print('Guess:', countries[prediction], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = lambda x: Categorical(probs=x).entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for test, label in testing_data:\n",
    "        for word in test:\n",
    "            vec = vector(word, n=2)\n",
    "            predictions.append(model(vec))\n",
    "            y_true.append(LABEL_INDEX[label])\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = sum([entropy(p) for p in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30.9901])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [np.argmax(p.numpy()) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ITA       0.67      1.00      0.80         2\n",
      "         FRA       1.00      0.50      0.67         2\n",
      "         USA       1.00      1.00      1.00         2\n",
      "         DEU       1.00      1.00      1.00         2\n",
      "         GBR       1.00      1.00      1.00         2\n",
      "         ESP       1.00      1.00      1.00         2\n",
      "         IND       1.00      1.00      1.00         2\n",
      "         CHN       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.96      0.94      0.93        16\n",
      "weighted avg       0.96      0.94      0.93        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=countries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make things harder\n",
    "In the following we simulate some spelling errors to see if the network can handle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_chars(s, substitutions=2):\n",
    "    w = list(s)\n",
    "    for iteration in range(substitutions):\n",
    "        n = np.random.choice(list(string.ascii_lowercase))\n",
    "        i = np.random.randint(0, len(w))\n",
    "        w[i] = n\n",
    "    return \"\".join(w)\n",
    "\n",
    "def add_chars(s, additions=2):\n",
    "    w = list(s)\n",
    "    for iteration in range(additions):\n",
    "        n = np.random.choice(list(string.ascii_lowercase))\n",
    "        i = np.random.randint(0, len(w))\n",
    "        w = w[:i] + list(n) + w[i:]\n",
    "    return \"\".join(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_test, h = [], 3\n",
    "for test, label in testing_data:\n",
    "    nk = []\n",
    "    for word in test:\n",
    "        nk.append(substitute_chars(word, substitutions=h))\n",
    "        nk.append(add_chars(word, additions=h))\n",
    "    h_test.append((test + nk, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for test, label in h_test:\n",
    "        for word in test:\n",
    "            vec = vector(word, n=2)\n",
    "            predictions.append(model(vec))\n",
    "            y_true.append(LABEL_INDEX[label])\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([93.4591])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([entropy(p) for p in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [np.argmax(p.numpy()) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ITA       0.67      1.00      0.80         6\n",
      "         FRA       1.00      0.50      0.67         6\n",
      "         USA       0.86      1.00      0.92         6\n",
      "         DEU       1.00      0.67      0.80         6\n",
      "         GBR       1.00      0.50      0.67         6\n",
      "         ESP       0.67      1.00      0.80         6\n",
      "         IND       0.83      0.83      0.83         6\n",
      "         CHN       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.81        48\n",
      "   macro avg       0.86      0.81      0.80        48\n",
      "weighted avg       0.86      0.81      0.80        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=countries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/spelling_correction_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for sample, label in testing_data:\n",
    "    for word in sample:\n",
    "        vectors.append(vector(word).numpy())\n",
    "X = torch.tensor(np.array(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model, X)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
