{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate new text\n",
    "We want to predict\n",
    "\n",
    "$$\\hat{P}(w_i \\mid w_1, \\dots, w_{i-1})$$\n",
    "\n",
    "In order to exploit the probability distribution $\\phi(V)$ over the vocabulary that is used to predict the next word as a tool for extracting the next word during the text generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study\n",
    "We aim at training a network for a Movie in the Movie-Dialog dataset. Instead of using simple tokens, we create artificial tokens by combining a token with its part-of-speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from langmodels.corpora.moviedialog import MovieDialogCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "Since we do not have single words, but words plus POS, we cannot use a pre-trained word embedding model. Thus, we create one custom model, using a larger corpus (see the [example](https://github.com/afflint/inforet/blob/master/thematic-studies/language-models/L04-wordembeddings.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = ['western']\n",
    "ug = {'$unwind': '$character.movie.genres'}\n",
    "mg = {'$match': {'character.movie.genres': {'$in': genre}}}\n",
    "pg = {'$project': {'_id': 0, 'id': 1, 'text': 1}}\n",
    "pipeline = [ug, mg, pg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'movie-dialogs'\n",
    "collection = 'lines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = MovieDialogCollection(db_name, collection, \n",
    "                                use_pos=False, \n",
    "                                mix_pos=True, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = Word2Vec.load('../../data/token_pos.word2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an embedding matrix for feeding the network\n",
    "For each word in datasetâ€™s vocabulary, we check if it is on Word2Vec vocabulary. If it do it, we load its pre-trained word vector. Otherwise, we initialize a random vector. Moreover, we add two special random vectors for the start sentence token `#S` and the end token `#E`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = corpus.vocabulary + ['#S', '#E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = dict([(w, i) for i, w in enumerate(V)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(V), embedding_model.vector_size))\n",
    "for word, i in word2idx.items():\n",
    "    try: \n",
    "        embedding_matrix[i] = embedding_model.wv[word]\n",
    "    except KeyError:\n",
    "        embedding_matrix[i] = np.random.normal(size=(embedding_model.vector_size, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.wv['he_PRON'] - embedding_matrix[word2idx['he_PRON']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model embedding layer\n",
    "We now create an embedding layer to be used as input for the network. This is non trainable, because we already have fitted it with the pre-trained word embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a307eb1b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(embedding_matrix, non_trainable=True):\n",
    "    num_embeddings, embedding_dim = embedding_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': torch.tensor(embedding_matrix)})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = create_emb_layer(embedding_matrix, non_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a simple NGram language model\n",
    "Simple example taken from [pytorch tutorials](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, emb_matrix, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder, num_embeddings, embedding_dim = create_emb_layer(emb_matrix, non_trainable=True)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size, n_layers, batch_first=True,\n",
    "                          bidirectional=False)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        self.output = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input_data, hidden):\n",
    "        input_data = self.encoder(input_data.view(1, -1))\n",
    "        output, hidden = self.gru(input_data.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        output = self.output(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.n_layers, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=len(V), hidden_size=64, output_size=len(V), emb_matrix=embedding_matrix, n_layers=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = []\n",
    "for _, tokens in corpus.get_tokens():\n",
    "    for a, b, c in nltk.ngrams(tokens, n=3):\n",
    "        training_set.append(([a, b], [c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['now_ADV', 'you_PRON'], ['tell_VERB'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(tokens):\n",
    "    return torch.tensor([word2idx[w] for w in tokens], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = prepare(training_set[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3411, 4550])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3411]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0].view(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "- Create input and target tensors\n",
    "- Create a zeroed initial hidden state\n",
    "- Read each word input and **keep hidden state** for next word\n",
    "- Compare final output to target\n",
    "- Back-propagate\n",
    "- Return the output and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a97872b9ed4d88953974302007f447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = tqdm_notebook(list(range(30)))\n",
    "losses = []\n",
    "limit = 1000 # just to speed up things in the examples\n",
    "for epoch in epochs:\n",
    "    total_loss = 0\n",
    "    for context_words, target_word in training_set[:limit]:\n",
    "        hidden = model.init_hidden()\n",
    "        model.zero_grad()\n",
    "        context, target = prepare(context_words), prepare(target_word)\n",
    "        for i in range(context.size()[0]):\n",
    "            output, hidden = model(context[i], hidden)\n",
    "        error = loss(output, target)\n",
    "        error.backward()\n",
    "        total_loss += error.item()\n",
    "    losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,3))\n",
    "ax.plot(losses, marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, hidden = model(prepare(['#S']), model.init_hidden())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.8745, -8.6447, -9.1027,  ..., -9.0204, -8.5116, -8.8660]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reward_NOUN'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[prediction.argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(start='#S', max_len=5):\n",
    "    text = [start]\n",
    "    for w in range(max_len):\n",
    "        prediction, hidden = model(prepare([text[-1]]), model.init_hidden())\n",
    "        next_word = np.random.choice(V, p=np.exp(prediction.detach().numpy()[0]))\n",
    "        text.append(next_word)\n",
    "        if next_word == '#E':\n",
    "            break\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#S', 'cares_VERB', 'smile_NOUN', 'bust_NOUN', 'killin_NOUN', 'haired_ADJ']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
