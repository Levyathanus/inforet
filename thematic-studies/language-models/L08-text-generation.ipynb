{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate new text\n",
    "We want to predict\n",
    "\n",
    "$$\\hat{P}(w_i \\mid w_1, \\dots, w_{i-1})$$\n",
    "\n",
    "In order to exploit the probability distribution $\\phi(V)$ over the vocabulary that is used to predict the next word as a tool for extracting the next word during the text generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study\n",
    "We aim at training a network for a Movie in the Movie-Dialog dataset. Instead of using simple tokens, we create artificial tokens by combining a token with its part-of-speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from langmodels.corpora.moviedialog import MovieDialogCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "Since we do not have single words, but words plus POS, we cannot use a pre-trained word embedding model. Thus, we create one custom model, using a larger corpus (see the [example](https://github.com/afflint/inforet/blob/master/thematic-studies/language-models/L04-wordembeddings.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = ['western']\n",
    "ug = {'$unwind': '$character.movie.genres'}\n",
    "mg = {'$match': {'character.movie.genres': {'$in': genre}}}\n",
    "pg = {'$project': {'_id': 0, 'id': 1, 'text': 1}}\n",
    "pipeline = [ug, mg, pg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'movie-dialogs'\n",
    "collection = 'lines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = MovieDialogCollection(db_name, collection, \n",
    "                                use_pos=False, \n",
    "                                mix_pos=True, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = Word2Vec.load('../../data/token_pos.word2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an embedding matrix for feeding the network\n",
    "For each word in datasetâ€™s vocabulary, we check if it is on Word2Vec vocabulary. If it do it, we load its pre-trained word vector. Otherwise, we initialize a random vector. Moreover, we add two special random vectors for the start sentence token `#S` and the end token `#E`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = corpus.vocabulary + ['#S', '#E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = dict([(w, i) for i, w in enumerate(V)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(V), embedding_model.vector_size))\n",
    "for word, i in word2idx.items():\n",
    "    try: \n",
    "        embedding_matrix[i] = embedding_model.wv[word]\n",
    "    except KeyError:\n",
    "        embedding_matrix[i] = np.random.normal(size=(embedding_model.vector_size, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.wv['he_PRON'] - embedding_matrix[word2idx['he_PRON']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model embedding layer\n",
    "We now create an embedding layer to be used as input for the network. This is non trainable, because we already have fitted it with the pre-trained word embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f901cad8110>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(embedding_matrix, non_trainable=True):\n",
    "    num_embeddings, embedding_dim = embedding_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': torch.tensor(embedding_matrix)})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = create_emb_layer(embedding_matrix, non_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a simple NGram language model\n",
    "Simple example taken from [pytorch tutorials](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, emb_matrix, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder, num_embeddings, embedding_dim = create_emb_layer(emb_matrix, non_trainable=True)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size, n_layers, batch_first=True,\n",
    "                          bidirectional=False)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        self.output = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input_data, hidden):\n",
    "        input_data = self.encoder(input_data.view(1, -1))\n",
    "        output, hidden = self.gru(input_data.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        output = self.output(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.n_layers, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=len(V), hidden_size=64, output_size=len(V), emb_matrix=embedding_matrix, n_layers=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = []\n",
    "for _, tokens in corpus.get_tokens():\n",
    "    for a, b, c in nltk.ngrams(tokens, n=3):\n",
    "        training_set.append(([a, b], [c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['now_ADV', 'you_PRON'], ['tell_VERB'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(tokens):\n",
    "    return torch.tensor([word2idx[w] for w in tokens], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = prepare(training_set[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 201, 1296])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[201]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0].view(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "- Create input and target tensors\n",
    "- Create a zeroed initial hidden state\n",
    "- Read each word input and **keep hidden state** for next word\n",
    "- Compare final output to target\n",
    "- Back-propagate\n",
    "- Return the output and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e5df7150704ffda501c4792f6db047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = tqdm(list(range(10)))\n",
    "losses = []\n",
    "limit = 50 # just to speed up things in the examples\n",
    "hidden = model.init_hidden()\n",
    "\n",
    "for epoch in epochs:\n",
    "    total_loss = 0\n",
    "    for context_words, target_word in training_set[:limit]:\n",
    "        model.zero_grad()\n",
    "        context, target = prepare(context_words), prepare(target_word)\n",
    "        for i in range(context.size()[0]):\n",
    "            output, hidden = model(context[i], hidden)\n",
    "        error = loss(output, target)\n",
    "        error.backward(retain_graph=True)\n",
    "        total_loss += error.item()\n",
    "    losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,3))\n",
    "ax.plot(losses, marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, hidden = model(prepare(['#S']), model.init_hidden())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.2731, -8.8434, -8.9895,  ..., -8.8563, -8.8851, -8.9855]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duck_VERB'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[prediction.argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(start='#S', max_len=5):\n",
    "    text = [start]\n",
    "    for w in range(max_len):\n",
    "        prediction, hidden = model(prepare([text[-1]]), model.init_hidden())\n",
    "        next_word = np.random.choice(V, p=np.exp(prediction.detach().numpy()[0]))\n",
    "        text.append(next_word)\n",
    "        if next_word == '#E':\n",
    "            break\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#S',\n",
       " 'dunno_INTJ',\n",
       " 'operative_ADJ',\n",
       " 'exploiting_VERB',\n",
       " 'feminine_ADJ',\n",
       " 'drop_VERB']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
