{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Materials by Francesco Periti and Elisabetta Rocchetti"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers recap:\n",
    "<center><img src=\"https://pytorch.org/tutorials/_images/transformer_architecture.jpg\" width=\"30%\"/></center>\n",
    "Both the decoder and the encoder have language understanding. Idea: use only either the decoder or the encoder!\n",
    "\n",
    "Example of Transformer models in real world:\n",
    "\n",
    "- Generative Pre-Training or GPT (Radford et al., “Improving Language Understanding by Generative Pre-Training.”)\n",
    "- Bidirectional Encoder Representations from Transformers or BERT (Devlin et al., “BERT.”)\n",
    "\n",
    "GPT looks like this:\n",
    "<center><img src=\"img/gpt.png\" width=\"30%\"/></center>\n",
    "\n",
    "Main properties of GPT:\n",
    "\n",
    "- transfer learning paradigm\n",
    "- based on Transformers decoder\n",
    "\n",
    "BERT looks like this:\n",
    "<center><img src=\"img/bert.png\" width=\"30%\"/></center>\n",
    "\n",
    "Main properties of BERT:\n",
    "\n",
    "- transfer learning paradigm\n",
    "- based on Transformers encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "But... what is transfer learning? Training procedure in 2 steps:\n",
    "\n",
    "1. Pre-training: understand language $\\rightarrow$ high computational cost\n",
    "2. Fine tuning: understand how to solve task, given that I have language knowledge $\\rightarrow$ low computational cost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why BERT? Unlike GPT, it is bidirectional: this means that it can learn from both left and right context! c:\n",
    "\n",
    "... but we loose the benefits of masked multi-head attention :c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "<center><img src=\"img/bert.svg\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input/Output Representations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected input: either a single sentence or a pair of sentences. \n",
    "\n",
    "Tokenization: WordPiece tokenizer [Wu et al., “Google’s Neural Machine Translation System.”].\n",
    "\n",
    "The sequence must start with $\\text{[CLS]}$, and each sentence must end with $\\text{[SEP]}$.\n",
    "$$\\text{Raccoons love eating. They are playful.} \\rightarrow \\text{[CLS] Raccoons love eating. [SEP] They are playful. [SEP]}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details on WordPiece tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation of WordPiece tokenizer is similar to Byte-Pair Encoding [Sennrich, Haddow, and Birch, “Neural Machine Translation of Rare Words with Subword Units.”] and is described in more detail in [Schuster and Nakajima, “Japanese and Korean Voice Search.”].\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Extract all the words from the dataset along with their count\n",
    "2. Split all the words into character sequences\n",
    "3. Define a vocabulary size\n",
    "4. Add all the unique characters present in the character sequences to the vocabulary\n",
    "5. Identify symbol pair having the highest score. Merge it, and add it to the vocabulary\n",
    "6. Repeat Step 5 until you reach the vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torch.utils.data import DataLoader\n",
    "import datasets\n",
    "\n",
    "dataset = torchtext.datasets.WikiText2(split = 'train')\n",
    "batch_size = 30\n",
    "data_loader = iter(DataLoader(dataset, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "class WordPieceTokenizer:\n",
    "    def __init__(self, vocabulary_size):\n",
    "        self.word_counter = Counter()\n",
    "        #3\n",
    "        self.vocab_size = vocabulary_size\n",
    "        #4 and 5\n",
    "        self.vocab = Counter()\n",
    "          \n",
    "    #1\n",
    "    def extract_words(self, batch):\n",
    "        res_batch = []\n",
    "        for sentence in batch:\n",
    "            tokenized = nltk.word_tokenize(sentence.lower().strip())\n",
    "            self.word_counter.update(tokenized)\n",
    "            res_batch.append(tokenized)\n",
    "        return res_batch\n",
    "    \n",
    "    #2\n",
    "    def split_char(self, batch):\n",
    "        res_batch = []\n",
    "        for sentence in batch:\n",
    "            res_batch.append([[c for c in word] for word in sentence])\n",
    "        return res_batch\n",
    "    \n",
    "    #4\n",
    "    def add_unique_chars(self, batch):\n",
    "        batch_split = self.split_char(batch)\n",
    "        for sentence in batch_split:\n",
    "            for word in sentence:\n",
    "                self.vocab.update(word)\n",
    "    \n",
    "    #5\n",
    "    def count_likelihood(self):\n",
    "        pair_counter = Counter()     \n",
    "        for word, word_count in self.word_counter.items():\n",
    "            word = self.word_tokenize(word)\n",
    "            if len(word) < 2: continue \n",
    "            for i in range(len(word)-1):\n",
    "                pair_counter.update([(word[i], word[i+1])] * word_count)\n",
    "        likelihoods = {k: v/(self.vocab[k[0]]*self.vocab[k[1]]) for k, v in pair_counter.items()}\n",
    "        likelihoods = sorted(likelihoods.items(), key=lambda x: x[1])\n",
    "        return likelihoods, pair_counter\n",
    "    \n",
    "    def add_frequent(self, logging = False):\n",
    "        while len(self.vocab) < self.vocab_size:\n",
    "            likelihoods, counter = self.count_likelihood()\n",
    "            found_next = False\n",
    "            while not found_next:\n",
    "                if not likelihoods: return len(self.vocab) < self.vocab_size\n",
    "                new_frequent_split = likelihoods.pop()\n",
    "                if not f'{new_frequent_split[0][0]}{new_frequent_split[0][1]}' in self.vocab: found_next = True\n",
    "            self.vocab.update({f'{new_frequent_split[0][0]}{new_frequent_split[0][1]}':counter[new_frequent_split[0]]})\n",
    "            if logging: \n",
    "                print(f'The pair \"{new_frequent_split[0][0]}{new_frequent_split[0][1]}\" having score {new_frequent_split[1]} has been added')\n",
    "                print(f'Updated vocabulary: {self.vocab}')\n",
    "        return len(self.vocab) == self.vocab_size\n",
    "    \n",
    "    def word_tokenize(self, word):\n",
    "        if len(word)==1:\n",
    "            return [word]\n",
    "        splits = []\n",
    "        i = 0\n",
    "        word_temp = word\n",
    "        while ''.join(splits) !=  word:\n",
    "            if i < len(word_temp):\n",
    "                split = word_temp[0:len(word_temp)-i]\n",
    "                if split in self.vocab:\n",
    "                    splits.append(split)\n",
    "                    word_temp = word_temp[len(split):]\n",
    "                    i=0\n",
    "                else:\n",
    "                    i = i+1\n",
    "            else:\n",
    "                splits = splits + [word_temp]\n",
    "        return splits\n",
    "    \n",
    "    def tokenize(self, sentence):\n",
    "        sentence_tokenized = []\n",
    "        for word in nltk.word_tokenize(sentence.lower().strip()):\n",
    "            sentence_tokenized.append(self.word_tokenize(word))\n",
    "        return sentence_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pair \"iv\" having score 1.0 has been added\n",
      "Updated vocabulary: Counter({'e': 5, 'h': 3, 'o': 3, 's': 3, 'u': 2, 'r': 2, 'm': 1, 'n': 1, 'i': 1, 'v': 1, 'iv': 1})\n",
      "The pair \"niv\" having score 1.0 has been added\n",
      "Updated vocabulary: Counter({'e': 5, 'h': 3, 'o': 3, 's': 3, 'u': 2, 'r': 2, 'm': 1, 'n': 1, 'i': 1, 'v': 1, 'iv': 1, 'niv': 1})\n",
      "The pair \"univ\" having score 0.5 has been added\n",
      "Updated vocabulary: Counter({'e': 5, 'h': 3, 'o': 3, 's': 3, 'u': 2, 'r': 2, 'm': 1, 'n': 1, 'i': 1, 'v': 1, 'iv': 1, 'niv': 1, 'univ': 1})\n",
      "The pair \"rs\" having score 0.3333333333333333 has been added\n",
      "Updated vocabulary: Counter({'e': 5, 'h': 3, 'o': 3, 's': 3, 'u': 2, 'r': 2, 'rs': 2, 'm': 1, 'n': 1, 'i': 1, 'v': 1, 'iv': 1, 'niv': 1, 'univ': 1})\n",
      "The pair \"om\" having score 0.3333333333333333 has been added\n",
      "Updated vocabulary: Counter({'e': 5, 'h': 3, 'o': 3, 's': 3, 'u': 2, 'r': 2, 'rs': 2, 'm': 1, 'n': 1, 'i': 1, 'v': 1, 'iv': 1, 'niv': 1, 'univ': 1, 'om': 1})\n",
      "The pair \"hom\" having score 0.3333333333333333 has been added\n",
      "Updated vocabulary: Counter({'e': 5, 'h': 3, 'o': 3, 's': 3, 'u': 2, 'r': 2, 'rs': 2, 'm': 1, 'n': 1, 'i': 1, 'v': 1, 'iv': 1, 'niv': 1, 'univ': 1, 'om': 1, 'hom': 1})\n",
      "The pair \"ho\" having score 0.2222222222222222 has been added\n",
      "Updated vocabulary: Counter({'e': 5, 'h': 3, 'o': 3, 's': 3, 'u': 2, 'r': 2, 'rs': 2, 'ho': 2, 'm': 1, 'n': 1, 'i': 1, 'v': 1, 'iv': 1, 'niv': 1, 'univ': 1, 'om': 1, 'hom': 1})\n",
      "The pair \"hors\" having score 0.25 has been added\n",
      "Updated vocabulary: Counter({'e': 5, 'h': 3, 'o': 3, 's': 3, 'u': 2, 'r': 2, 'rs': 2, 'ho': 2, 'm': 1, 'n': 1, 'i': 1, 'v': 1, 'iv': 1, 'niv': 1, 'univ': 1, 'om': 1, 'hom': 1, 'hors': 1})\n",
      "The pair \"hou\" having score 0.25 has been added\n",
      "Updated vocabulary: Counter({'e': 5, 'h': 3, 'o': 3, 's': 3, 'u': 2, 'r': 2, 'rs': 2, 'ho': 2, 'm': 1, 'n': 1, 'i': 1, 'v': 1, 'iv': 1, 'niv': 1, 'univ': 1, 'om': 1, 'hom': 1, 'hors': 1, 'hou': 1})\n",
      "The pair \"hous\" having score 0.3333333333333333 has been added\n",
      "Updated vocabulary: Counter({'e': 5, 'h': 3, 'o': 3, 's': 3, 'u': 2, 'r': 2, 'rs': 2, 'ho': 2, 'm': 1, 'n': 1, 'i': 1, 'v': 1, 'iv': 1, 'niv': 1, 'univ': 1, 'om': 1, 'hom': 1, 'hors': 1, 'hou': 1, 'hous': 1})\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "wptokenizer = WordPieceTokenizer(vocabulary_size=20)\n",
    "b = ['home', 'house', 'horse', 'universe']\n",
    "d = wptokenizer.extract_words(b)\n",
    "wptokenizer.add_unique_chars(d)\n",
    "wptokenizer.add_frequent(logging = True)\n",
    "print(len(wptokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hors', 'e']"
      ]
     },
     "execution_count": 1384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wptokenizer.word_tokenize('horse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wptokenizer = WordPieceTokenizer(vocabulary_size=10000)\n",
    "b = next(data_loader)\n",
    "d = wptokenizer.extract_words(b)\n",
    "wptokenizer.add_unique_chars(d)\n",
    "wptokenizer.add_frequent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence:  = = = January – February = = = \n",
      "\n",
      "Tokenized:[['='], ['='], ['='], ['j', 'an', 'u', 'ar', 'y'], ['–'], ['f', 'e', 'b', 'r', 'u', 'ar', 'y'], ['='], ['='], ['=']]\n"
     ]
    }
   ],
   "source": [
    "example_sentence = next(data_loader)[5]\n",
    "tokenized = wptokenizer.tokenize(example_sentence)\n",
    "print(f'Example sentence: {example_sentence}')\n",
    "print(f'Tokenized:{tokenized}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence:  Flower Fairies of the Winter ; Blackie , 1985 \n",
      "\n",
      "Tokenized:[['flower'], ['fairies'], ['of'], ['the'], ['wi', 'n', 't', 'e', 'r'], [';'], ['blackie'], [','], ['1', '9', '8', '5']]\n"
     ]
    }
   ],
   "source": [
    "example_sentence = next(data_loader)[0]\n",
    "tokenized = wptokenizer.tokenize(example_sentence)\n",
    "print(f'Example sentence: {example_sentence}')\n",
    "print(f'Tokenized:{tokenized}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... on Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: Do you like raccons?\n",
      "Tokenized:['do', 'you', 'like', 'ra', '##cco', '##ns', '?']\n"
     ]
    }
   ],
   "source": [
    "#sentences = example_sentence.split('.')\n",
    "example_sentence = 'Do you like raccons? Yes, I love them!'\n",
    "example_sentence_1, example_sentence_2 = 'Do you like raccons?', 'Yes, I love them!'\n",
    "tokenized_1 = bert_tokenizer.tokenize(example_sentence_1)\n",
    "tokenized_2 = bert_tokenizer.tokenize(example_sentence_2)\n",
    "print(f'Example sentence: {example_sentence_1}')\n",
    "print(f'Tokenized:{tokenized_1}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our tokens, we can extract embeddings for them (as with the Transformers!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ids: [101, 2079, 2017, 2066, 10958, 21408, 3619, 1029, 102, 2748, 1010, 1045, 2293, 2068, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "tokenizer_output = bert_tokenizer(example_sentence_1, example_sentence_2, padding = 'max_length')\n",
    "print(f'Input ids: {tokenizer_output[\"input_ids\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens (512): ['[CLS]', 'do', 'you', 'like', 'ra', '##cco', '##ns', '?', '[SEP]', 'yes', ',', 'i', 'love', 'them', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "tokens = bert_tokenizer.convert_ids_to_tokens(tokenizer_output[\"input_ids\"])\n",
    "print(f'Input tokens ({len(tokens)}): {tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 768])"
      ]
     },
     "execution_count": 1351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 768 #as in the original paper\n",
    "max_seq_len = 512\n",
    "\n",
    "embedding_layer = nn.Embedding(bert_tokenizer.vocab_size, d_model)\n",
    "input_embedding = embedding_layer(torch.IntTensor(tokenizer_output[\"input_ids\"]))\n",
    "input_embedding.size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add position embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self):\n",
    "        i = torch.arange(0,self.d_model,2, dtype=torch.float).repeat_interleave(2)[:self.d_model]\n",
    "        denominator = torch.pow(10000, 2*i/self.d_model)\n",
    "        position = torch.arange(self.max_sequence_length).reshape(self.max_sequence_length, 1)\n",
    "        sin_cos_argument = position/denominator\n",
    "        PE = torch.zeros(size = sin_cos_argument.shape)\n",
    "        PE[:, 0::2] = torch.sin(sin_cos_argument[:, 0::2])\n",
    "        PE[:, 1::2] = torch.cos(sin_cos_argument[:, 1::2])\n",
    "        return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-5.9135e-01, -2.0353e-01,  3.2511e-01,  ...,  8.4548e-01,\n",
       "          9.1684e-01,  3.2428e+00],\n",
       "        [ 4.7695e-01, -5.5562e-01,  2.0502e+00,  ...,  1.2189e+00,\n",
       "         -1.4139e+00,  1.7901e+00],\n",
       "        [ 9.7310e-01,  9.6069e-01,  1.4754e+00,  ..., -5.0557e-04,\n",
       "         -6.6664e-02, -6.6653e-02],\n",
       "        ...,\n",
       "        [ 2.7986e-01,  6.8731e-01,  1.6882e+00,  ..., -1.6535e-01,\n",
       "          3.7201e-01,  7.0767e-01],\n",
       "        [ 1.0912e+00,  1.7637e-01,  1.4525e+00,  ..., -1.6535e-01,\n",
       "          3.7201e-01,  7.0767e-01],\n",
       "        [ 1.0997e+00, -7.8245e-01,  5.9306e-01,  ..., -1.6535e-01,\n",
       "          3.7201e-01,  7.0767e-01]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_output = bert_tokenizer(example_sentence_1, example_sentence_2, truncation=True, padding='max_length', add_special_tokens=True)\n",
    "input_embedding = embedding_layer(torch.IntTensor(tokenizer_output[\"input_ids\"]))\n",
    "print(input_embedding.size())\n",
    "\n",
    "positional_encoding_layer = PositionalEncoding(max_sequence_length=max_seq_len, d_model=d_model)\n",
    "input_embedding = input_embedding + positional_encoding_layer()\n",
    "input_embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 1048,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = torch.tile(torch.IntTensor(tokenizer_output['token_type_ids']).unsqueeze(1), (1, d_model))\n",
    "print(sentence_embeddings.size())\n",
    "sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.9135e-01, -2.0353e-01,  3.2511e-01,  ...,  8.4548e-01,\n",
       "          9.1684e-01,  3.2428e+00],\n",
       "        [ 4.7695e-01, -5.5562e-01,  2.0502e+00,  ...,  1.2189e+00,\n",
       "         -1.4139e+00,  1.7901e+00],\n",
       "        [ 9.7310e-01,  9.6069e-01,  1.4754e+00,  ..., -5.0557e-04,\n",
       "         -6.6664e-02, -6.6653e-02],\n",
       "        ...,\n",
       "        [ 2.7986e-01,  6.8731e-01,  1.6882e+00,  ..., -1.6535e-01,\n",
       "          3.7201e-01,  7.0767e-01],\n",
       "        [ 1.0912e+00,  1.7637e-01,  1.4525e+00,  ..., -1.6535e-01,\n",
       "          3.7201e-01,  7.0767e-01],\n",
       "        [ 1.0997e+00, -7.8245e-01,  5.9306e-01,  ..., -1.6535e-01,\n",
       "          3.7201e-01,  7.0767e-01]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 1049,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding = input_embedding + sentence_embeddings\n",
    "input_embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! BERT is bidirectional: this allows each word to \"see itself\", and the model could trivially predict the target word in a multi-layered context.\n",
    "\n",
    "*SOLUTION*: mask some percentage of the input tokens at random, and then predict those masked tokens! c:\n",
    "\n",
    "This is called **Masked Language Modeling (MLM)**, and it is one of the two pre-training objectives BERT has.\n",
    "\n",
    "Usually, language models are trained to predict each word in a sentence; here, BERT must predict only the masked tokens.\n",
    "\n",
    "**Masking procedure**\n",
    "\n",
    "0. Take 15% of the tokens in the input sentence\n",
    "1. $\\rightarrow$ 80% of those tokens will be replaced with the special token $\\text{[MASK]}$\n",
    "2. $\\rightarrow$ 10% of those tokens will be replaced with a random token\n",
    "3. $\\rightarrow$ 10% of those tokens will remain unchanged\n",
    "\n",
    "**Why 80-10-10?**\n",
    "\n",
    "There may be a mismatch between the pre-training and fine-tuning tasks because the latter does not involve predicting masked words in most of the downstream tasks (e.g. sentiment analysis). The model should be good not only in predicting masked tokens, but also as pre-trained model for other tasks. The advantage of this procedure is that the Transformer encoder does not know which words it will be asked to predict or which have been replaced by random words, so it is forced to keep a distributional contextual representation of every input token.\n",
    "\n",
    "- Just using the $\\text{[MASK]}$ token resulted in the model learning very little about the context of the surrounding words. This seems to occur since the model knows it can “forget” all the information about the surrounding words and focus only on the target word.\n",
    "\n",
    "- If you use the $\\text{[MASK]}$ token 80% of the time and the right word 20% of the time, the model will know that when the [MASK] is not there, then the word is correct. The network has to predict the token, but it actually gets the answer already as input. Thus, it needs to learn nothing, since it knows the non-masked token is always correct.\n",
    "\n",
    "- If you use the $\\text{[MASK]}$ token 80% of the time and a wrong word 20% of the time, the model will know when the $\\text{[MASK]}$ doesn’t appear the selected token is a wrong one, and it will just treat it like another $\\text{[MASK]}$, i.e. you would likely encounter the same problem of before (100% $\\text{[MASK]}$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def mask_sentence(sentence1, sentence2 = None, add_special_tokens = True, padding = 'max_length'):\n",
    "    if sentence2:\n",
    "        inputs = bert_tokenizer(sentence1, sentence2, return_tensors='pt', add_special_tokens=add_special_tokens, truncation=True, padding=padding)\n",
    "    else:\n",
    "        inputs = bert_tokenizer(sentence1, return_tensors='pt', add_special_tokens=add_special_tokens, truncation=True, padding=padding)\n",
    "    \n",
    "    inputs['labels'] = inputs.input_ids.detach().clone() #for training\n",
    "    \n",
    "    rand = torch.rand(inputs.input_ids.squeeze().shape) #Returns a tensor filled with random numbers from a uniform distribution on the interval [0,1)\n",
    "    mask_arr = (rand < 0.15) * (inputs.input_ids.squeeze() != 101) * (inputs.input_ids.squeeze() != 102) * (inputs.input_ids.squeeze() != 0) #101 is [CLS] and 102 is [SEP] and 0 is [PAD]\n",
    "    index_to_mask = torch.flatten(mask_arr.nonzero()).tolist()\n",
    "    \n",
    "    index_to_mask_shuffle = random.sample(index_to_mask, int(len(index_to_mask)-(0.1 * len(index_to_mask))))\n",
    "    to_mask = int(0.8*len(index_to_mask))\n",
    "    inputs.input_ids[0, index_to_mask_shuffle[:to_mask]] = 103 #[MASK] token\n",
    "    inputs.input_ids[0, index_to_mask_shuffle[to_mask:]] = torch.LongTensor(random.sample(list(bert_tokenizer.vocab.values()), len(index_to_mask_shuffle)-to_mask)) #random token\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: Do you like raccons? Yes, I love them!\n",
      "Masked sentence: [CLS] [MASK] you like ra ##cco ##ns ? [SEP] yes , i love them ! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "masked_sentence = mask_sentence(example_sentence_1, example_sentence_2)\n",
    "print(f'Original sentence: {example_sentence_1} {example_sentence_2}')\n",
    "print(f'Masked sentence: {\" \".join(bert_tokenizer.convert_ids_to_tokens(*masked_sentence.input_ids))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline with masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.9135e-01, -2.0353e-01,  3.2511e-01,  ...,  8.4548e-01,\n",
       "           9.1684e-01,  3.2428e+00],\n",
       "         [ 4.7695e-01, -5.5562e-01,  2.0502e+00,  ...,  1.2189e+00,\n",
       "          -1.4139e+00,  1.7901e+00],\n",
       "         [ 9.7310e-01,  9.6069e-01,  1.4754e+00,  ..., -5.0557e-04,\n",
       "          -6.6664e-02, -6.6653e-02],\n",
       "         ...,\n",
       "         [ 2.7986e-01,  6.8731e-01,  1.6882e+00,  ..., -1.6535e-01,\n",
       "           3.7201e-01,  7.0767e-01],\n",
       "         [ 1.0912e+00,  1.7637e-01,  1.4525e+00,  ..., -1.6535e-01,\n",
       "           3.7201e-01,  7.0767e-01],\n",
       "         [ 1.0997e+00, -7.8245e-01,  5.9306e-01,  ..., -1.6535e-01,\n",
       "           3.7201e-01,  7.0767e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 1335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input_masked = mask_sentence(example_sentence_1, example_sentence_2)\n",
    "token_embeddings = embedding_layer(tokenized_input_masked['input_ids'])\n",
    "position_embeddings = positional_encoding_layer()\n",
    "sentence_embeddings = torch.tile(tokenized_input_masked['token_type_ids'].permute(1,0), (1, d_model)).unsqueeze(0)\n",
    "embeddings = token_embeddings + position_embeddings + sentence_embeddings\n",
    "print(embeddings.size())\n",
    "embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During pre-training, BERT will evaluate the loss of these masked tokens, and it will backpropagate it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second pre-training objective is called **Next Sentence Prediction (NSP)**. \n",
    "\n",
    "Many important downstream tasks such as Question Answering (QA) and Natural Language Inference (NLI) are based on understanding the relationship between two sentences, which is not directly captured by language modeling.\n",
    "\n",
    "When pre-traininig for a binarized NSP task, we choose the sentences A and B for each pretraining example,ì so that 50% of the time B is the actual next sentence that follows A (labeled as IsNext), and 50% of the time it is a random sentence from the corpus (labeled as NotNext).\n",
    "\n",
    "$\\text{[CLS]}$ is used for NSP.\n",
    "\n",
    "<center><img src=\"img/bert_pretrain_2.svg\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just use task-specific data and additional output layers taking as input BERT's output.\n",
    "\n",
    "**Question Answering with Stanford Question Answering Dataset (SQuAD)**\n",
    "<center><img src=\"img/bert_finetune_squad.svg\"/></center>\n",
    "\n",
    "**Entailment with MNLI**\n",
    "<center><img src=\"img/bert_finetune_mnli.svg\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands-on: BERT!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is (finally) dedicated to some real-world BERT use cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "\n",
    "model_mlm = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "print(bert_tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 30522])"
      ]
     },
     "execution_count": 1337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model_mlm(**masked_sentence).logits\n",
    "logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 1338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve index of [MASK]\n",
    "mask_token_index = (masked_sentence.input_ids == bert_tokenizer.mask_token_id)[0].nonzero().squeeze()\n",
    "mask_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2079)\n",
      "['do']\n"
     ]
    }
   ],
   "source": [
    "predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
    "print(predicted_token_id)\n",
    "print(tokenizer.convert_ids_to_tokens([predicted_token_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] do you like raccons? [SEP] yes, i love them! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS] [MASK] you like raccons? [SEP] yes, i love them! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS] do you like raccons? [SEP] yes, i love them! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "prediction = torch.where(masked_sentence.input_ids == tokenizer.mask_token_id, logits[0, :].argmax(axis=-1), masked_sentence.input_ids)[0]\n",
    "print(tokenizer.decode(masked_sentence.labels[0]))\n",
    "print(tokenizer.decode(masked_sentence.input_ids[0]))\n",
    "print(tokenizer.decode(prediction))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mlm_pipeline = pipeline('fill-mask', model=model_mlm, tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] do you like racco [MASK]? [SEP] yes, i love them! [SEP]'"
      ]
     },
     "execution_count": 1347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_mask_sentence = mask_sentence(example_sentence_1, example_sentence_2, add_special_tokens = True, padding = False)\n",
    "pipeline_mask_sentence = tokenizer.decode(pipeline_mask_sentence.input_ids[0])\n",
    "pipeline_mask_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9958614706993103,\n",
       "  'token': 5644,\n",
       "  'token_str': '##ons',\n",
       "  'sequence': 'do you like raccoons? yes, i love them!'},\n",
       " {'score': 0.004032552242279053,\n",
       "  'token': 2239,\n",
       "  'token_str': '##on',\n",
       "  'sequence': 'do you like raccoon? yes, i love them!'},\n",
       " {'score': 2.0726880393340252e-05,\n",
       "  'token': 27896,\n",
       "  'token_str': '##ols',\n",
       "  'sequence': 'do you like raccools? yes, i love them!'},\n",
       " {'score': 1.5128574887057766e-05,\n",
       "  'token': 21821,\n",
       "  'token_str': '##ones',\n",
       "  'sequence': 'do you like raccoones? yes, i love them!'},\n",
       " {'score': 1.1780225577240344e-05,\n",
       "  'token': 9236,\n",
       "  'token_str': '##urs',\n",
       "  'sequence': 'do you like raccours? yes, i love them!'}]"
      ]
     },
     "execution_count": 1348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_pipeline(pipeline_mask_sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForNextSentencePrediction\n",
    "\n",
    "model_nsp = BertForNextSentencePrediction.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels (torch.LongTensor of shape (batch_size,), optional) — Labels for computing the next sequence prediction (classification) loss. Input should be a sequence pair (see input_ids docstring). Indices should be in [0, 1]:\n",
    "- 0 indicates sequence B is a continuation of sequence A,\n",
    "- 1 indicates sequence B is a random sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.7190, -3.6768]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "masked_sentence['labels'] = torch.LongTensor([0])\n",
    "outputs = model_nsp(**masked_sentence)\n",
    "logits = outputs.logits\n",
    "print(logits)\n",
    "print(torch.argmax(logits)) #isNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0730,  5.9056]], grad_fn=<AddmmBackward0>)\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\"\n",
    "encoding = bert_tokenizer(prompt, next_sentence, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model_nsp(**encoding, labels=torch.LongTensor([1]))\n",
    "logits = outputs.logits\n",
    "print(logits)\n",
    "print(torch.argmax(logits))# next sentence was random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequence Classification with MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset multi_nli (/Users/lizzy/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "mnli_dataset = load_dataset('multi_nli', split='train[:100]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'promptID': 60529,\n",
       " 'pairID': '60529c',\n",
       " 'premise': \"At the end of Rue des Francs-Bourgeois is what many consider to be the city's most handsome residential square, the Place des Vosges, with its stone and red brick facades.\",\n",
       " 'premise_binary_parse': \"( ( At ( ( the end ) ( of Rue ) ) ) ( ( des Francs-Bourgeois ) ( ( is ( what ( many ( consider ( to ( ( be ( ( ( ( ( the ( city 's ) ) ( ( most handsome ) ( residential square ) ) ) , ) ( the ( Place ( des Vosges ) ) ) ) , ) ) ( with ( its ( stone ( and ( red ( brick facades ) ) ) ) ) ) ) ) ) ) ) ) . ) ) )\",\n",
       " 'premise_parse': \"(ROOT (S (PP (IN At) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (NNP Rue))))) (NP (NNP des) (NNP Francs-Bourgeois)) (VP (VBZ is) (SBAR (WHNP (WP what)) (S (NP (DT many)) (VP (VBP consider) (S (VP (TO to) (VP (VB be) (NP (NP (NP (DT the) (NN city) (POS 's)) (ADJP (RBS most) (JJ handsome)) (JJ residential) (NN square)) (, ,) (NP (DT the) (NNP Place) (NNP des) (NNPS Vosges)) (, ,)) (PP (IN with) (NP (PRP$ its) (NN stone) (CC and) (JJ red) (NN brick) (NNS facades)))))))))) (. .)))\",\n",
       " 'hypothesis': 'Place des Vosges is constructed entirely of gray marble.',\n",
       " 'hypothesis_binary_parse': '( ( Place ( des Vosges ) ) ( ( is ( ( constructed entirely ) ( of ( gray marble ) ) ) ) . ) )',\n",
       " 'hypothesis_parse': '(ROOT (S (NP (NNP Place) (FW des) (NNP Vosges)) (VP (VBZ is) (VP (VBN constructed) (ADVP (RB entirely)) (PP (IN of) (NP (JJ gray) (NN marble))))) (. .)))',\n",
       " 'genre': 'travel',\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 1262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_mnli = mnli_dataset[9] #entailment (0), neutral (1), contradiction (2)\n",
    "example_mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnli_preprocess_function(examples):\n",
    "    return bert_tokenizer(examples['premise'], examples['hypothesis'], truncation=True, padding = True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: At the end of Rue des Francs-Bourgeois is what many consider to be the city's most handsome residential square, the Place des Vosges, with its stone and red brick facades.\n",
      "Hypothesis: Place des Vosges is constructed entirely of gray marble.\n",
      "After preprocessing: [CLS] at the end of rue des francs - bourgeois is what many consider to be the city's most handsome residential square, the place des vosges, with its stone and red brick facades. [SEP] place des vosges is constructed entirely of gray marble. [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(f'Premise: {example_mnli[\"premise\"]}')\n",
    "print(f'Hypothesis: {example_mnli[\"hypothesis\"]}')\n",
    "example_mnli_processed = mnli_preprocess_function(example_mnli)\n",
    "print(f'After preprocessing: {bert_tokenizer.decode(example_mnli_processed[\"input_ids\"][0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/lizzy/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39/cache-861fae54f0939407.arrow\n"
     ]
    }
   ],
   "source": [
    "encoded_mnli_dataset = mnli_dataset.map(mnli_preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_mnli = AutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-MNLI\") #entailment (1), neutral (2), contradiction (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.7612, -4.3002, -0.1899]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "outputs = model_mnli(**example_mnli_processed)\n",
    "logits = outputs.logits\n",
    "print(logits)\n",
    "print(torch.argmax(logits))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question Answering with SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset squad/plain_text to /Users/lizzy/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 7090.96it/s]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1236.89it/s]\n",
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad downloaded and prepared to /Users/lizzy/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "squad_dataset = load_dataset(\"squad\", split = 'train[:100]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 1279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_example = squad_dataset[0]\n",
    "squad_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline = pipeline(\n",
    "  \"question-answering\",\n",
    "  model=\"csarron/bert-base-uncased-squad-v1\",\n",
    "  tokenizer=\"csarron/bert-base-uncased-squad-v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9795623421669006, 'start': 515, 'end': 541, 'answer': 'Saint Bernadette Soubirous'}\n"
     ]
    }
   ],
   "source": [
    "predictions = qa_pipeline({\n",
    "  'context': squad_example['context'],\n",
    "  'question': squad_example['question']\n",
    "})\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Variants"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/bert_models.png\" width = \"70%\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Extensions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/bert_variants.png\" width = \"70%\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Papers:\n",
    "- Radford, Alec, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. “Improving Language Understanding by Generative Pre-Training,” 2019, 12.\n",
    "- Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. “BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding.” In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 4171–86. Minneapolis, Minnesota: Association for Computational Linguistics, 2019. https://doi.org/10.18653/v1/N19-1423.\n",
    "- Wu, Yonghui, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, et al. “Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation.” ArXiv:1609.08144 [Cs], October 8, 2016. http://arxiv.org/abs/1609.08144.\n",
    "- Sennrich, Rico, Barry Haddow, and Alexandra Birch. “Neural Machine Translation of Rare Words with Subword Units.” arXiv, June 10, 2016. https://doi.org/10.48550/arXiv.1508.07909.\n",
    "- Schuster, Mike, and Kaisuke Nakajima. “Japanese and Korean Voice Search.” In 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 5149–52, 2012. https://doi.org/10.1109/ICASSP.2012.6289079.\n",
    "- Liu, Yinhan, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. “RoBERTa: A Robustly Optimized BERT Pretraining Approach.” ArXiv:1907.11692 [Cs], July 26, 2019. http://arxiv.org/abs/1907.11692.\n",
    "- Sanh, Victor, Lysandre Debut, Julien Chaumond, and Thomas Wolf. “DistilBERT, a Distilled Version of BERT: Smaller, Faster, Cheaper and Lighter.” arXiv, February 29, 2020. https://doi.org/10.48550/arXiv.1910.01108.\n",
    "\n",
    "Online resources / tutorials:\n",
    "- https://huggingface.co/docs/transformers/v4.28.1/en/model_doc/bert#bert\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
