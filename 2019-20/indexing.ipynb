{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "- **Task**: index tokens in documents and weigth their relevance.\n",
    "- **Input**: tokenized documents\n",
    "- **Output**: term-document matrix\n",
    "\n",
    "### Main steps\n",
    "1. Tf (Term frequency)\n",
    "2. Idf (Inverse document frequency)\n",
    "3. TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = '../data/country_dataset.json'\n",
    "with open(dataset_file, 'r') as infile:\n",
    "    dataset = json.load(infile)\n",
    "docs = dataset['docs']\n",
    "queries = dataset['queries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = lambda text: [x.lemma_ for x in nlp(text) if x.pos_ not in ['PUNCT', 'SPACE'] and not x.is_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing from scratch\n",
    "Index structure: <code>{doc_id: {token: tf(token, doc_id), ...}, ...}</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf\n",
    "In this example, we exploit double normalized K tf, with K = 0.5:\n",
    "$$\n",
    "tf(t, d) = K + (1 - K)\\frac{f(t,d)}{\\max\\limits_{t' \\in d} f(t',d)},\n",
    "$$\n",
    "where $f(t,d)$ is the frequency (i.e., count) of token $t$ in document $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF, k = {}, 0.5\n",
    "for docid, text in enumerate(docs):\n",
    "    f = Counter(tokens(text)).most_common()\n",
    "    maxf = f[0][1]\n",
    "    TF[docid] = dict([(token, k + (1 - k) * (x / maxf)) for token, x in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a 2016 ranking of Chinese high schools that send students to study in American universities, Shenzhen Foreign Language School ranked number 19 in mainland China in terms of the number of students entering top American universities.\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[504]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('student', 1.0),\n",
       " ('american', 1.0),\n",
       " ('university', 1.0),\n",
       " ('number', 1.0),\n",
       " ('2016', 0.75),\n",
       " ('ranking', 0.75),\n",
       " ('chinese', 0.75),\n",
       " ('high', 0.75),\n",
       " ('school', 0.75),\n",
       " ('send', 0.75)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted(TF[504].items(), key=lambda x: -x[1]))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idf\n",
    "$$\n",
    "idf(t) = \\log \\left(\\frac{N}{n_t} \\right),\n",
    "$$\n",
    "where $N$ denotes the corpus size, and $n_t$ denotes the number of documents actually containing $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF, N = defaultdict(lambda: 0), len(docs)\n",
    "for k, bow in TF.items():\n",
    "    for t in bow.keys():\n",
    "        DF[t] += 1\n",
    "IDF = lambda x: np.log(N / DF[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 2\n",
      "4.153006474870687 5.539300835990577\n"
     ]
    }
   ],
   "source": [
    "print(DF['send'], DF['chinese'])\n",
    "print(IDF('send'), IDF('chinese'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "TfIdf = {}\n",
    "for k, bow in TF.items():\n",
    "    TfIdf[k] = dict([(token, w * IDF(token)) for token, w in bow.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('university', 5.133835727882413),\n",
       " ('ranking', 4.674336012412892),\n",
       " ('Shenzhen', 4.674336012412892),\n",
       " ('Foreign', 4.674336012412892),\n",
       " ('Language', 4.674336012412892),\n",
       " ('student', 4.623010104116422),\n",
       " ('american', 4.623010104116422),\n",
       " ('number', 4.440688547322468),\n",
       " ('chinese', 4.154475626992933),\n",
       " ('rank', 4.154475626992933)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted(TfIdf[504].items(), key=lambda x: -x[1]))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiword indexing and compound terms selection\n",
    "**Task**: find sequences of n words (called n_grams) that should be counted as a single word during indexing (i.e., New York).\n",
    "\n",
    "**Approch**: use pointwise mutual information to estimate the probability of a n_gram (say a 2_gram in the example) to be a single compound term\n",
    "\n",
    "$$\n",
    "pmi(t_i, t_j) = \\log \\left (\\frac{P(t_i, t_j)}{P(t_i)P(t_j)} \\right ) \n",
    "$$\n",
    "\n",
    "Denoting $f(t)$ the frequency of terms in the corpus, probabilities can be estimated as:\n",
    "\n",
    "$$\n",
    "P(t_i, t_j) = \\frac{f(t_i, t_j)}{\\sum\\limits_{(x, y) \\in corpus}f(x, y)} \n",
    ", P(t_i) = \\frac{f(t_i)}{\\sum\\limits_{t \\in corpus}f(t)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unigram prebability estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, Un = defaultdict(lambda: 0), 0\n",
    "for doc in docs:\n",
    "    for token in tokens(doc):\n",
    "        U[token] += 1\n",
    "        Un += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_u = lambda x: U[x] / Un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6361 0.0009432479169941833\n"
     ]
    }
   ],
   "source": [
    "print(U['school'], Un, p_u('school'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigram probability estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, Bn = defaultdict(lambda: 0), 0\n",
    "for doc in docs:\n",
    "    for a, b in nltk.ngrams(tokens(doc), 2):\n",
    "        B[(a, b)] += 1\n",
    "        Bn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_b = lambda x, y: B[(x, y)] / Bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 5852 0.001367053998632946\n"
     ]
    }
   ],
   "source": [
    "print(B[('New', 'York')], Bn, p_b('New', 'York'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "PMI = {}\n",
    "for (a, b), _ in B.items():\n",
    "    PMI[(a, b)] = np.log(p_b(a, b) / (p_u(a) * p_u(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cyrville Ward 8.841342991217594 1 1\n",
      "Matthew Julia 8.841342991217594 1 1\n",
      "Street Manhattan 8.841342991217594 1 1\n",
      "description M. 8.841342991217594 1 1\n",
      "M. slaina 8.841342991217594 1 1\n",
      "slaina ant 8.841342991217594 1 1\n",
      "Donald Lu 8.841342991217594 1 1\n",
      "2012 Community 8.841342991217594 1 1\n",
      "Community Shield 8.841342991217594 1 1\n",
      "Shield broadcast 8.841342991217594 1 1\n"
     ]
    }
   ],
   "source": [
    "for (a, b), p in sorted(PMI.items(), key=lambda x: -x[1])[:10]:\n",
    "    print(a, b, p, U[a], U[b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a threshold on the miminum number of occurrences requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "PMI, th = {}, 5\n",
    "for (a, b), _ in B.items():\n",
    "    if U[a] > th and U[b] > th:\n",
    "        PMI[(a, b)] = np.log(p_b(a, b) / (p_u(a) * p_u(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indian Ocean 6.2022856616023345 7 8\n",
      "July 1915 5.950971233321429 6 6\n",
      "December 1915 5.950971233321429 6 6\n",
      "Damascus capital 5.796820553494171 6 7\n",
      "North Western 5.796820553494171 6 7\n",
      "main power 5.663289160869648 8 6\n",
      "World War 5.642669873666912 7 7\n",
      "power base 5.545506125213264 6 9\n",
      "base Damascus 5.545506125213264 9 6\n",
      "high school 5.545506125213264 9 6\n"
     ]
    }
   ],
   "source": [
    "for (a, b), p in sorted(PMI.items(), key=lambda x: -x[1])[:10]:\n",
    "    print(a, b, p, U[a], U[b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed bigrams in tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmi_tokenizer(doc, perc=95):\n",
    "    bigram = []\n",
    "    words = []\n",
    "    tks = tokens(doc)\n",
    "    th = np.percentile(list(PMI.values()), perc)\n",
    "    for (a, b) in nltk.ngrams(tks, 2):\n",
    "        if (a, b) in PMI.keys() and PMI[(a, b)] > th:\n",
    "            if len(bigram) == 0:\n",
    "                bigram += [a, b]\n",
    "            else:\n",
    "                bigram.append(b)\n",
    "        else:\n",
    "            if len(bigram) > 0:\n",
    "                words.append(\" \".join(bigram))\n",
    "                bigram = []\n",
    "            else:\n",
    "                words.append(a)\n",
    "    if tks[-1] != words[-1].split()[-1]:\n",
    "        words.append(tks[-1])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_tokens = lambda doc: pmi_tokenizer(doc, perc=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016', 'ranking', 'chinese', 'high', 'school', 'send', 'student', 'study', 'american', 'university']\n",
      "['2016', 'ranking', 'chinese', 'high school', 'send', 'student', 'study', 'american', 'university', 'Shenzhen']\n"
     ]
    }
   ],
   "source": [
    "print(tokens(docs[504])[:10])\n",
    "print(pmi_tokens(docs[504])[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = pd.DataFrame(TfIdf)\n",
    "M.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3215, 509)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>perform</td>\n",
       "      <td>4.846154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Habitat</td>\n",
       "      <td>6.232448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Center</td>\n",
       "      <td>5.539301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>New</td>\n",
       "      <td>2.706087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.706087</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Delhi</td>\n",
       "      <td>6.232448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 509 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0    1    2    3    4    5    6    7    8    9    ...  499  500  \\\n",
       "perform  4.846154  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "Habitat  6.232448  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "Center   5.539301  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "New      2.706087  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "Delhi    6.232448  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "         501  502  503  504  505  506       507  508  \n",
       "perform  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "Habitat  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "Center   0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "New      0.0  0.0  0.0  0.0  0.0  0.0  2.706087  0.0  \n",
       "Delhi    0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "\n",
       "[5 rows x 509 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perform</th>\n",
       "      <th>Habitat</th>\n",
       "      <th>Center</th>\n",
       "      <th>New</th>\n",
       "      <th>Delhi</th>\n",
       "      <th>visit</th>\n",
       "      <th>India</th>\n",
       "      <th>Zalog</th>\n",
       "      <th>independent</th>\n",
       "      <th>settlement</th>\n",
       "      <th>...</th>\n",
       "      <th>Burj</th>\n",
       "      <th>weave</th>\n",
       "      <th>950,000</th>\n",
       "      <th>kind</th>\n",
       "      <th>turf</th>\n",
       "      <th>Mauro</th>\n",
       "      <th>Badaracchi</th>\n",
       "      <th>Tivoli</th>\n",
       "      <th>sport</th>\n",
       "      <th>shooter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.846154</td>\n",
       "      <td>6.232448</td>\n",
       "      <td>5.539301</td>\n",
       "      <td>2.706087</td>\n",
       "      <td>6.232448</td>\n",
       "      <td>4.286538</td>\n",
       "      <td>3.187926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.232448</td>\n",
       "      <td>5.539301</td>\n",
       "      <td>4.846154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    perform   Habitat    Center       New     Delhi     visit     India  \\\n",
       "0  4.846154  6.232448  5.539301  2.706087  6.232448  4.286538  3.187926   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      Zalog  independent  settlement  ...  Burj  weave  950,000  kind  turf  \\\n",
       "0  0.000000     0.000000    0.000000  ...   0.0    0.0      0.0   0.0   0.0   \n",
       "1  6.232448     5.539301    4.846154  ...   0.0    0.0      0.0   0.0   0.0   \n",
       "2  0.000000     0.000000    0.000000  ...   0.0    0.0      0.0   0.0   0.0   \n",
       "3  0.000000     0.000000    0.000000  ...   0.0    0.0      0.0   0.0   0.0   \n",
       "4  0.000000     0.000000    0.000000  ...   0.0    0.0      0.0   0.0   0.0   \n",
       "\n",
       "   Mauro  Badaracchi  Tivoli  sport  shooter  \n",
       "0    0.0         0.0     0.0    0.0      0.0  \n",
       "1    0.0         0.0     0.0    0.0      0.0  \n",
       "2    0.0         0.0     0.0    0.0      0.0  \n",
       "3    0.0         0.0     0.0    0.0      0.0  \n",
       "4    0.0         0.0     0.0    0.0      0.0  \n",
       "\n",
       "[5 rows x 3215 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing with scikit-learn\n",
    "A tutorial on scikit-learn text processing is available [here](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn text facilities expect to work with text as strings instead of pre-tokenized text. Thus, we create a pseudo-text by exploiting our previous tokenizers and creating pseudo words for bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_docs = [\" \".join([x.replace(' ', '_') for x in pmi_tokens(d)]) for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016 ranking chinese high_school send student study american university Shenzhen Foreign Language School rank number 19 mainland China term number_student enter american university'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_docs[504]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = V.fit_transform(pseudo_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<509x3024 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5899 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map matrix columns on words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1371"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.vocabulary_.get('high_school')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 90, 504]), array([0, 0]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(C[:,1371].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[90, 1371]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfTransformer(use_idf=True)\n",
    "X = tf_idf.fit_transform(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<509x3024 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5899 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.27298188, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24369107498675482"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[90, 1371]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
