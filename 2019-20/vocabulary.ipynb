{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary\n",
    "- **Task**: implement different strategies to tokenize and normalize text in order to weight token relevance.\n",
    "- **Input**: raw text\n",
    "- **Output**: a list of tokens for each text\n",
    "\n",
    "### Main steps\n",
    "0. Language detection\n",
    "1. Tokenization\n",
    "2. Case, punctuation, stopwords\n",
    "3. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = '../data/country_dataset.json'\n",
    "with open(dataset_file, 'r') as infile:\n",
    "    dataset = json.load(infile)\n",
    "docs = dataset['docs']\n",
    "queries = dataset['queries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = docs[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The group was presented to the Prince of Wales, later King Charles I, in 1623 while he was in Spain negotiating a marriage contract, and it soon became the most famous Italian sculpture in England.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language detection\n",
    "Many options, see for example [langdetect](https://pypi.org/project/langdetect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, detect_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = \"Testo che mescola English words con testo italiano.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This shows how models trained mainly on English may be unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[en:0.7142848002489957, it:0.2857148540663416]\n",
      "en\n"
     ]
    }
   ],
   "source": [
    "print(detect_langs(L))\n",
    "print(detect(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of language detection is to use it when dealing with multilanguage corpora because some of the vocabulary building operations may be language dependant (e.g., lemmatization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '\\w+|\\$[\\d\\.]+|\\S+'\n",
    "tokenizer = RegexpTokenizer(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = docs[10]\n",
    "tokens = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The group was presented to the Prince of Wales, later King Charles I, in 1623 while he was in Spain negotiating a marriage contract, and it soon became the most famous Italian sculpture in England.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'group', 'was', 'presented', 'to', 'the', 'Prince', 'of', 'Wales', ',', 'later', 'King', 'Charles', 'I', ',', 'in', '1623', 'while', 'he', 'was', 'in', 'Spain', 'negotiating', 'a', 'marriage', 'contract', ',', 'and', 'it', 'soon', 'became', 'the', 'most', 'famous', 'Italian', 'sculpture', 'in', 'England', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: when dealing with long texts, tokenization shold be performed sentence by sentence, exploiting <code>nltk.tokenize.sent_tokenize</code> before tokenization and normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case, punctuation and stopwords removal\n",
    "The importance of each step is relative to the size of the corpus and its sparseness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_tokens = lambda data: [x.lower() for x in data]\n",
    "punct_tokens = lambda data: [x for x in data if x not in punctuation]\n",
    "stop_tokens = lambda data: [x for x in data if x not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The group was presented to the Prince of Wales, later King Charles I, in 1623 while he was in Spain negotiating a marriage contract, and it soon became the most famous Italian sculpture in England.\n",
      "\n",
      "['The', 'group', 'was', 'presented', 'to', 'the', 'Prince', 'of', 'Wales', ',', 'later', 'King', 'Charles', 'I', ',', 'in', '1623', 'while', 'he', 'was', 'in', 'Spain', 'negotiating', 'a', 'marriage', 'contract', ',', 'and', 'it', 'soon', 'became', 'the', 'most', 'famous', 'Italian', 'sculpture', 'in', 'England', '.'] \n",
      "\n",
      "lower\n",
      "['the', 'group', 'was', 'presented', 'to', 'the', 'prince', 'of', 'wales', ',', 'later', 'king', 'charles', 'i', ',', 'in', '1623', 'while', 'he', 'was', 'in', 'spain', 'negotiating', 'a', 'marriage', 'contract', ',', 'and', 'it', 'soon', 'became', 'the', 'most', 'famous', 'italian', 'sculpture', 'in', 'england', '.'] \n",
      "\n",
      "punctuation\n",
      "['the', 'group', 'was', 'presented', 'to', 'the', 'prince', 'of', 'wales', 'later', 'king', 'charles', 'i', 'in', '1623', 'while', 'he', 'was', 'in', 'spain', 'negotiating', 'a', 'marriage', 'contract', 'and', 'it', 'soon', 'became', 'the', 'most', 'famous', 'italian', 'sculpture', 'in', 'england'] \n",
      "\n",
      "stopwords\n",
      "['group', 'presented', 'prince', 'wales', 'later', 'king', 'charles', '1623', 'spain', 'negotiating', 'marriage', 'contract', 'soon', 'became', 'famous', 'italian', 'sculpture', 'england'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = [('lower', lower_tokens), ('punctuation', punct_tokens), ('stopwords', stop_tokens)]\n",
    "current = tokens\n",
    "print(T)\n",
    "print(current, '\\n')\n",
    "for operation, f in pipeline:\n",
    "    print(operation)\n",
    "    current = f(current)\n",
    "    print(current, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['group', 'present', 'princ', 'wale', 'later', 'king', 'charl', '1623', 'spain', 'negoti', 'marriag', 'contract', 'soon', 'becam', 'famous', 'italian', 'sculptur', 'england']\n"
     ]
    }
   ],
   "source": [
    "print([stemmer.stem(x) for x in current])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization with WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "syns = wn.synsets('group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1: word sense disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('group.n.01') any number of entities (members) considered as a unit\n",
      "Synset('group.n.02') (chemistry) two or more atoms bound together as a single unit and forming part of a molecule\n",
      "Synset('group.n.03') a set that is closed, associative, has an identity element and every element has an inverse\n",
      "Synset('group.v.01') arrange into a group or groups\n",
      "Synset('group.v.02') form a group or group together\n"
     ]
    }
   ],
   "source": [
    "for syn in syns:\n",
    "    print(syn, syn.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2: choice of lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('group.n.01') ['group', 'grouping']\n",
      "Synset('group.n.02') ['group', 'radical', 'chemical_group']\n",
      "Synset('group.n.03') ['group', 'mathematical_group']\n",
      "Synset('group.v.01') ['group']\n",
      "Synset('group.v.02') ['group', 'aggroup']\n"
     ]
    }
   ],
   "source": [
    "for syn in syns:\n",
    "    print(syn, [lemma.name() for lemma in syn.lemmas()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wnlemma(word):\n",
    "    try:\n",
    "        s = wn.synsets(word)[0]\n",
    "        try:\n",
    "            l = s.lemmas()[0].name()\n",
    "        except IndexError:\n",
    "            return word\n",
    "    except IndexError:\n",
    "        return word\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_tokens = lambda data: [wnlemma(x) for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['group', 'presented', 'prince', 'wales', 'later', 'king', 'charles', '1623', 'spain', 'negotiating', 'marriage', 'contract', 'soon', 'became', 'famous', 'italian', 'sculpture', 'england']\n",
      "['group', 'show', 'prince', 'Wales', 'later', 'king', 'Charles', '1623', 'Spain', 'negociate', 'marriage', 'contract', 'soon', 'become', 'celebrated', 'Italian', 'sculpture', 'England']\n"
     ]
    }
   ],
   "source": [
    "print(current)\n",
    "print(lemma_tokens(current))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercize: find a better strategy for word sense disambiguation using WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approaches based on language modeling: Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The group was presented to the Prince of Wales, later King Charles I, in 1623 while he was in Spain negotiating a marriage contract, and it soon became the most famous Italian sculpture in England.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in doc.sents:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['text', 'lemma', 'pos', 'tag', 'dep', 'shape', 'alpha', 'stopwords']\n",
    "tks = []\n",
    "for token in doc:\n",
    "    data = [token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop]\n",
    "    tks.append(dict([(fields[i], x) for i, x in enumerate(data)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep</th>\n",
       "      <th>shape</th>\n",
       "      <th>alpha</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>group</td>\n",
       "      <td>group</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>nsubjpass</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>auxpass</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>presented</td>\n",
       "      <td>present</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Prince</td>\n",
       "      <td>Prince</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>pobj</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Wales</td>\n",
       "      <td>Wales</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>pobj</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>later</td>\n",
       "      <td>later</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>King</td>\n",
       "      <td>King</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Charles</td>\n",
       "      <td>Charles</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>appos</td>\n",
       "      <td>X</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1623</td>\n",
       "      <td>1623</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>pobj</td>\n",
       "      <td>dddd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>while</td>\n",
       "      <td>while</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>mark</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>he</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>advcl</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Spain</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>pobj</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>negotiating</td>\n",
       "      <td>negotiate</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>acl</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>marriage</td>\n",
       "      <td>marriage</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>compound</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>contract</td>\n",
       "      <td>contract</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>dobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>cc</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>it</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>soon</td>\n",
       "      <td>soon</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>became</td>\n",
       "      <td>become</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>conj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>most</td>\n",
       "      <td>most</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RBS</td>\n",
       "      <td>advmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>famous</td>\n",
       "      <td>famous</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Italian</td>\n",
       "      <td>italian</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>attr</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>England</td>\n",
       "      <td>England</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>pobj</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SP</td>\n",
       "      <td></td>\n",
       "      <td>\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text      lemma    pos  tag        dep  shape  alpha  stopwords\n",
       "0           The        the    DET   DT        det    Xxx   True       True\n",
       "1         group      group   NOUN   NN  nsubjpass   xxxx   True      False\n",
       "2           was         be   VERB  VBD    auxpass    xxx   True       True\n",
       "3     presented    present   VERB  VBN       ROOT   xxxx   True      False\n",
       "4            to         to    ADP   IN       prep     xx   True       True\n",
       "5           the        the    DET   DT        det    xxx   True       True\n",
       "6        Prince     Prince  PROPN  NNP       pobj  Xxxxx   True      False\n",
       "7            of         of    ADP   IN       prep     xx   True       True\n",
       "8         Wales      Wales  PROPN  NNP       pobj  Xxxxx   True      False\n",
       "9             ,          ,  PUNCT    ,      punct      ,  False      False\n",
       "10        later      later    ADV   RB     advmod   xxxx   True      False\n",
       "11         King       King  PROPN  NNP   compound   Xxxx   True      False\n",
       "12      Charles    Charles  PROPN  NNP   compound  Xxxxx   True      False\n",
       "13            I          I  PROPN  NNP      appos      X   True       True\n",
       "14            ,          ,  PUNCT    ,      punct      ,  False      False\n",
       "15           in         in    ADP   IN       prep     xx   True       True\n",
       "16         1623       1623    NUM   CD       pobj   dddd  False      False\n",
       "17        while      while    ADP   IN       mark   xxxx   True       True\n",
       "18           he     -PRON-   PRON  PRP      nsubj     xx   True       True\n",
       "19          was         be   VERB  VBD      advcl    xxx   True       True\n",
       "20           in         in    ADP   IN       prep     xx   True       True\n",
       "21        Spain      Spain  PROPN  NNP       pobj  Xxxxx   True      False\n",
       "22  negotiating  negotiate   VERB  VBG        acl   xxxx   True      False\n",
       "23            a          a    DET   DT        det      x   True       True\n",
       "24     marriage   marriage   NOUN   NN   compound   xxxx   True      False\n",
       "25     contract   contract   NOUN   NN       dobj   xxxx   True      False\n",
       "26            ,          ,  PUNCT    ,      punct      ,  False      False\n",
       "27          and        and  CCONJ   CC         cc    xxx   True       True\n",
       "28           it     -PRON-   PRON  PRP      nsubj     xx   True       True\n",
       "29         soon       soon    ADV   RB     advmod   xxxx   True      False\n",
       "30       became     become   VERB  VBD       conj   xxxx   True       True\n",
       "31          the        the    DET   DT        det    xxx   True       True\n",
       "32         most       most    ADV  RBS     advmod   xxxx   True       True\n",
       "33       famous     famous    ADJ   JJ       amod   xxxx   True      False\n",
       "34      Italian    italian    ADJ   JJ       amod  Xxxxx   True      False\n",
       "35    sculpture  sculpture   NOUN   NN       attr   xxxx   True      False\n",
       "36           in         in    ADP   IN       prep     xx   True       True\n",
       "37      England    England  PROPN  NNP       pobj  Xxxxx   True      False\n",
       "38            .          .  PUNCT    .      punct      .  False      False\n",
       "39           \\n         \\n  SPACE  _SP                \\n  False      False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case, punctuation and stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_tokens = lambda data: [x for x in data if x.pos_ not in ['PUNCT', 'SPACE']]\n",
    "stop_tokens = lambda data: [x for x in data if not x.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokens = stop_tokens(punct_tokens(nlp(T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[group, presented, Prince, Wales, later, King, Charles, 1623, Spain, negotiating, marriage, contract, soon, famous, Italian, sculpture, England]\n"
     ]
    }
   ],
   "source": [
    "print(spacy_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_lemma = lambda data: [x.lemma_ for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['group', 'present', 'Prince', 'Wales', 'later', 'King', 'Charles', '1623', 'Spain', 'negotiate', 'marriage', 'contract', 'soon', 'famous', 'italian', 'sculpture', 'England']\n"
     ]
    }
   ],
   "source": [
    "print(spacy_lemma(spacy_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A look into dependencies and entities (more on this later on course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = docs[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Zalog\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is a formerly independent settlement in the eastern part of the capital \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Ljubljana\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " in central \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Slovenia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(T), style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"fd8ab8def4ce43db9e13fc275108d918-0\" class=\"displacy\" width=\"1550\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Zalog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">a formerly independent settlement</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">the eastern part</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">the capital</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Ljubljana</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">central Slovenia.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fd8ab8def4ce43db9e13fc275108d918-0-0\" stroke-width=\"2px\" d=\"M62,152.0 62,127.0 197.0,127.0 197.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fd8ab8def4ce43db9e13fc275108d918-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,154.0 L58,146.0 66,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fd8ab8def4ce43db9e13fc275108d918-0-1\" stroke-width=\"2px\" d=\"M212,152.0 212,127.0 347.0,127.0 347.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fd8ab8def4ce43db9e13fc275108d918-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M347.0,154.0 L351.0,146.0 343.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fd8ab8def4ce43db9e13fc275108d918-0-2\" stroke-width=\"2px\" d=\"M362,152.0 362,127.0 497.0,127.0 497.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fd8ab8def4ce43db9e13fc275108d918-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M497.0,154.0 L501.0,146.0 493.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fd8ab8def4ce43db9e13fc275108d918-0-3\" stroke-width=\"2px\" d=\"M512,152.0 512,127.0 647.0,127.0 647.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fd8ab8def4ce43db9e13fc275108d918-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M647.0,154.0 L651.0,146.0 643.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fd8ab8def4ce43db9e13fc275108d918-0-4\" stroke-width=\"2px\" d=\"M662,152.0 662,127.0 797.0,127.0 797.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fd8ab8def4ce43db9e13fc275108d918-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M797.0,154.0 L801.0,146.0 793.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fd8ab8def4ce43db9e13fc275108d918-0-5\" stroke-width=\"2px\" d=\"M812,152.0 812,127.0 947.0,127.0 947.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fd8ab8def4ce43db9e13fc275108d918-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M947.0,154.0 L951.0,146.0 943.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fd8ab8def4ce43db9e13fc275108d918-0-6\" stroke-width=\"2px\" d=\"M962,152.0 962,127.0 1097.0,127.0 1097.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fd8ab8def4ce43db9e13fc275108d918-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1097.0,154.0 L1101.0,146.0 1093.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fd8ab8def4ce43db9e13fc275108d918-0-7\" stroke-width=\"2px\" d=\"M362,152.0 362,102.0 1250.0,102.0 1250.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fd8ab8def4ce43db9e13fc275108d918-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1250.0,154.0 L1254.0,146.0 1246.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fd8ab8def4ce43db9e13fc275108d918-0-8\" stroke-width=\"2px\" d=\"M1262,152.0 1262,127.0 1397.0,127.0 1397.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fd8ab8def4ce43db9e13fc275108d918-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1397.0,154.0 L1401.0,146.0 1393.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(T), style='dep', options={'compact': True, \n",
    "                                              'collapse_phrases': True,\n",
    "                                             'add_lemma': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {'token': [], 'token dep': [], 'head': [], 'head pos': [], 'children': [], 'ancestors': []}\n",
    "for token in nlp(T):\n",
    "    table['token'].append(token.text)\n",
    "    table['token dep'].append(token.dep_)\n",
    "    table['head'].append(token.head.text)\n",
    "    table['head pos'].append(token.head.pos_)\n",
    "    table['children'].append(\", \".join([child.text for child in token.children]))\n",
    "    table['ancestors'].append(\", \".join([a.text for a in token.ancestors]))\n",
    "S = pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>token dep</th>\n",
       "      <th>head</th>\n",
       "      <th>head pos</th>\n",
       "      <th>children</th>\n",
       "      <th>ancestors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Zalog</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>is</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>is</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Zalog, settlement, .</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>det</td>\n",
       "      <td>settlement</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td>settlement, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>formerly</td>\n",
       "      <td>advmod</td>\n",
       "      <td>independent</td>\n",
       "      <td>ADJ</td>\n",
       "      <td></td>\n",
       "      <td>independent, settlement, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>independent</td>\n",
       "      <td>amod</td>\n",
       "      <td>settlement</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>formerly</td>\n",
       "      <td>settlement, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>settlement</td>\n",
       "      <td>attr</td>\n",
       "      <td>is</td>\n",
       "      <td>VERB</td>\n",
       "      <td>a, independent, in, in</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>in</td>\n",
       "      <td>prep</td>\n",
       "      <td>settlement</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>part</td>\n",
       "      <td>settlement, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>the</td>\n",
       "      <td>det</td>\n",
       "      <td>part</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td>part, in, settlement, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>eastern</td>\n",
       "      <td>amod</td>\n",
       "      <td>part</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td>part, in, settlement, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>part</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>the, eastern, of</td>\n",
       "      <td>in, settlement, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>of</td>\n",
       "      <td>prep</td>\n",
       "      <td>part</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>capital</td>\n",
       "      <td>part, in, settlement, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>the</td>\n",
       "      <td>det</td>\n",
       "      <td>capital</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td>capital, of, part, in, settlement, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>capital</td>\n",
       "      <td>pobj</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>the, Ljubljana</td>\n",
       "      <td>of, part, in, settlement, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Ljubljana</td>\n",
       "      <td>appos</td>\n",
       "      <td>capital</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td>capital, of, part, in, settlement, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>in</td>\n",
       "      <td>prep</td>\n",
       "      <td>settlement</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>settlement, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>central</td>\n",
       "      <td>amod</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>PROPN</td>\n",
       "      <td></td>\n",
       "      <td>Slovenia, in, settlement, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>central</td>\n",
       "      <td>in, settlement, is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>is</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token token dep         head head pos                children  \\\n",
       "0         Zalog     nsubj           is     VERB                           \n",
       "1            is      ROOT           is     VERB    Zalog, settlement, .   \n",
       "2             a       det   settlement     NOUN                           \n",
       "3      formerly    advmod  independent      ADJ                           \n",
       "4   independent      amod   settlement     NOUN                formerly   \n",
       "5    settlement      attr           is     VERB  a, independent, in, in   \n",
       "6            in      prep   settlement     NOUN                    part   \n",
       "7           the       det         part     NOUN                           \n",
       "8       eastern      amod         part     NOUN                           \n",
       "9          part      pobj           in      ADP        the, eastern, of   \n",
       "10           of      prep         part     NOUN                 capital   \n",
       "11          the       det      capital     NOUN                           \n",
       "12      capital      pobj           of      ADP          the, Ljubljana   \n",
       "13    Ljubljana     appos      capital     NOUN                           \n",
       "14           in      prep   settlement     NOUN                Slovenia   \n",
       "15      central      amod     Slovenia    PROPN                           \n",
       "16     Slovenia      pobj           in      ADP                 central   \n",
       "17            .     punct           is     VERB                           \n",
       "\n",
       "                                ancestors  \n",
       "0                                      is  \n",
       "1                                          \n",
       "2                          settlement, is  \n",
       "3             independent, settlement, is  \n",
       "4                          settlement, is  \n",
       "5                                      is  \n",
       "6                          settlement, is  \n",
       "7                part, in, settlement, is  \n",
       "8                part, in, settlement, is  \n",
       "9                      in, settlement, is  \n",
       "10               part, in, settlement, is  \n",
       "11  capital, of, part, in, settlement, is  \n",
       "12           of, part, in, settlement, is  \n",
       "13  capital, of, part, in, settlement, is  \n",
       "14                         settlement, is  \n",
       "15           Slovenia, in, settlement, is  \n",
       "16                     in, settlement, is  \n",
       "17                                     is  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
