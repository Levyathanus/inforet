{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples with statistical language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple statistical model using skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class N2Model(object):\n",
    "    \n",
    "    def __init__(self, label: str):\n",
    "        self.label = label\n",
    "        self.index = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        self.n = defaultdict(lambda: 0)\n",
    "        self.N = sum(self.n.values())\n",
    "    \n",
    "    @staticmethod\n",
    "    def skip(sequence, s=2):\n",
    "        n = 2\n",
    "        k_grams = []\n",
    "        for i in range(len(sequence)):\n",
    "            for j in range(i+1, min(i+s, len(sequence))):\n",
    "                k_grams.append((sequence[i], sequence[j]))\n",
    "        return k_grams\n",
    "    \n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        for sent in sent_tokenize(text):\n",
    "            tokens = ['#S'] + nltk.word_tokenize(sent.lower()) + ['#E']\n",
    "            yield tokens\n",
    "    \n",
    "    def add(self, sequence):\n",
    "        for a, b in sequence:\n",
    "            self.n[a] += 1\n",
    "            self.index[a][b] += 1\n",
    "    \n",
    "    def fit(self, texts, s=3):\n",
    "        for text in texts:\n",
    "            if text is not None:\n",
    "                for tokens in N2Model.tokenize(text):\n",
    "                    self.add(N2Model.skip(tokens, s=s))\n",
    "        self.N = sum(self.n.values())\n",
    "    \n",
    "    def frequency_filter(self, min_bgram=50, min_unigram=100):\n",
    "        for k, v in self.index.items():\n",
    "            self.index[k] = defaultdict(lambda: 0, dict([(z, c) for z, c in v.items() if c >= min_bgram]))\n",
    "        self.n = defaultdict(lambda: 0, dict([(z, c) for z, c in self.n.items() if c >= min_unigram]))\n",
    "        self.N = sum(self.n.values())\n",
    "    \n",
    "    def p_word(self, word):\n",
    "        try:\n",
    "            if self.n[word] > 0:\n",
    "                return self.n[word] / self.N\n",
    "            else:\n",
    "                return 1 / (self.N + len(self.n))\n",
    "        except KeyError:\n",
    "            return 1 / (self.N + len(self.n))\n",
    "    \n",
    "    def p_gram(self, w1, w2):\n",
    "        try:\n",
    "            if self.index[w1][w2] > 0:\n",
    "                if self.n[w1] > 0:\n",
    "                    return self.index[w1][w2] / self.n[w1]\n",
    "                else:\n",
    "                    return self.p_word(w1) * self.p_word(w2)\n",
    "            else:\n",
    "                return self.p_word(w1) * self.p_word(w2)\n",
    "        except KeyError:\n",
    "            return self.p_word(w1) * self.p_word(w2)\n",
    "    \n",
    "    def p_text(self, text, s=3):\n",
    "        probs = []\n",
    "        for tokens in N2Model.tokenize(text):\n",
    "            sequence = N2Model.skip(tokens, s=s)\n",
    "            p = []\n",
    "            for a, b in sequence:\n",
    "                w = self.p_gram(a, b)\n",
    "                if w is not None:\n",
    "                    p.append(w)\n",
    "            data = np.array(p)\n",
    "            probs.append(np.prod(data))\n",
    "        return probs\n",
    "    \n",
    "    def save(self):\n",
    "        idx = {}\n",
    "        for w, i in self.index.items():\n",
    "            k = dict([(x, y) for x, y in i.items()])\n",
    "            idx[w] = k\n",
    "        self.index = idx\n",
    "        self.n = dict([(x, y) for x, y in self.n.items()])\n",
    "        # do serialize\n",
    "\n",
    "class N2Classifier(object):\n",
    "    \n",
    "    def __init__(self, models: typing.Iterable[N2Model]):\n",
    "        self.models = {}\n",
    "        for model in models:\n",
    "            model.save()\n",
    "            self.models[model.label] = model\n",
    "        self.G = N2Model(label='global')\n",
    "        \n",
    "    def frequency_filter(self, min_bgram=50, min_unigram=100):\n",
    "        for model in self.models.values():\n",
    "            model.frequency_filter(min_bgram=min_bgram, min_unigram=min_unigram)\n",
    "    \n",
    "    def global_model(self):\n",
    "        for model in self.models.values():\n",
    "            for k, v in model.index.items():\n",
    "                self.G.n[k] += model.n[k]\n",
    "                for z, c in v.items():\n",
    "                    self.G.index[k][z] += c\n",
    "        self.G.N = sum(self.G.n.values())\n",
    "            \n",
    "    def save(self, file):\n",
    "        data = {}\n",
    "        for label, model in self.models.items():\n",
    "            data[label] = model.index\n",
    "        with open(file, 'w') as out:\n",
    "            json.dump(data, out)\n",
    "            \n",
    "    def load(self, file):\n",
    "        with open(file, 'r') as infile:\n",
    "            data = json.load(infile)\n",
    "        for label, index_data in data.items():\n",
    "            model = N2Model(label=label)\n",
    "            for k, v in index_data.items():\n",
    "                for z, c in v.items():\n",
    "                    model.index[k][z] = c\n",
    "                    model.n[k] += c\n",
    "            model.N = sum(model.n.values())\n",
    "            self.models[label] = model\n",
    "    \n",
    "    def p_word(self, label, word):\n",
    "        return self.models[label].p_word(word)\n",
    "    \n",
    "    def p_gram(self, label, w1, w2):\n",
    "        return self.models[label].p_gram(w1, w2)\n",
    "    \n",
    "    def p_text(self, label, text):\n",
    "        return self.models[label].p_text(text)\n",
    "    \n",
    "    def kl_gram(self, label, w1, w2):\n",
    "        p_k = self.models[label].p_gram(w1, w2)\n",
    "        p = self.G.p_gram(w1, w2)\n",
    "        return p_k * np.log(p_k / p)\n",
    "    \n",
    "    def kl_text(self, label, text, s=3):\n",
    "        scores = []\n",
    "        for tokens in N2Model.tokenize(text):\n",
    "            sequence = N2Model.skip(tokens, s=s)\n",
    "            data = np.array([self.kl_gram(label, a, b) for a, b in sequence])\n",
    "            scores.append(np.exp(data.sum()))\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: 20News classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and index corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = '/Users/alfio/Dati/sklearn/'\n",
    "data_train = fetch_20newsgroups(subset='train', data_home=load_dir, remove=('headers', 'footers', 'quotes'))\n",
    "data_test = fetch_20newsgroups(subset='test', data_home=load_dir, remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = defaultdict(lambda: [])\n",
    "for i, text in enumerate(data_train.data):\n",
    "    target = data_train.target_names[data_train.target[i]]\n",
    "    train_corpus[target].append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit & save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models = dict([(genre, N2Model(label=genre)) for genre in train_corpus.keys()])\n",
    "for genre, data in tqdm(train_corpus.items()):\n",
    "    models[genre].fit(data, s=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K = N2Classifier(models.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outfile = '../../data/lm-news.json'\n",
    "K.save(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = N2Classifier(models=[])\n",
    "infile = '../../data/lm-news.json'\n",
    "M.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "They were attacking the Iraqis to drive them out of Kuwait,\n",
      "a country whose citizens have close blood and business ties\n",
      "to Saudi citizens.  And me thinks if the US had not helped out\n",
      "the Iraqis would have swallowed Saudi Arabia, too (or at \n",
      "least the eastern oilfields).  And no Muslim country was doing\n",
      "much of anything to help liberate Kuwait and protect Saudi\n",
      "Arabia; indeed, in some masses of ci \n",
      "\n",
      "talk.politics.mideast \n",
      "\n",
      "misc.forsale 2.749735285342311e-43\n",
      "rec.sport.hockey 4.0624280278472776e-44\n",
      "comp.sys.ibm.pc.hardware 2.0542005543863144e-44\n",
      "comp.sys.mac.hardware 1.5193340887785927e-44\n",
      "sci.electronics 1.0489064404015975e-46\n",
      "comp.os.ms-windows.misc 1.880976165149902e-47\n",
      "comp.graphics 4.03500509226384e-48\n",
      "rec.sport.baseball 9.491050801605009e-50\n",
      "rec.motorcycles 2.671238106774861e-50\n",
      "rec.autos 3.9374126682999835e-51\n",
      "talk.religion.misc 1.1846131032069708e-51\n",
      "comp.windows.x 1.0745001086149284e-51\n",
      "sci.space 3.1602076619281703e-52\n",
      "talk.politics.misc 6.61422621267017e-54\n",
      "sci.med 4.608216729859667e-54\n",
      "soc.religion.christian 2.8996501679580455e-55\n",
      "talk.politics.guns 5.119813976492771e-57\n",
      "alt.atheism 2.059707834617861e-57\n",
      "sci.crypt 1.5009472854119278e-57\n",
      "talk.politics.mideast 1.3753396315687853e-64\n"
     ]
    }
   ],
   "source": [
    "item = 3\n",
    "text = data_test.data[item]\n",
    "target = data_test.target_names[data_test.target[item]]\n",
    "print(text[:400], '\\n')\n",
    "print(target, '\\n')\n",
    "genres = list(M.models.keys())\n",
    "probs = np.zeros(len(genres))\n",
    "for i, genre in enumerate(genres):\n",
    "    # Note that we have multiple sentences here!\n",
    "    probs[i] = np.median(np.array(M.p_text(genre, text)))\n",
    "for j, p in sorted(enumerate(probs), key=lambda x: -x[1]):\n",
    "    print(genres[j], p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue of generic, noisy, text: fixing by specificity\n",
    "We create a `global` model that computes the probability of a bigram over the whole corpus. Then, we compute the a score for bigrams by means of KL divergence, that is:\n",
    "\n",
    "$$\n",
    "KL(P_k(w_i \\mid w_{i-1})) = P_k(w_i \\mid w_{i-1}) \\log \\left ( \\frac{P_k(w_i \\mid w_{i-1})}{P(w_i \\mid w_{i-1})} \\right ),\n",
    "$$\n",
    "\n",
    "where $P_k(w_i \\mid w_{i-1})$ denotes the probability estimated by the model $k$ and $P(w_i \\mid w_{i-1})$ the global probability.\n",
    "\n",
    "Then we compute a classification score for a sequence of bigrams $(w_1, w_2), \\dots, (w_{n-1}, w_n)$ by:\n",
    "\n",
    "$$\n",
    "\\sigma_k = \\exp \\left ( \\sum\\limits_{i=1}^{n} KL(P_k(w_i \\mid w_{i-1})) \\right )\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.global_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "1.073592525892085e-11\n"
     ]
    }
   ],
   "source": [
    "print(M.models['talk.politics.mideast'].p_gram('saudi', 'arabia'))\n",
    "print(M.models['comp.sys.mac.hardware'].p_gram('saudi', 'arabia'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.01600854153470727612\n",
      "-0.00000000025474235976\n"
     ]
    }
   ],
   "source": [
    "a = M.kl_gram('talk.politics.mideast', 'saudi', 'arabia')\n",
    "print(f'{a:.20f}')\n",
    "b = M.kl_gram('comp.sys.mac.hardware', 'saudi', 'arabia')\n",
    "print(f'{b:.20f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "They were attacking the Iraqis to drive them out of Kuwait,\n",
      "a country whose citizens have close blood and business ties\n",
      "to Saudi citizens.  And me thinks if the US had not helped out\n",
      "the Iraqis would have swallowed Saudi Arabia, too (or at \n",
      "least the eastern oilfields).  And no Muslim country was doing\n",
      "much of anything to help liberate Kuwait and protect Saudi\n",
      "Arabia; indeed, in some masses of ci \n",
      "\n",
      "talk.politics.mideast \n",
      "\n",
      "talk.politics.misc 1.7367846296428642\n",
      "comp.sys.mac.hardware 1.5411875183357442\n",
      "rec.sport.hockey 1.5115550883854625\n",
      "talk.politics.mideast 1.4782089143499884\n",
      "alt.atheism 1.4255910788582544\n",
      "sci.crypt 1.4088569219390155\n",
      "rec.sport.baseball 1.391599781355192\n",
      "talk.religion.misc 1.3819814254276068\n",
      "rec.autos 1.3561091577058808\n",
      "comp.sys.ibm.pc.hardware 1.3487476200188737\n",
      "soc.religion.christian 1.344990505175291\n",
      "sci.electronics 1.238146537297835\n",
      "comp.windows.x 1.2155094783893277\n",
      "rec.motorcycles 1.1960712374649423\n",
      "sci.med 1.179093846456174\n",
      "sci.space 1.1309613073853133\n",
      "misc.forsale 1.1099641946718148\n",
      "comp.graphics 1.094780404420162\n",
      "talk.politics.guns 1.0857617211857788\n",
      "comp.os.ms-windows.misc 0.8349593945654032\n"
     ]
    }
   ],
   "source": [
    "item = 3\n",
    "text = data_test.data[item]\n",
    "target = data_test.target_names[data_test.target[item]]\n",
    "print(text[:400], '\\n')\n",
    "print(target, '\\n')\n",
    "genres = list(M.models.keys())\n",
    "probs = np.zeros(len(genres))\n",
    "for i, genre in enumerate(genres):\n",
    "    probs[i] = np.median(np.array(M.kl_text(genre, text)))\n",
    "for j, p in sorted(enumerate(probs), key=lambda x: -x[1]):\n",
    "    print(genres[j], p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439781ab78c649199f3a61c917329aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lm_pred = []\n",
    "kl_pred = []\n",
    "targets = []\n",
    "docs = []\n",
    "genres = list(M.models.keys())\n",
    "for t, text in tqdm(list(enumerate(data_test.data[:100]))):\n",
    "    try:\n",
    "        lm_probs = np.zeros(len(genres))\n",
    "        kl_probs = np.zeros(len(genres))\n",
    "        for i, genre in enumerate(genres):\n",
    "            lm_probs[i] = np.max(np.array(M.p_text(genre, text)))\n",
    "            kl_probs[i] = np.max(np.array(M.kl_text(genre, text)))\n",
    "        lm_target = [j for j, p in sorted(enumerate(lm_probs), key=lambda x: -x[1])][0]\n",
    "        kl_target = [j for j, p in sorted(enumerate(kl_probs), key=lambda x: -x[1])][0]\n",
    "        lm_pred.append(genres[lm_target])\n",
    "        kl_pred.append(genres[kl_target])\n",
    "        targets.append(data_test.target_names[data_test.target[t]])\n",
    "        docs.append(t)\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00         5\n",
      "           comp.graphics       0.00      0.00      0.00         8\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00         5\n",
      "comp.sys.ibm.pc.hardware       0.83      0.71      0.77         7\n",
      "   comp.sys.mac.hardware       0.40      0.40      0.40         5\n",
      "          comp.windows.x       0.29      0.40      0.33         5\n",
      "            misc.forsale       0.33      1.00      0.50         4\n",
      "               rec.autos       0.17      0.20      0.18         5\n",
      "         rec.motorcycles       0.22      0.29      0.25         7\n",
      "      rec.sport.baseball       0.25      0.33      0.29         6\n",
      "        rec.sport.hockey       1.00      0.25      0.40         4\n",
      "               sci.crypt       0.50      0.67      0.57         3\n",
      "         sci.electronics       0.00      0.00      0.00         1\n",
      "                 sci.med       0.33      0.50      0.40         4\n",
      "               sci.space       0.33      0.20      0.25         5\n",
      "  soc.religion.christian       0.20      0.33      0.25         3\n",
      "      talk.politics.guns       0.33      0.17      0.22         6\n",
      "   talk.politics.mideast       0.40      0.29      0.33         7\n",
      "      talk.politics.misc       0.00      0.00      0.00         6\n",
      "      talk.religion.misc       0.50      0.33      0.40         3\n",
      "\n",
      "                accuracy                           0.29        99\n",
      "               macro avg       0.30      0.30      0.28        99\n",
      "            weighted avg       0.30      0.29      0.27        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(targets, lm_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00         5\n",
      "           comp.graphics       0.00      0.00      0.00         8\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00         5\n",
      "comp.sys.ibm.pc.hardware       0.17      0.29      0.21         7\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00         5\n",
      "          comp.windows.x       0.20      0.20      0.20         5\n",
      "            misc.forsale       0.00      0.00      0.00         4\n",
      "               rec.autos       0.00      0.00      0.00         5\n",
      "         rec.motorcycles       0.33      0.14      0.20         7\n",
      "      rec.sport.baseball       0.33      0.50      0.40         6\n",
      "        rec.sport.hockey       0.00      0.00      0.00         4\n",
      "               sci.crypt       0.00      0.00      0.00         3\n",
      "         sci.electronics       0.14      1.00      0.25         1\n",
      "                 sci.med       0.00      0.00      0.00         4\n",
      "               sci.space       0.50      0.40      0.44         5\n",
      "  soc.religion.christian       0.00      0.00      0.00         3\n",
      "      talk.politics.guns       0.20      0.17      0.18         6\n",
      "   talk.politics.mideast       0.00      0.00      0.00         7\n",
      "      talk.politics.misc       0.40      0.33      0.36         6\n",
      "      talk.religion.misc       0.14      0.33      0.20         3\n",
      "\n",
      "                accuracy                           0.14        99\n",
      "               macro avg       0.12      0.17      0.12        99\n",
      "            weighted avg       0.13      0.14      0.13        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(targets, kl_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sci.crypt',\n",
       " 'comp.graphics',\n",
       " 'misc.forsale',\n",
       " 'misc.forsale',\n",
       " 'rec.sport.baseball',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'rec.sport.hockey',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'talk.politics.mideast']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec.autos',\n",
       " 'comp.windows.x',\n",
       " 'alt.atheism',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.religion.misc',\n",
       " 'sci.med',\n",
       " 'soc.religion.christian',\n",
       " 'soc.religion.christian',\n",
       " 'comp.windows.x',\n",
       " 'comp.graphics']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nI've just spent two solid months arguing that no such thing as an\\nobjective moral system exists.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.data[docs[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#S i 0.03939831914779723 0.03509384984025559\n",
      "#S 've 0.001338258123226808 0.0010483226837060702\n",
      "#S just 0.0035865317702478455 0.0027456070287539937\n",
      "#S spent 5.353032492907232e-05 0.00014976038338658146\n",
      "i 've 0.007965686274509803 0.010369068541300527\n",
      "i just 0.006127450980392157 0.0036906854130052723\n",
      "i spent 7.862102948513678e-07 0.0008787346221441124\n",
      "i two 0.0004084967320261438 0.0005272407732864675\n",
      "'ve just 0.008064516129032258 0.0035087719298245615\n",
      "'ve spent 3.982437768037974e-08 7.443486319272112e-08\n",
      "'ve two 8.32119891532145e-07 5.080179412903217e-07\n",
      "'ve solid 7.964875536075948e-08 1.4886972638544225e-08\n",
      "just spent 1.0164851238580796e-07 1.6323434910684456e-07\n",
      "just two 0.001579778830963665 1.1140744326542142e-06\n",
      "just solid 2.0329702477161592e-07 3.264686982136892e-08\n",
      "just months 1.0699843409032417e-07 4.897030473205337e-08\n",
      "spent two 6.37511207222208e-08 0.025\n",
      "spent solid 6.102122386509799e-09 2.0893996685676104e-09\n",
      "spent months 3.211643361320947e-09 3.1340995028514152e-09\n",
      "spent arguing 6.423286722641893e-10 4.701149254277123e-09\n",
      "two solid 1.275022414444416e-07 1.4260152737973942e-08\n",
      "two months 6.710644286549557e-08 2.139022910696091e-08\n",
      "two arguing 1.3421288573099113e-08 3.208534366044137e-08\n",
      "two that 0.012594458438287154 0.01098901098901099\n",
      "solid months 6.423286722641894e-09 6.268199005702831e-10\n",
      "solid arguing 1.2846573445283787e-09 9.402298508554246e-10\n",
      "solid that 1.102557165941481e-06 3.516459642199288e-07\n",
      "solid no 1.9045045132633216e-07 4.847407231076856e-08\n",
      "months arguing 6.761354444886204e-10 1.410344776283137e-09\n",
      "months that 5.802932452323584e-07 5.274689463298932e-07\n",
      "months no 1.0023707964543798e-07 7.271110846615283e-08\n",
      "months such 1.5044013639871803e-08 3.6590611695790276e-08\n",
      "arguing that 0.25 7.912034194948398e-07\n",
      "arguing no 2.0047415929087594e-08 1.0906666269922924e-07\n",
      "arguing such 3.00880272797436e-09 5.488591754368542e-08\n",
      "arguing thing 4.32726684472717e-09 1.7981895897609997e-08\n",
      "that no 0.0011651616661811825 0.002822341057635175\n",
      "that such 0.0005825808330905913 0.0011883541295306002\n",
      "that thing 0.00029129041654529564 0.00014854426619132502\n",
      "that as 0.0037867754150888435 0.00267379679144385\n",
      "no such 4.4605500442219896e-07 0.008620689655172414\n",
      "no thing 6.41517309730803e-07 0.005387931034482759\n",
      "no as 0.00505902192242833 0.005387931034482759\n",
      "no an 3.5032859336080575e-06 0.0021551724137931034\n",
      "such thing 9.628168729517952e-08 0.019271948608137045\n",
      "such as 0.056179775280898875 0.08779443254817987\n",
      "such an 0.02247191011235955 0.008565310492505354\n",
      "such objective 7.522006819935901e-09 0.004282655246252677\n",
      "thing as 0.0078125 0.032679738562091505\n",
      "thing an 7.56189881116073e-07 0.006535947712418301\n",
      "thing objective 1.0818167111817926e-08 0.013071895424836602\n",
      "thing moral 1.0490439979631043e-09 2.917063112278955e-07\n",
      "as an 0.007447528774542992 0.011553784860557768\n",
      "as objective 1.2483150643871155e-07 0.0007968127490039841\n",
      "as moral 1.2104984257746135e-08 0.00039840637450199205\n",
      "as system 3.495282180283923e-07 1.4585968498791203e-06\n",
      "an objective 0.001430615164520744 0.01048951048951049\n",
      "an moral 5.72876370762664e-09 0.0017482517482517483\n",
      "an system 1.6541653649414098e-07 0.0017482517482517483\n",
      "an exists 1.1815466892438641e-08 3.58540983126202e-07\n",
      "objective moral 8.195656234086753e-11 4.880837625773938e-07\n",
      "objective system 2.3664740557101713e-09 1.4876525640201388e-07\n",
      "objective exists 1.690338611221551e-10 0.00390625\n",
      "objective . 0.1 0.1015625\n",
      "moral system 2.2947837455442907e-10 0.0410958904109589\n",
      "moral exists 1.6391312468173505e-11 9.151570548326133e-08\n",
      "moral . 3.165162437604304e-08 0.0684931506849315\n",
      "moral #E 7.947375828891992e-12 0.0684931506849315\n",
      "system exists 4.732948111420342e-10 2.78934855753776e-08\n",
      "system . 9.139322803152681e-07 0.056179775280898875\n",
      "system #E 0.03571428571428571 0.06741573033707865\n",
      "exists . 0.5 0.041666666666666664\n",
      "exists #E 0.5 0.041666666666666664\n",
      ". #E 0.96504401864319 0.9295114878429623\n"
     ]
    }
   ],
   "source": [
    "for tokens in N2Model.tokenize(data_test.data[docs[4]]):\n",
    "    sequence = N2Model.skip(tokens, s=5)\n",
    "    for a, b in sequence:\n",
    "        print(a, b, M.p_gram('rec.sport.baseball', a, b), M.p_gram('talk.religion.misc', a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As multi label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_pred = []\n",
    "kl_pred = []\n",
    "targets = []\n",
    "genres = list(M.models.keys())\n",
    "for t, text in tqdm(list(enumerate(data_test.data[:100]))):\n",
    "    lm_probs = np.zeros(len(genres))\n",
    "    kl_probs = np.zeros(len(genres))\n",
    "    for i, genre in enumerate(genres):\n",
    "        lm_probs[i] = np.median(np.array(M.p_text(genre, text)))\n",
    "        kl_probs[i] = np.median(np.array(M.kl_text(genre, text)))\n",
    "    lm_target = [j for j, p in sorted(enumerate(lm_probs), key=lambda x: -x[1])][:4]\n",
    "    kl_target = [j for j, p in sorted(enumerate(kl_probs), key=lambda x: -x[1])][:4]\n",
    "    lm_pred.append([genres[lmt] for lmt in lm_target])\n",
    "    kl_pred.append([genres[klt] for klt in kl_target])\n",
    "    targets.append(data_test.target_names[data_test.target[t]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in kl_pred[:10]:\n",
    "    print(\", \".join(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter specific words only\n",
    "In this example, we keep in the index only the words that are specifically relevant for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_words(label):\n",
    "    label_words = [x for x in M.models[label].n.keys() if M.models[label].n[x] > 0]\n",
    "    label_stats = [M.models[label].n[x] for x in label_words]\n",
    "    L = sum(label_stats)\n",
    "    p_m = np.array(label_stats) / L\n",
    "    p_g = np.array([M.G.n[x] for x in label_words]) / M.G.N\n",
    "    kl_words = p_m * np.log(p_m / p_g)\n",
    "    w = [x for i, x in enumerate(label_words) if kl_words[i] > 0]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_models = []\n",
    "for label in M.models.keys():\n",
    "    W = set(select_words(label))\n",
    "    nm = N2Model(label=label)\n",
    "    for k, v in M.models[label].index.items():\n",
    "        for z, c in v.items():\n",
    "            if k in W and z in W:\n",
    "                nm.index[k][z] = c\n",
    "                nm.n[k] += c\n",
    "    nm.N = sum(nm.n.values())\n",
    "    new_models.append(nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = N2Classifier(new_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#S i 0.051150184168462016 0.04068287037037037\n",
      "#S 've 0.0017374383209396067 0.0012152777777777778\n",
      "#S just 0.004656334700118146 0.00318287037037037\n",
      "#S spent 6.949753283758427e-05 0.00017361111111111112\n",
      "i 've 0.010233534505379166 0.011743630573248409\n",
      "i just 0.007871949619522435 0.004179936305732484\n",
      "i spent 1.2546236625094159e-06 0.0009952229299363057\n",
      "i two 0.0005247966413014956 5.786018183629562e-08\n",
      "'ve just 0.010471204188481676 0.0040650406504065045\n",
      "'ve spent 6.287932813941182e-08 1.0480101095281288e-07\n",
      "'ve two 1.245010697160354e-06 2.8331219609332643e-09\n",
      "'ve solid 1.0899083544164714e-07 2.8331219609332643e-09\n",
      "just spent 1.5703371477748394e-07 2.2664283669470102e-07\n",
      "just two 0.0020964360587002098 6.126914159416653e-09\n",
      "just solid 2.7219177228097213e-07 6.126914159416653e-09\n",
      "just months 1.0124514988739007e-08 6.126914159416653e-09\n",
      "spent two 9.777570920107492e-08 4.1460321379511186e-10\n",
      "spent solid 8.559489694370195e-09 4.1460321379511186e-10\n",
      "spent months 3.1838097448864805e-10 4.1460321379511186e-10\n",
      "spent arguing 3.1838097448864805e-10 6.8163259156301055e-09\n",
      "two solid 1.6947789594852985e-07 1.120811201530603e-11\n",
      "two months 6.303943294875231e-09 1.120811201530603e-11\n",
      "two arguing 6.303943294875231e-09 1.8426809502004971e-10\n",
      "two that 0.016835016835016835 7.019462744670019e-08\n",
      "solid months 5.518603557803232e-10 1.120811201530603e-11\n",
      "solid arguing 5.518603557803232e-10 1.8426809502004971e-10\n",
      "solid that 1.4836448803575002e-06 7.019462744670019e-08\n",
      "solid no 2.2882369116282986e-07 8.821835049084881e-09\n",
      "months arguing 2.0527139365627733e-11 1.8426809502004971e-10\n",
      "months that 5.518603557803232e-08 7.019462744670019e-08\n",
      "months no 8.511384717996525e-09 8.821835049084881e-09\n",
      "months such 2.0527139365627733e-11 4.618219131439996e-09\n",
      "arguing that 5.518603557803232e-08 1.154041845993486e-06\n",
      "arguing no 8.511384717996525e-09 1.4503626809368502e-07\n",
      "arguing such 2.0527139365627733e-11 7.592629700465758e-08\n",
      "arguing thing 1.9739620418296177e-09 2.2531743998888406e-08\n",
      "that no 0.0015384615384615385 0.003117309269893355\n",
      "that such 5.518603557803232e-08 0.0013125512715340443\n",
      "that thing 0.0003846153846153846 0.00016406890894175554\n",
      "that as 0.005 0.0029532403609515995\n",
      "no such 8.511384717996525e-09 0.010443864229765013\n",
      "no thing 8.184847414670453e-07 0.006527415143603133\n",
      "no as 0.007481296758104738 0.006527415143603133\n",
      "no an 8.511384717996525e-09 0.0026109660574412533\n",
      "such thing 1.9739620418296177e-09 0.022443890274314215\n",
      "such as 2.479126521351606e-08 0.10224438902743142\n",
      "such an 2.0527139365627733e-11 0.00997506234413965\n",
      "such objective 2.0527139365627733e-11 0.004987531172069825\n",
      "thing as 0.010752688172043012 0.04201680672268908\n",
      "thing an 1.9739620418296177e-09 0.008403361344537815\n",
      "thing objective 1.9739620418296177e-09 0.01680672268907563\n",
      "thing moral 1.9739620418296177e-09 3.069950119848545e-07\n",
      "as an 2.479126521351606e-08 0.013068949977467327\n",
      "as objective 2.479126521351606e-08 0.0009013068949977468\n",
      "as moral 2.479126521351606e-08 0.0004506534474988734\n",
      "as system 2.479126521351606e-08 2.5555681428093143e-08\n",
      "an objective 2.0527139365627733e-11 0.012861736334405145\n",
      "an moral 2.0527139365627733e-11 0.0021436227224008574\n",
      "an system 2.0527139365627733e-11 1.0745133290856649e-08\n",
      "an exists 2.0527139365627733e-11 4.747642003631323e-07\n",
      "objective moral 2.0527139365627733e-11 5.288569534192872e-07\n",
      "objective system 2.0527139365627733e-11 2.360934967444387e-09\n",
      "objective exists 2.0527139365627733e-11 0.004878048780487805\n",
      "objective . 7.216635421742689e-10 0.12682926829268293\n",
      "moral system 2.0527139365627733e-11 2.5106527946481773e-09\n",
      "moral exists 2.0527139365627733e-11 1.1093097071721633e-07\n",
      "moral . 7.216635421742689e-10 0.09174311926605505\n",
      "moral #E 2.0527139365627733e-11 2.5106527946481773e-09\n",
      "system exists 2.0527139365627733e-11 4.952205053663836e-10\n",
      "system . 7.216635421742689e-10 2.579753330280696e-09\n",
      "system #E 2.0527139365627733e-11 1.120811201530603e-11\n",
      "exists . 7.216635421742689e-10 0.046511627906976744\n",
      "exists #E 2.0527139365627733e-11 4.952205053663836e-10\n",
      ". #E 7.216635421742689e-10 2.579753330280696e-09\n"
     ]
    }
   ],
   "source": [
    "for tokens in N2Model.tokenize(data_test.data[docs[4]]):\n",
    "    sequence = N2Model.skip(tokens, s=5)\n",
    "    for a, b in sequence:\n",
    "        print(a, b, K.p_gram('rec.sport.baseball', a, b), K.p_gram('talk.religion.misc', a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0058711905924107e-288]\n",
      "[2.685894332951408e-217]\n"
     ]
    }
   ],
   "source": [
    "print(K.p_text('rec.sport.baseball', data_test.data[docs[4]]))\n",
    "print(K.p_text('talk.religion.misc', data_test.data[docs[4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad982227a4f494c8e54b49d4c0822c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alfio/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:139: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lm_pred = []\n",
    "kl_pred = []\n",
    "targets = []\n",
    "docs = []\n",
    "genres = list(K.models.keys())\n",
    "for t, text in tqdm(list(enumerate(data_test.data[:100]))):\n",
    "    try:\n",
    "        lm_probs = np.zeros(len(genres))\n",
    "        kl_probs = np.zeros(len(genres))\n",
    "        for i, genre in enumerate(genres):\n",
    "            lm_probs[i] = np.max(np.array(K.p_text(genre, text)))\n",
    "            kl_probs[i] = np.max(np.array(K.kl_text(genre, text)))\n",
    "        lm_target = [j for j, p in sorted(enumerate(lm_probs), key=lambda x: -x[1])][0]\n",
    "        kl_target = [j for j, p in sorted(enumerate(kl_probs), key=lambda x: -x[1])][0]\n",
    "        lm_pred.append(genres[lm_target])\n",
    "        kl_pred.append(genres[kl_target])\n",
    "        targets.append(data_test.target_names[data_test.target[t]])\n",
    "        docs.append(t)\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00         5\n",
      "           comp.graphics       0.33      0.12      0.18         8\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00         5\n",
      "comp.sys.ibm.pc.hardware       1.00      0.14      0.25         7\n",
      "   comp.sys.mac.hardware       0.14      0.20      0.17         5\n",
      "          comp.windows.x       0.00      0.00      0.00         5\n",
      "            misc.forsale       0.21      0.75      0.33         4\n",
      "               rec.autos       0.20      0.20      0.20         5\n",
      "         rec.motorcycles       0.25      0.29      0.27         7\n",
      "      rec.sport.baseball       0.25      0.33      0.29         6\n",
      "        rec.sport.hockey       0.00      0.00      0.00         4\n",
      "               sci.crypt       0.33      0.67      0.44         3\n",
      "         sci.electronics       0.00      0.00      0.00         1\n",
      "                 sci.med       1.00      0.25      0.40         4\n",
      "               sci.space       0.00      0.00      0.00         5\n",
      "  soc.religion.christian       0.25      0.33      0.29         3\n",
      "      talk.politics.guns       0.17      0.17      0.17         6\n",
      "   talk.politics.mideast       0.50      0.14      0.22         7\n",
      "      talk.politics.misc       0.25      0.17      0.20         6\n",
      "      talk.religion.misc       0.00      0.00      0.00         3\n",
      "\n",
      "                accuracy                           0.18        99\n",
      "               macro avg       0.24      0.19      0.17        99\n",
      "            weighted avg       0.28      0.18      0.18        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(targets, lm_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sci.electronics',\n",
       " 'sci.electronics',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'alt.atheism',\n",
       " 'sci.med',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.misc',\n",
       " 'talk.politics.misc',\n",
       " 'talk.politics.guns']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec.autos',\n",
       " 'comp.windows.x',\n",
       " 'alt.atheism',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.religion.misc',\n",
       " 'sci.med',\n",
       " 'soc.religion.christian',\n",
       " 'soc.religion.christian',\n",
       " 'comp.windows.x',\n",
       " 'comp.graphics']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2word relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [x for x, y in M.G.n.items() if y > 50]\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = np.zeros((len(words), len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(enumerate(words))\n",
    "for i, w1 in tqdm(data):\n",
    "    for j, w2 in data:\n",
    "        sigma = M.G.p_gram(w1, w2)\n",
    "        wv[i,j] = sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = cosine_similarity(wv[words.index('history')].reshape(1, -1), wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = [words[x] for x, y in sorted(enumerate(S[0]), key=lambda k: -k[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = np.zeros((len(words), len(words)))\n",
    "N = sum([sum(v.values()) for v in M.G.index.values()])\n",
    "data = list(enumerate(words))\n",
    "for i, w1 in tqdm(data):\n",
    "    for j, w2 in data:\n",
    "        sigma = (M.G.index[w1][w2] / N) * np.log((M.G.index[w1][w2] / N) / (M.G.p_word(w1) * M.G.p_word(w2)))\n",
    "        mi[i,j] = sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = cosine_similarity(wv[words.index('history')].reshape(1, -1), wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = [words[x] for x, y in sorted(enumerate(S[0]), key=lambda k: -k[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.G.index['arabia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
